\label{abstract}%
Despite the prevalence and importance of software testing, it lacks
a standardized and consistent taxonomy. This hinders precise communication,
leading to discrepancies across the literature (even within individual
documents!) and to potential misunderstandings when planning and performing
testing. In this paper, we systematically explore the current state of
software testing terminology. We 1) identify established standards
and prominent testing resources, 2) capture relevant testing terms
from these sources, along with their definitions and relationships---both
explicit and implicit---and 3) construct graphs to visualize and analyze
these data. This process uncovers \approachCount{} test approaches and
\ifnotpaper four in-scope methods for deriving test approaches, such as those
    related to \fi \qualityCount{} software qualities\ifnotpaper\else\ that may
    imply additional related test approaches\fi. We also build
a tool for generating graphs that illustrate relations between test
approaches and track discrepancies captured by this tool and manually through
the research process. This reveals \discrepCount{} discrepancies,
including nine terms used as synonyms to two (or more) disjoint test approaches
and \parSynCount{} pairs of test approaches that may either be synonyms or have
a parent-child relationship. This also highlights notable confusion surrounding
functional, operational acceptance, recovery, and scalability testing. Our
findings make clear the urgent need for improved testing terminology so that
the discussion, analysis and implementation of various test approaches can be
more coherent. We provide some preliminary advice on how to achieve this
standardization.