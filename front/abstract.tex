\label{abstract}%
Testing is a pervasive software development activity that is often
complicated and expensive (if not simply overlooked), partly due to
the lack of a standardized and consistent taxonomy for software testing.
This hinders precise communication, leading to discrepancies across the
literature and even within individual documents!
% Therefore, automating the software testing process is an area of interest,
% and understanding the underlying domain is an important prerequisite.
In this paper, we systematically examine the current state of software
testing terminology. We 1) identify established standards
and prominent testing resources, 2) capture relevant testing terms
from these sources, along with their definitions and relationships---both
explicit and implicit---and 3) construct graphs to visualize and analyze
this data. Our research uncovered \approachCount{} test approaches and
four in-scope methods for describing ``implied'' test approaches. We also build
a tool for generating graphs that illustrate relations between test
approaches and track discrepancies captured by this tool and manually through
the research process. Our results reveal \totalDiscreps{} discrepancies,
including nine terms used as synonyms to two (or more) disjoint test approaches
and \parSynCount{} pairs of test approaches that may
either be synonyms or have a parent-child relationship. They also reveal
notable confusion surrounding functional, operational acceptance, recovery,
and scalability testing. These findings make clear
the urgent need for improved testing terminology so that the discussion,
analysis and implementation of various test approaches can be more coherent.
We provide some preliminary advice on how to achieve this standardization.