Name | Approach Category | Definition | Parent(s) | Synonym(s) | Notes
0-Switch Testing | Technique (inferred from state transition testing and IEEE, 2021, p. 19) | Testing that "cover[s] valid single transitions in the state model" (IEEE, 2021, p. 19) | State Transition Testing (IEEE, 2021, p. 19) | Single Transition Testing (IEEE, 2021, p. 19) | 
1-Switch Testing | Technique (inferred from state transition testing and IEEE, 2021, pp. 19-20) | Testing "requires pairs of transitions to be exercised" (IEEE, 2021, p. 20) | N-Switch Testing (IEEE, 2021, p. 20) |  | 
A/B Testing | Practice (IEEE, 2022, p. 22), Type (implied by Firesmith, 2015, p. 58) | Testing "that allows testers to determine which of two systems or components performs better" (IEEE, 2022, p. 1) | Statistical Testing (IEEE, 2022, pp. 1, 35), Usability Testing (Firesmith, 2015, p. 58) | Split-Run Testing (IEEE, 2022, pp.1, 35) | "Not a test case generation technique as test inputs are not generated"; "us[es] the existing system as a partial oracle" (IEEE, 2022, p. 36)
Absolute Correctness Testing (implied by Lahiri et al., 2013, p. 345 and correctness testing) | Approach |  | Correctness Testing |  | 
Acceptance Testing | Level (IEEE, 2022, pp. 12, 21-22, 26-27; 2021, p. 6; 2017, p. 467; Washizaki, 2024, p. 5-7; Hamburg and Mogyorodi, 2024) | "Testing conducted to enable a user, customer, or other authorized entity to determine whether to accept a system or component" and whether it "satisfies its acceptance criteria" and/or "the contractual requirements are met" (IEEE, 2017, p. 5; similar in 2022, p. 13; 2021, p. 6) "with respect to user needs, requirements, and business processes" (Kam, 2008, p. 42) | Formal Testing (Kam, 2008, p. 42), System Testing (van Vliet, 2000, p. 439), V-Model Testing (Gerrard, 2000a, p. 9), W-Model Testing (Gerrard, 2000a, Figs. 3-5) | Qualification Testing (Bourque and Fairley, 2014, p. 4-6), AT (Firesmith, 2015, p. 30), Red-Box Testing (although this may be incorrect, since the other synonyms are; Sneed and Göschl, 2000, p. 18) | "May or may not involve the developers of the system" (Bourque and Fairley, 2014, p. 4-6), but "usually performed by the purchaser … with the … vendor" (IEEE, 2017, p. 5). Related to usability testing (van Vliet, 2000, p. 439) and validation testing (IEEE, 2017, p. 5). Note that IEEE (2017, p. 5) makes a distinction between "acceptance testing" and "an acceptance test"
Access Control Testing (Firesmith, 2015, p. 57) | Type (implied by Firesmith, 2015, p. 57) |  | Security Testing (Firesmith, 2015, p. 57) |  | 
Accessibility Testing | Type (IEEE, 2022, pp. 1, 22; implied by its quality (ISO/IEC, 2011) and by Firesmith, 2015, p. 58) | Testing "used to measure the degree to which a test item can be operated by users with the widest possible range of characteristics and abilities" (IEEE, 2022, p. 1; 2013, p. 2), including those with disabilities (Kam, 2008, p. 42; OG Gerrard) "to achieve a specified goal in a specified context of use" (ISO/IEC, 2011) | Usability Testing (IEEE, 2022, p.1 [although listed separately on p. 22]; ISO/IEC, 2011; Firesmith, 2015, p. 58) | User Assistance Testing? (ISO/IEC, 2023a; see ISO/IEC 25019) | Good to use when the software will be widely available or when it will be used by people with disabilities (IEEE, 2022, p. 45)
Acquisition Organization Testing (Firesmith, 2015, p. 37) | Practice? |  | Organization-based Testing (Firesmith, 2015, p. 37) |  | 
Ad Hoc Reviews | Approach | Reviews "performed informally without a structured process" (Hamburg and Mogyorodi, 2024) | Reviews |  | See ISO 20246
Ad Hoc Testing | Technique (Washizaki, 2024, p. 5-14) | Testing where "test cases are derived by relying on the software engineer's skill, intuition, and experience with similar programs" to "identify[] test cases that are not easily generated by more formalized techniques" (Washizaki, 2024, p. 5-14) "performed without test analysis [or] test design" (Hamburg and Mogyorodi, 2024) | Experience-based Testing (Washizaki, 2024, p. 5-14); Informal Testing (Hamburg and Mogyorodi, 2024) |  | Although this is sometimes called a "technique", it is one in which "no recognized test design technique is used" (Kam, 2008, p. 42)
Adaptive Random Testing | Technique (Washizaki, 2024, p. 5-12) | Random testing "in which other input selection criteria direct the random input sampling" (Washizaki, 2024, p. 5-12) | Random Testing (Washizaki, 2024, p. 5-12) |  | Kind of a vague definition; what are these criteria?
Adversarial Testing | Technique (Hamburg and Mogyorodi, 2024) | Testing "based on the attempted creation and execution of adversarial examples [("input[s] to an ML model … that result[] in the model outputting an incorrect result with high confidence")] to identify defects in an ML model" (Hamburg and Mogyorodi, 2024) | ML Model Testing |  | See ISO 29119-11
Agent-based Testing | Approach |  | Web Application Testing, Object-Oriented Testing, Data Flow Testing, Functional Testing, Specification-based Testing (usually) (Kam, 2008, Tab. 1) |  | 
Agile Testing (Firesmith, 2015, p. 29) | Practice? | Testing performed in the context of the agile development model "based on iterative development, frequent inspection and adaptation, and incremental deliveries" (IEEE, 2017, p. 15; OG ISO/IEC, 2016) | Continuous Testing (Firesmith, 2015, p. 29; implied by Washizaki, 2024, p. 9-6), Test-driven Development (Washizaki, 2024, p. 11-10; Sangwan and LaPlante, 2006, p. 25), Lifecycle-based Testing (Washizaki, 2024, p. 10-5; OG [2, 3, 10]), Incremental Testing (Sangwan and LaPlante, 2006, p. 26), DevOps Testing? (implied by Washizaki, 2024, p. 10-7; OG [11]), At-the-Beginning Testing (if it exists; implied by Kam, 2008, p. 42) |  | Test cases may change to match changes to requirements specifications (implied by Washizaki, 2024, p. 10-5; OG [9, 10])
AJAX Testing (Doğan et al., 2014, Tab. 22) | Practice? |  | Web Application Testing (Doğan et al., 2014, Tab. 22) |  | 
All Combinations Testing | Technique (IEEE, 2022, p. 22; 2021, p. 2, Fig. 2; Washizaki, 2024, p. 5-11) | Testing that covers "all unique combinations of P-V pairs" (IEEE, 2021, p. 16) | Combinatorial Testing (IEEE, 2022, p. 22; 2021, pp. 2, 16, Fig. 2; Washizaki, 2024, p. 5-11) |  | "The minimum number of test cases required to achieve 100% … coverage corresponds to the product of the number of P-V pairs for each test item parameter" (IEEE, 2021, p. 16). See also Grindal et al., 2005
All Rules Testing | Technique? (inferred from control flow testing) | Testing that covers "a set of formal business rules" (Doğan et al., 2014, Tab. 13; OG Thummalapenta et al., 2013) | Web Application Testing (Doğan et al., 2014, Tab. 13), Formal Testing, Control Flow Testing? |  | 
All Transitions Testing | Technique (inferred from state transition testing and IEEE, 2021, p. 20) | Testing that "cover[s] both valid transitions in the state model and 'invalid' transitions (transitions from states initiated by events in the state model for which no valid transition is specified)" (IEEE, 2021, p. 19) | State Transition Testing, Model-based Testing (IEEE, 2021, p. 19) |  | 
All-C-Uses Testing | Technique (IEEE, 2022, p. 22; 2021, Fig. 2; Washizaki, 2024, p. 5-13) | Testing that aims to execute all "use[s] of the value of a variable in any type of statement" (IEEE, 2017, p. 83; OG IEEE, 2015) as "defined in [a given] data definition"? (IEEE, 2017, p. 115; OG IEEE, 2015) | Data Flow Testing (IEEE, 2022, p. 22; 2021, p. 3, Fig. 2; Washizaki, 2024, p. 5-13) | Sometimes spelled in all lowercase (IEEE, 2021, p. 3, Fig. 2), All Computation Data Uses (implied by IEEE, 2017, p. 83) | See also van Vliet (2000, pp. 424-425)
All-Definitions Testing | Technique (IEEE, 2022, p. 22; 2021, Fig. 2; Washizaki, 2024, p. 5-13) | Testing that aims to execute all "statement[s] where a variable is assigned a value"? (IEEE, 2017, p. 115; OG IEEE, 2015) | Data Flow Testing (IEEE, 2022, p. 22; 2021, p. 3, Fig. 2; Washizaki, 2024, p. 5-13; Firesmith, 2015, p. 49) | Sometimes spelled without a hyphen (Firesmith, 2015, p. 49) or in all lowercase (IEEE, 2021, p. 3, Fig. 2), All Defs Testing (implied by Doğan et al., 2014, Tab. 11) | A "weaker strateg[y]" than all-DU-paths testing (Washizaki, 2024, p. 5-13). See also van Vliet (2000, pp. 424-425)
All-DU-Paths Testing | Technique (IEEE, 2022, p. 22; 2021, Fig. 2; Washizaki, 2024, p. 5-13) | Testing that "requires executing, for each variable, every control flow path segment from a definition of that variable to the use of that definition" (Washizaki, 2024, p. 5-13), or that aims to execute all "predicate or computational data use[s that] … use[] the value defined in [a given] data definition"? (IEEE, 2017, p. 125; OG IEEE, 2015) | Data Flow Testing (IEEE, 2022, p. 22; 2021, p. 3, Fig. 2; Washizaki, 2024, p. 5-13) | Sometimes spelled in all lowercase (IEEE, 2021, p. 3, Fig. 2), All Def-Use Testing (implied by Doğan et al., 2014, Tab. 11) | "The strongest data flow testing criterion" (Washizaki, 2024, p. 5-13). See also van Vliet (2000, pp. 424-425)
All-Input-GUI Testing (Doğan et al., 2014, Tab. 13; OG Mansour and Houri, 2006) | Technique? (inferred from input-parameter testing) |  | Web Application Testing, GUI Testing, Input-Parameter Testing? |  | 
All-P-Uses Testing | Technique (IEEE, 2022, p. 22; 2021, Fig. 2; Washizaki, 2024, p. 5-13) | Testing that aims to execute all "predicate data use[s that] … use[] the value defined in [a given] data definition"? (IEEE, 2017, p. 115; OG IEEE, 2015) | Data Flow Testing (IEEE, 2022, p. 22; 2021, p. 3, Fig. 2; Washizaki, 2024, p. 5-13) | Sometimes spelled in all lowercase (IEEE, 2021, p. 3, Fig. 2) | See also van Vliet (2000, pp. 424-425)
All-URL Testing | Technique? (inferred from control flow testing) | Testing that aims to "cover[] each URL of the application at least once" (Doğan et al., 2014, Tab. 13; OG Sprenkle et al., 2005) | Web Application Testing (Doğan et al., 2014, Tab. 13), Control Flow Testing? |  | Can be decomposed into covering single URLs, URL seq2, URL names, URL seq2 names, URL names values, and URL seq2 names values (Doğan et al., 2014, Tab. 13; OG Sampath et al., 2005)
All-Uses Testing | Technique (IEEE, 2022, p. 22; 2021, Fig. 2; Washizaki, 2024, p. 5-13) |  | Data Flow Testing (IEEE, 2022, p. 22; 2021, p. 3, Fig. 2; Washizaki, 2024, p. 5-13; Firesmith, 2015, p. 49) | Sometimes spelled without a hyphen (Firesmith, 2015, p. 49; Doğan et al., 2014, Tab. 11) or in all lowercase (IEEE, 2021, p. 3, Fig. 2) | A "weaker strateg[y]" than all-DU-paths testing (Washizaki, 2024, p. 5-13). See also van Vliet (2000, pp. 424-425)
Alpha Testing | Level (IEEE, 2022, p. 22; inferred from acceptance testing), Type (implied by Firesmith, 2015, p. 58) | "Simulated or actual operational testing" (Kam, 2008, p. 42) that is "first stage of testing before a product is considered ready for commercial or operational use" (IEEE, 2017, p. 17) | Acceptance Testing (IEEE, 2022, p. 22; Hamburg and Mogyorodi, 2024; Dennis et al., 2012, p. 455), Unscripted Testing (Washizaki, 2024, p. 5-8), Tester Testing (Firesmith, 2015, p. 39), Security Testing (Firesmith, 2015, p. 57), Operational Testing (Kam, 2008, p. 42), User as Tester Testing? (implied by Washizaki, 2024, p. 5-8) | Alpha Tester Testing? (Firesmith, 2015, p. 39) | "Often performed only by users within the organization developing the software" (IEEE, 2017, p. 17), by "a small, selected group of potential users" (Washizaki, 2024, p. 5-8), or "in the developer's test environment by roles outside the development organization" (Hamburg and Mogyorodi, 2024). Related to beta testing (IEEE, 2017, p. 17; Washizaki, 2024, p. 5-8). "Often employed for off-the-shelf software as a form of internal acceptance testing" (Kam, 2008, p. 42)
Anti-Spoofing Testing (Firesmith, 2015, p. 57) | Type (implied by Firesmith, 2015, p. 57) |  | Security Testing (Firesmith, 2015, p. 57) |  | 
Anti-Tamper Testing (Firesmith, 2015, p. 57) | Type (implied by Firesmith, 2015, p. 57) |  | Security Testing (Firesmith, 2015, p. 57) |  | 
API Testing | Approach | A specific form of interface testing that "simulate[s] the use of APIs by end-user applications", including "generating parameters", "defining internal data" (Washizaki, 2024, p. 5-10), and "submitting requests" (Hamburg and Mogyorodi, 2024) | Interface Testing (Washizaki, 2024, p. 5-10) | Application Program Interface Testing (Washizaki, 2024, p. 5-10) | 
Application System Testing (AST) | Approach | Testing that "aims to cover complete testing of the [e-business] application with business oriented scenarios to ensure all features of the system meet their requirements" (Gerrard, 2000b, p. 17) | Functional Testing (Gerrard, 2000a, Tab. 2; 2000b, Tab. 1, p. 13), Functionality Testing (2000a, Tab. 2; 2000b, Tab. 1, p. 17), System Testing, Dynamic Testing (2000a, Tab. 2; 2000b, Tab. 1), Scenario Testing (implied by 2000b, p. 17) | Application Testing? (Firesmith, 2015, p. 22) | "Simply System Testing for E-Business systems", although "the navigation buttons … are not under the control of the application" and "the Web is 'stateless'" (which is why things like cookies are used) (Gerrard, 2000b, p. 17)
Architect Testing (Firesmith, 2015, p. 39) | Practice? |  | Developer Testing (Firesmith, 2015, p. 39), Architecture-driven Testing |  | 
Architecture-driven Testing | Approach | Testing that "verifies" the "system conforms to [the specified] architecture" (Firesmith, 2015, p. 33) |  |  | 
Assertion Checking (Firesmith, 2015, p. 31) | Practice? | Testing of [separation logic] specifications to ensure that they are not violated (inferred from Chalin et al., 2006, p. 343) | Ongoing Built-In Testing (Firesmith, 2015, p. 31), Self-Testing? (implied by Firesmith, 2015, p. 31), Formal Modular Verification? (implied by Chalin et al., 2006, p. 342), Specification-based Testing? | Invariant-based Testing (implied by Doğan et al., 2014, pp. 184-185) | "Types [of assertion] include input assertion, loop assertion, output assertion" (IEEE, 2017, p. 30), which may imply sub-approaches
Asynchronous Testing (Jard et al., 1999) | Practice? | Testing in which the test environment, such as "a network connection", comes "between the tester and the IUT" (Jard et al., 1999, p. 26) | Test Environment Testing (implied by Jard et al., 1999, p. 26) |  | "Error-prone" (Jard et al., 1999, p. 25)
Attacks | Practice (IEEE, 2022, p. 34), Technique? (Hamburg and Mogyorodi, 2024) | Testing with the goal of "exploiting a specific … way of thinking about how and why software fails … [which] can be behaviour-based" (IEEE, 2022, p. 34), including by "attempting to trigger specific failures" (Hamburg and Mogyorodi, 2024) | Experience-based Testing (IEEE, 2022, p. 34; 2021, p. 4) | Fault Attacks (Hamburg and Mogyorodi, 2024) | This term can also be defined as a "malicious action or interaction with the system or its environment that has the potential to result in a fault or an error, and thereby possibly in a failure, or an adverse consequence" (IEEE, 2019, p. 7) which is essentially the same definition with the modification of being "malicious"; like the difference between white- and black-hat hacking
At-the-Beginning Testing? | Practice? |  | Static Testing?, W-Model Testing? (Gerrard, 2000a, Fig. 4), Incremental Testing?, Continuous Testing? | Early Test Case Preparation? (Gerrard, 2000a, Fig. 4) | Not described by any source; implied by at-the-end testing (Firesmith, 2015, p. 29) and early test case preparation (Gerrard, 2000a, Fig. 4)
At-the-End Testing (Firesmith, 2015, p. 29) | Practice? | Testing that occurs as "the last phase of the development life cycle" (Gerrard, 2000a, p. 8) | Waterfall Testing (Firesmith, 2015, p. 29) |  | "The most costly and least effective way of performing testing" (Gerrard, 2000a, p. 8)
Audio Testing | Approach | "Testing to determine if the game music and sound effects will engage the user in the game and enhance the game play [sic]" (Hamburg and Mogyorodi, 2024) |  |  | 
Audits | Practice? | "Independent examination[s] of … work products to assess compliance with specifications, standards, contractual agreements, or other criteria" (IEEE, 2017, p. 36; OG ISO/IEC TS 24748-1:2016) "often mandated to be performed by third parties" (Washizaki, 2024, p. 12-14; similar in Hamburg and Mogyorodi, 2024) | Static Analysis? (Washizaki, 2024, p. 12-13), Static Testing, Compliance Testing (implied by IEEE, 2022, p. 44), Independent Test Organization Testing? |  | Also described as testing "used to verify compliance with standards" (IEEE, 2022, p. 44)
Automated Testing | Practice (IEEE, 2022, pp. 20, 22) | Testing "executed by a test automation tool" (IEEE, 2022, p. 35) such as test drivers (Gerrard, 2000a, p. 11) | Scripted Testing (IEEE, 2022, p. 33), Developer Testing (can be) (Gerrard, 2000a, p. 11) |  | Often cost-effective "if a set of test cases is going to be executed 5 or more times" (IEEE, 2022, p. 35) but "must be automated as much as possible throughout the entire software delivery process, including throughout development and operations", and at all levels (Washizaki, 2024, p. 6-13); it is time-consuming to "automate manual tests later" (Gerrard, 2000a, p. 11). See also "automated verification system " (IEEE, 2017, p. 37)
Availability Testing | Type (implied by its quality (ISO/IEC, 2023a; IEEE, 2017, p. 38; OG ISO/IEC 16350-2015)) | Testing the "capability of a product to be operational and accessible when required for use" (ISO/IEC, 2023a) or "to perform its required function at an agreed instant or over an agreed period of time" (IEEE, 2017, p. 38; OG ISO/IEC 16350-2015), usually represented as a ratio, percentage (IEEE, 2017, p. 38), or proportion (ISO/IEC, 2023a) representing uptime (Gerrard, 2000b, p. 26) | Reliability Testing (ISO/IEC, 2023a; Washizaki, 2024, p. 7-10), Security Testing (IEEE, 2017, p. 404), Post-Deployment Monitoring (Gerrard, 2000a, Tab. 2; 2000b, Tab. 1, p. 32), Non-functional Testing, Automated Testing, Dynamic Testing, Post-Deployment Monitoring (2000a, Tab. 2; 2000b, Tab. 1), Dependability Testing (if it exists) (ISO/IEC, 2023a) |  | Can be supported by "failover or duplication of systems" (ISO/IEC, 2023a), "diverse routing", multiple servers, middleware, or "distributed object technology that handles load balancing and rerouting of traffic in failure scenarios" (Gerrard, 2000b, p. 26). Related to robustness testing, as well as error/fault tolerance testing (if they exist) (IEEE, 2017, p. 38)
Back-to-Back Testing | Practice (IEEE, 2022, p. 22) | Testing "whereby an alternative version of the system is used to generate expected results for comparison from the same test inputs" (IEEE, 2022, p.2) or where "two or more variants of a program are executed with the same inputs, the outputs are compared, and errors are analyzed in case of discrepancies" (IEEE, 2017, p. 38; similar in Hamburg and Mogyorodi, 2024; OG Spillner) | Non-functional Testing (Washizaki, 2024, p. 5-9) | Differential Testing (IEEE, 2022, p.2) | "Not a test case generation technique as test inputs are not generated" (IEEE, 2022, p. 35). Similar to testing using a pseudo-oracle (Barr et al., 2015, p. 515) and related to mutation testing (IEEE, 2017, p. 38)
Backup and Recovery Testing | Type (inferred from reliability testing) | Testing "that measures the degree to which system state can be restored from backup within specified parameters of time, cost, completeness, and accuracy in the event of failure" (IEEE, 2013, p. 2) | Reliability Testing (IEEE, 2013, p. 2) |  | Nonatomic; captures both "backup" and "recovery". Seems to be what is meant by "recovery testing" in the context of performance
Backup Testing (implied by Washizaki, 2024, p. 6-8) | Approach |  |  |  | "Should be constantly rehearsed as changes to the production environment are made" (Washizaki, 2024, p. 6-8)
Backwards Compatibility Testing (Firesmith, 2015, p. 53) | Type (implied by Firesmith, 2015, p. 53) |  | Compatibility Testing (Firesmith, 2015, p. 53) |  | 
Base Choice Testing | Technique (IEEE, 2022, p. 22; 2021, p. 2, Fig. 2) | Testing "based on … representative or typical value[s] for … [given input] parameter[s]" (IEEE, 2021, p. 1) "where all parameters except one are set to their 'base' value and the final parameter is set to one of its other valid values" (p. 17) | Combinatorial Testing (IEEE, 2022, p. 22; 2021, pp. 2, 17, Fig. 2), Scenario Testing (can be; p. 17), Smoke Testing? | Base Value Testing (implied by IEEE, 2021, pp. 1, 17) | "Generally[,] the base choice is the most 'important' [or "most frequently used"] value that the parameter can take" (IEEE, 2021, p. 17). See Grindal et al., 2005
Baseline Testing (Kam, 2008, p. 15) | Approach, "Method" (Kam, 2008, p. 15) |  |  |  | 
Behaviour Analysis? | Approach |  | Static Testing, W-Model Testing (Gerrard, 2000a, Fig. 4), Static Analysis? |  | 
Beta Testing | Level (IEEE, 2022, p. 22), Type (implied by Firesmith, 2015, p. 58) | The "second stage of testing when a product is in limited production use" (IEEE, 2017, p. 17) "to determine whether or not … [it] satisfies the user/customer needs and fits within the business processes" (Kam, 2008, p. 42) | Acceptance Testing (IEEE, 2022, p. 22; Hamburg and Mogyorodi, 2024; Dennis et al., 2012, p. 455), Unscripted Testing (Washizaki, 2024, p. 5-8, implied by Dennis et al., 2012, p. 455), User Testing (Firesmith, 2015, p. 39), Security Testing (Firesmith, 2015, p. 58), Operational Testing (Kam, 2008, p. 42), User as Tester Testing? | Beta Tester Testing? (Firesmith, 2015, p. 39) | "Often performed at a customer site" (IEEE, 2017, p. 45) by "a larger set of representative users" (Washizaki, 2024, p. 5-8) or, more specifically, "at an external site to the developer's test environment by roles outside the development organization" (Hamburg and Mogyorodi, 2024); related to alpha testing (Washizaki, 2024, p. 5-8)
Big-Bang Testing | Level (inferred from integration testing) | "Testing in which … [components of a system] are combined all at once into an overall system, rather than in stages" (IEEE, 2017, p. 45) | Integration Testing (Washizaki, 2024, p. 5-7; IEEE, 2017, p. 45; Sharma et al., 2021, p. 603; Kam, 2008, p. 42) |  | 
Block Testing (implied by Doğan et al., 2014, Tab. 11) | Technique (inferred from structure-based testing) |  | Structured-based Testing (implied by Doğan et al., 2014, Tab. 11), Control Flow Testing? |  | 
Blue Team Testing (Firesmith, 2015, p. 57) | Type (implied by Firesmith, 2015, p. 57) |  | Penetration Testing (Firesmith, 2015, p. 57) |  | 
Bottom-Up (Integration) Testing | Level (inferred from integration testing) | Integration testing (Washizaki, 2024, p. 5-7; Kam, 2008, p. 42) that "starts with the lowest-level components … and proceeds through progressively higher-levels" (IEEE, 2017, p. 49; OG ISO/IEC 2015; similar in Kam, 2008, p. 42) | Integration Testing (Washizaki, 2024, p. 5-7; Sharma et al., 2021, p. 603; Kam, 2008, p. 42; Sangwan and LaPlante, 2006, p. 27) |  | Difference between this as integration testing vs. not (as in Firesmith, 2015, p. 28; Gerrard, 2000b, p. 27)? Often used for functional web application testing (Gerrard, 2000b, p. 13)
Boundary Value Analysis | Technique (IEEE, 2022, pp. 2, 20, 22; 2021, pp. 1, 7, Fig. 2; Washizaki, 2024, p. 5-11; Hamburg and Mogyorodi, 2024) | Testing "based on exercising the boundaries of equivalence partitions" (IEEE, 2022, p. 2; 2021, p. 1; similar on p. 12 and in Hamburg and Mogyorodi, 2024) (i.e., "minimum or maximum input[s], internal [values], or output value[s] specified for a system or component" (IEEE, 2017, p. 49)) | Specification-based Testing (IEEE, 2022, pp. 2, 22; 2021, p. 1, Fig. 2; Washizaki, 2024, p. 5-11; Hamburg and Mogyorodi, 2024; Sharma et al., 2021, Fig. 1), Equivalence Partitioning (IEEE, 2022, p. 2; 2021, p. 1; implied by pp. 10, 12 and Hamburg and Mogyorodi, 2024), Model-based Testing (IEEE, 2021, p. 12), Negative Testing (can be; p. 10), One-to-One Testing, Minimized Testing (can be; pp. 11, 13; OG BS 7925-2; Myers 1979) Gray-Box Testing (Firesmith, 2015, p. 48), Dynamic Testing, W-Model Testing (Gerrard, 2000a, Fig. 5), Functional Testing? (IEEE, 2022, p. 20) | Boundary Testing (implied by IEEE, 2021, p. 13) | "Contiguous partitions … will result in duplicate test coverage items, in which case it is typical practice to only exercise these duplicated values once" (IEEE, 2021, p. 13). Seems to be related to stress testing (IEEE, 2017, p. 49). See also BS 7925-2; Myers 1979; and Patton, 2006, pp. 70-74
Branch Condition Combination Testing | Technique (IEEE, 2022, p. 22; 2021, p. 2, Fig. 2; Hamburg and Mogyorodi, 2024) | Testing "based on exercising combinations of Boolean values of conditions within a decision" (IEEE, 2021, p. 2) | Structure-based Testing (IEEE, 2022, p. 22; 2021, p. 2, Fig. 2; Hamburg and Mogyorodi, 2024) | (Multiple) Condition Testing (Hamburg and Mogyorodi, 2024; Patton, 2006, p. 120), Condition Combination Testing (Hamburg and Mogyorodi, 2024), Extended Branch Coverage? (van Vliet, 2000, p. 422) | 
Branch Condition Testing | Technique (IEEE, 2022, p. 22; 2021, p. 2, Fig. 2; Washizaki, 2024, p. 5-13) | Testing "based on exercising combinations of Boolean values of conditions within decisions and the decision outcomes" (IEEE, 2021, p. 2) | Structure-based Testing (IEEE, 2022, p. 22; 2021, p. 2, Fig. 2), Control Flow Testing (Washizaki, 2024, p. 5-13) | (Multiple) Condition Testing? (Patton, 2006, p. 120), Extended Branch Coverage? (van Vliet, 2000, p. 422) | 
Branch Testing | Technique (IEEE, 2022, pp. 2, 22; 2021, pp. 2, 8, Fig. 2; Washizaki, 2024, p. 5-13; Hamburg and Mogyorodi, 2024) | Testing "based on exercising branches [or "execut[ing] each outcome of each decision point" (IEEE, 2017, p. 51)] in the control flow of the test item" (IEEE, 2022, p. 2; 2021, p. 2) | Structure-based Testing (IEEE, 2022, pp. 2, 22; 2021, p. 2, Fig. 2; Hamburg and Mogyorodi, 2024), Control Flow Testing (Washizaki, 2024, p. 5-13; Firesmith, 2015, p. 49; implied by IEEE, 2021, p. 2), Closed-Loop Testing (Preuße et al., 2012, p. 6) | Arc Testing (Kam, 2008, p. 42) | IEEE (2017, p. 51) says it is "designed to execute each outcome of each decision point"; is this level of coverage required or advised?
Browser Page Testing | Approach | Testing "the objects that execute within the browser, but … not … the server-based components", including code within HTML and applets (Gerrard, 2000b, p. 13) | Smoke Testing, Functional Testing, Dynamic Testing, Desktop Development Testing (Gerrard, 2000a, Tab. 2; 2000b, Tab. 1), Web Application Testing |  | "Most easily tested against checklists" (Gerrard, 2000b, p. 13)
Buddy Testing | Technique (Washizaki, 2024, p. 5-14) | Testing that "generates test cases by using internal architecture knowledge and testing specific knowledge" (Washizaki, 2024, p. 5-14); this definition seems vague | Ad Hoc Testing (Washizaki, 2024, p. 5-14), Group Testing (Firesmith, 2015, p. 36), Embedded Tester Testing (Firesmith, 2015, p. 39) |  | Related to pair testing
Bug Hunt Testing (Firesmith, 2015, p. 50) | Technique? |  | Experience-based Testing (Firesmith, 2015, p. 50) |  | 
Build Verification Testing (BVT) | Practice (inferred from automated testing) | "Automated test[ing] that validates the integrity of each new build and verifies its key/core functionality, stability, and testability" (Hamburg and Mogyorodi, 2024) | Automated Testing (Hamburg and Mogyorodi, 2024); Integrity, Functionality, Stability, and Testability Testing (if they exist) |  | 
Built-In Testing (Firesmith, 2015, p. 31) | Practice? |  |  | BIT (Firesmith, 2015, p. 31), Self-Testing? (implied by Firesmith, 2015, p. 31) | 
Business Acceptance Testing (Firesmith, 2015, p. 30) | Level (Firesmith, 2015, p. 30; inferred from acceptance testing) |  | Acceptance Testing (Firesmith, 2015, p. 30) | BAT (Firesmith, 2015, p. 30) | 
Business Process-based Testing (Kam, 2008, p. 42) | Technique (Washizaki, 2024, p. 5-12) | Testing "designed based on descriptions and/or knowledge of business processes" (Kam, 2008, p. 43), including "roles in a workflow specification" (Washizaki, 2024, p. 5-12) | Scenario-based Testing (Washizaki, 2024, p. 5-12) | Business Process Testing (Washizaki, 2024, p. 5-12) | 
Canary (Release) Testing (see Washizaki, 2024, pp. 6-5, 6-10) | Technique (Washizaki, 2024, p. 6-5) | "A partial and time-limited deployment of a change in a service and an evaluation of that change" to help "decide whether to proceed with a complete deployment" (Washizaki, 2024, p. 6-10) |  |  | A method for "testing the software in the production system context" which "can be particularly challenging" (Washizaki, 2024, p. 6-5)
Capacity Testing | Type (IEEE, 2022, p. 22; 2013, p. 2; implied by its quality (ISO/IEC, 2023a) and by Firesmith, 2015, p. 53) | Testing that evaluates the "capability of a product to meet requirements for the maximum limits of a product parameter", such as the number of concurrent users, transaction throughput, or database size (ISO/IEC, 2023a) | Performance Testing (Washizaki, 2024, p. 5-9; implied by Moghadam, 2019, p. 1187; implied by IEEE, 2022, p. 22), Performance Efficiency Testing (IEEE, 2013, p. 2; ISO/IEC, 2023a), Volume Testing (potentially) (IEEE, 2017, p. 508; OG 2013) |  | Has the following subcategories: channel capacity (IEEE, 2017, p. 67), memory capacity (p. 270), storage capacity (p. 441)
Capture-Replay Driven Testing | Practice (IEEE, 2022, p. 22; inferred from automated testing); Approach (Hamburg and Mogyorodi, 2024) | "A test automation approach in which inputs to the test object are recorded during manual testing to generate automated test scripts that can be executed later" (Hamburg and Mogyorodi, 2024) | Automated Testing (IEEE, 2022, pp. 22, 35; Hamburg and Mogyorodi, 2024; Firesmith, 2015, p. 44), Specification-based Testing (implied by Doğan et al., 2014, p. 194) | Capture/Playback, Capture/Replay, Record/Playback (Hamburg and Mogyorodi, 2024), Record-Playback Testing? (Firesmith, 2015, p. 44) | 
Cause-Effect Graphing | Technique (IEEE, 2022, pp. 2, 22; 2021, p. 2, Fig. 2; Washizaki, 2024, p. 5-11) | Testing "based on exercising decision rules ["between causes … and effects" (IEEE, 2021, p. 18)] in a cause-effect graph" (2022, p. 2; 2021, p. 2) | Specification-based Testing (IEEE, 2022, p. 22; 2021, p. 2, Fig. 2; Washizaki, 2024, p. 5-11; Firesmith, 2015, p. 47), Model-based Testing (IEEE, 2021, p. 18), Dynamic Testing, W-Model Testing (Gerrard, 2000a, Fig. 5) | Cause and Effect Testing? (Firesmith, 2015, p. 47) | Related to decision table testing (Washizaki, 2024, p. 5-11; implied by IEEE, 2021, pp. 18-19). See BS 7925-2; Myers, 1979; Nursimulu and Probert, 1995
Certification | Approach | The "process of confirming that a system or component complies with its specified requirements and is acceptable for operational use" (IEEE, 2017, p. 63; similar in Hamburg and Mogyorodi, 2024); usually done by a third-party (IEEE, 2017, p. 63; OG ISO/IEC 2015) |  |  | 
CGI Component Testing | Approach | Testing that "covers the objects that execute on the server, but are initiated by forms-based user interactions on the browser" (Gerrard, 2000b, p. 13) | Smoke Testing, Infrastructure Testing, Functional Testing, Dynamic Testing (Gerrard, 2000a, Tab. 2; 2000b, Tab. 1), Transaction Testing, Unit Testing (implied by Gerrard, 2000b, p. 16) | Common Gateway Interface Component Testing (Gerrard, 2000a, p. 17) | If the UI is "the last thing to be written", "server-based components cannot be tested completely until very late in the project" (Gerrard, 2000b, p. 13), so test drivers may be used (p. 14). The functional testing portion of this is often developer testing (p. 14).  "More effective and economic" when automated due to the potential for "complex transactions that interface with legacy systems" (p. 13)
Change-Related Testing | Approach | "Testing initiated by modification to a component or system" (Hamburg and Mogyorodi, 2024) |  |  | 
Checklist-based Reviews | Approach; Technique? (Hamburg and Mogyorodi, 2024) | "Review[s] … guided by a list of questions or required attributes" (Hamburg and Mogyorodi, 2024) | Checklist-based Testing, Reviews |  | See ISO 20246
Checklist-based Testing | Practice (IEEE, 2022, p. 34); Technique? (Hamburg and Mogyorodi, 2024) | Testing generated "based on a list of pre-determined items" that "can be based on personal experience, commonly found defects, and perceived risks" (IEEE, 2022, p. 34) | Experience-based Testing (IEEE, 2022, p. 34; Hamburg and Mogyorodi, 2024) | Checklist Analysis? (IEEE, 2017, p. 67) | "Often focused on a particular quality characteristic" (IEEE, 2022, p. 34). See also Patton, 2006, pp. 61, 99-103
Classification Tree Method | Technique (IEEE, 2022, p. 22; 2021, p. 2, Fig. 2; Hamburg and Mogyorodi, 2024) | Testing "based on exercising classes in a classification tree" (IEEE, 2021, p. 2) | Specification-based Testing (IEEE, 2022, p. 22; 2021, p. 2, Fig. 2; Hamburg and Mogyorodi, 2024; Firesmith, 2015, p. 47), Model-based Testing (IEEE, 2022, p. 13; 2021, pp. 6, 12) | Classification Tree Technique (Hamburg and Mogyorodi, 2024) | Can be done based on "minimality" by covering "the classes represented by leaf nodes" or on "maximality" by covering "unique combinations of the classes represented by leaf nodes" (IEEE, 2021, p. 12). Related to combinatorial testing (Hamburg and Mogyorodi, 2024) and equivalence partitioning (although with disjoint partitions) and can be done recursively (IEEE, 2021, p. 12). See Grochtmann and Grimm 1993
Closed Beta Testing (Firesmith, 2015, p. 58) | Level (inferred from beta testing), Type (implied by Firesmith, 2015, p. 58) |  | Beta Testing (Firesmith, 2015, pp. 39, 58) |  | 
Closed Loop Testing (Control Flow) | Technique? | Loop testing performed on loops with "no exit … whose execution can be interrupted only by intervention from outside the computer program or procedure in which the [it] is located" (IEEE, 2017, p. 71) | Loop Testing |  | Not explicitly described by a source (in the context of software control flows); implied by loop testing (Gerrard, 2000a, Fig. 5) and closed loops (IEEE, 2017, p. 71)
Closed Loop Testing (Control Systems) | Technique? | Testing that "evaluate[s] the performance of the physical device(s) under actual operating conditions prior to their installation in the real network" (Forsyth et al., 2004, p. 329) | Specification-based Testing (Preuße et al., 2012, pp. 5-6), Formal Testing (p. 6), Control System Testing? (Forsyth et al., 2004, pp. 329, 331), Performance Testing (can be; Preuße et al., 2012, p. 2; Forsyth et al., 2004, pp. 329, 331), Correctness Testing (can be; Preuße et al., 2012, pp. 4, 6), Functional Testing, Non-functional Testing (can be; p. 6), Online Testing (can be; Forsyth et al., 2004, p. 329), Model-based Testing (implied by Preuße et al., 2012), Domain-Specific Testing? | Sometimes spelled with a hyphen (Preuße et al.), Closed-Loop Verification? (Preuße et al., 2012, p. 1) | This definition seems exclusive to hardware, but may be generalizable. "The only way to do [sic] get a comprehensive assertion about the correctness of control software" since the state space is restricted to "practically relevant" inputs (Preuße et al., 2012, p. 4). Often performed using "real time simulators" (Forsyth et al., 2004, p. 332). See also Trudnowski et al., (2017; if in scope)
Cloud Testing (Firesmith, 2015, p. 42) | Approach |  |  |  | 
Code Injection | Approach | "A type of security attack performed by inserting malicious code at an interface into an application to exploit poor handling of untrusted data" (Hamburg and Mogyorodi, 2024) | Security Attacks (Hamburg and Mogyorodi, 2024), Interface Testing (implied by Hamburg and Mogyorodi, 2024) |  | 
Code Reviews | Approach | A "meeting at which software code is presented to project personnel, managers, users, customers, or other interested parties for comment or approval" (IEEE, 2017, p. 74); can also be done "using a pull request technique/tool … before [the code] can be merged into [the] project" (Washizaki, 2024, p. 12-13) | Reviews (Washizaki, 2024, p. 12-13), Peer Reviews (sometimes) (Washizaki, 2024, p. 12-13), Static Analysis? (Washizaki, 2024, p. 12-13) |  | Sometimes kept separate from testing (Washizaki, 2024, p. 12-11). Seems to line up most closely with the notion of "peer review" from Patton (2006, p. 94) and van Vliet (2000, p. 414)
Co-existence Testing | Type (inferred from compatibility and interoperability testing and implied by its quality (ISO/IEC, 2023a)) | "Testing that measures the degree to which a test item can function satisfactorily alongside other independent products in a shared environment" (IEEE, 2022, p. 3; similar in ISO/IEC, 2023a) "without a negative impact on any of them" (Hamburg and Mogyorodi, 2024; similar in ISO/IEC, 2023a) | Compatibility Testing (IEEE, 2022, p. 3; ISO/IEC, 2023a) | Sometimes spelled without a hyphen (Hamburg and Mogyorodi, 2024) | Testing approach not mentioned explicitly by IEEE (2022), Hamburg and Mogyorodi (2024), or ISO/IEC (2023a). Related to portability testing (Hamburg and Mogyorodi, 2024)
Combinatorial Testing | Technique (IEEE, 2022, pp. 3, 22; 2021, pp. 2, 15, Fig. 2; Washizaki, 2024, p. 5-11; Hamburg and Mogyorodi, 2024), Practice? (since it is a "class of … techniques" (IEEE, 2022, p. 3; 2021, p. 2); see notes) | Testing that "systematically derive[s] a meaningful and manageable [(i.e., finite)] subset of test cases … in terms of test item parameters and the values these parameters can take" (P-V pairs) (IEEE, 2021, p. 15) | Specification-based Testing (IEEE, 2022, pp. 3, 22; 2021, p. 2, Fig. 2; Washizaki, 2024, p. 5-11; Hamburg and Mogyorodi, 2024; Firesmith, 2015, p. 47), Model-based Testing (IEEE, 2022, p. 13; 2021, pp. 6, 15) |  | "Other test design techniques, such as equivalence partitioning or boundary value analysis, … [can be used to] reduce the large set of possible values for a parameter to a manageable subset" (IEEE, 2021, p. 16). Related to the classification tree method (Hamburg and Mogyorodi, 2024). See also Grindal et al., 2005 and Engström and Petersen, 2015
Command-Form Testing (Doğan et al., 2014, Tab. 13; OG Halfond and Orso, 2006; 2007, Halfond et al., 2009) | Technique? (inferred from database coverage testing) | Testing that aims to "adequately exercis[e] the interactions between an application and its underlying database" (Doğan et al., 2014, Tab. 13; OG Halfond and Orso, 2006; 2007, Halfond et al., 2009) | Web Application Testing, Database Coverage Testing? (Doğan et al., 2014, Tab. 13), Integration Testing? |  | 
Command-Line Interface (CLI) Testing | Approach | "Testing performed by submitting commands to the software under test using a dedicated command-line interface" (Hamburg and Mogyorodi, 2024) |  |  | 
Comparison Testing (Sharma et al., 2021, p. 601; OG [10]) | Approach |  |  |  | 
Compatibility Testing | Type (IEEE, 2022, pp. 3, 22; 2013, p. 2; implied by its quality (ISO/IEC, 2023a) and by Firesmith, 2015, p. 53) | "Testing that measures the degree to which a test item can function satisfactorily alongside other independent products in a shared environment (co-existence), and where necessary, exchanges information with other systems or components (interoperability)" (IEEE, 2022, p. 3; 2013, p. 2; similar in ISO/IEC, 2023a and Hamburg and Mogyorodi, 2024) | Non-functional Testing (Washizaki, 2024, p. 5-9) |  | Not atomic and implies the existence of "co-existence testing" and "interoperability testing", which is made more explicit by ISO/IEC (2023a). Includes both "different hardware and software facilities" and "different versions or releases" (Washizaki, 2024, p. 5-9). Likely has two subtypes: "downward compatibility testing" (implied by IEEE, 2017, p. 147) and "upward compatibility testing" (implied by IEEE, 2017, p. 492)
Complete Regression Testing (Firesmith, 2015, p. 34) | Approach |  | Regression Testing (Firesmith, 2015, p. 34) |  | 
Compliance Testing | Type (implied by its quality (IEEE, 2017, p. 82; Hamburg and Mogyorodi, 2024)) | Testing that "validates" (Firesmith, 2015, p. 33) the "adherance of [the test item] … to standards, conventions or regulations in laws and similar prescriptions" (Hamburg and Mogyorodi, 2024; OG IREB Glossary; similar in Firesmith, 2015, p. 33) usually "forced by an external regulatory body" (Washizaki, 2024, p. 5-8) |  | Regulatory-Compliance Testing (Firesmith, 2015, p. 33), Regulation Testing (Kam, 2008, p. 47), Standards Testing (Kam, 2008, p. 48) | "Audits are often used to verify compliance with standards" (IEEE, 2022, p. 44)
Component Integration Testing | Level (IEEE, 2017, p. 467; Hamburg and Mogyorodi, 2024; inferred from integration testing) | "Testing of groups of related components" (IEEE, 2017, p. 82) or "integration testing of components" (Hamburg and Mogyorodi, 2024) "performed to expose defects in the interfaces and interaction between [them]" (Kam, 2008, p. 43) | Integration Testing (Hamburg and Mogyorodi, 2024) | Module Integration Testing, Unit Integration Testing (Hamburg and Mogyorodi, 2024), Link Testing? (Kam, 2008, p. 45) | Difference between this, integration testing, and unit testing?
Concrete Execution (Doğan et al., 2014, p. 192) | Technique (inferred from symbolic execution) |  | Static Testing? |  | Related to symbolic execution (Doğan et al., 2014, p. 192)
Concurrency Testing | Approach | "Testing to determine how the occurrence of two or more activities within the same interval of time, achieved either by interleaving the activities or by simultaneous execution, is handled" (Kam, 2008, p. 43) | Performance Testing (Gerrard, 2000b, p. 23) |  | Can find "obscure bugs" "over extended periods" (Gerrard, 2000b, p. 23)
Condition Testing | Technique (Hamburg and Mogyorodi, 2024) | Testing "in which test conditions are outcomes of atomic conditions" (Hamburg and Mogyorodi, 2024) | Structure-based Testing (Hamburg and Mogyorodi, 2024; Sharma et al., 2021, Fig. 1), Control Flow Testing (Firesmith, 2015, p. 49), Decision Testing? | Decision Testing (Washizaki, 2024, p. 5-13) | Hamburg and Mogyorodi (2024) make the distinction that this only involves atomic conditions, but Washizaki (2024, p. 5-13) doesn't, considering these two terms to be synonyms
Configuration Testing | Type (implied by Firesmith, 2015, p. 53) | Testing that "verifies the software under specified configurations" (Washizaki, 2024, p. 5-10), or "arrangement[s] … defined by … its constituent parts[,] … requirements, design, and[/or] implementation" (IEEE, 2017, p. 90), when it "is built to serve different users" (Washizaki, 2024, p. 5-10) | Non-functional Testing (Gerrard, 2000a, Tab. 2; 2000b, Tab. 1, p. 20), Smoke Testing, Dynamic Testing (2000a, Tab. 2; 2000b, Tab. 1), Data Center Testing (Firesmith, 2015, p. 24), Combinatorial Testing (can be; IEEE, 2021, p. 15), Developer Testing (can be) (Gerrard, 2000a, p. 11) | Portability Testing (implied by Kam, 2008, p. 43) | Can be done by an audit (IEEE, 2017, p. 90). For web application testing, this includes combinations of OS platforms, network connections, commercial services, and browsers (Gerrard, 2000b, p. 20)
Conformance Testing (Washizaki, 2024, p. 5-7; Jard et al., 1999, p. 25; implied by IEEE, 2017, p. 93) | Type (implied by its quality (IEEE, 2017, p. 92; OG PMBOK 5th ed.)) | Testing that "aims to verify that the SUT conforms to standards, rules, specifications, requirements, design, processes, or practices" (Washizaki, 2024, p. 5-7) or that evaluates the degree to which "results … fall within the limits that define acceptable variation for a quality requirement" (IEEE, 2017, p. 92; OG PMBOK 5th ed.) "to obtain the conviction that its [the SUT's] behaviour conforms with its specification" (Jard et al., 1999, p. 25) "in its test environment" (p. 26; OG [4]) | Formal Testing (can be; Jard et al., 1999, pp. 25-26) | Correctness Testing? | Related to functional testing (Washizaki, 2024, p. 5-7) and may be contrasted with nonconformity (IEEE, 2017, p. 292)
Consistency Testing (Firesmith, 2015, p. 53) | Type (implied by Firesmith, 2015, p. 53) | Testing the "degree of uniformity, standardization, and freedom from contradiction" (IEEE, 2017, p. 94) |  |  | Content consistency testing is possibly a subapproach (see IEEE, 2017, p. 96). Related to traceability testing (IEEE, 2017, p. 94)
Construction Testing | Approach | Testing that "aims to reduce the gap between when faults are inserted into the code and when those faults are detected, thereby reducing the cost incurred to fix them" (Washizaki, 2024, p. 4-7) |  |  | "Involves two forms of testing, which are often performed by the software engineer who wrote the code: unit testing and integration testing", but not "more specialized testing" (Washizaki, 2024, p. 4-7). IEEE (2017, p. 95) defines a process just called "construction" that includes unit testing (but not integration testing). See also IEEE Standard 829-1998 and IEEE Standard 1008-1987
Content Checking | Approach | Testing "the content of Web pages … [for] accuracy, completeness, consistency, spelling[, and] … accessibility" (Gerrard, 2000a, p. 3) | Usability Testing, Static Testing (Gerrard, 2000a, Tab. 2; 2000b, Tab. 1, p. 3), Desktop Development Testing (2000a, Tab. 2; 2000b, Tab. 1), Web Application Testing, Gray-Box Testing? (Patton, 2006, p. 220) |  | Difference between this and content usage testing?
Content Usage Testing (Firesmith, 2015, p. 58) | Type (implied by Firesmith, 2015, p. 58) |  | Usability Testing (Firesmith, 2015, p. 58) |  | Difference between this and content checking?
Continuous Testing | Practice (Washizaki, 2024, p. 6-13); Approach (Hamburg and Mogyorodi, 2024); Process? | Testing "started via an automated process that can occur on-demand" (IEEE, 2022, p. 35) "that involves testing the software at every stage of the software development life cycle" (Washizaki, 2024, p. 6-13) "to obtain feedback … as rapidly as possible" (Hamburg and Mogyorodi, 2024) | Automated Testing (IEEE, 2022, p. 35; Hamburg and Mogyorodi, 2024), Lifecycle-based Testing (Firesmith, 2015, p. 29), Developer Testing (can be) (Gerrard, 2000a, p. 11) | CT (Firesmith, 2015, p. 29) | Involves testing early (IEEE, 2022, p. 35; Washizaki, 2024, p. 6-13; Hamburg and Mogyorodi, 2024), often (Washizaki, 2024, p. 6-13; Hamburg and Mogyorodi, 2024), and everywhere (Hamburg and Mogyorodi, 2024), and ideally employs "prioritization", the process of "defin[ing] a test execution order according to some criteria" (Washizaki, 2024, p. 5-4), so that time isn't wasted on lower priority tests. Difficult to do alongside "geographically distributed development" (Sangwan and LaPlante, 2006, p. 27)
Contractual Acceptance Testing | Level (Firesmith, 2015, p. 30; inferred from acceptance testing) | "Acceptance testing performed to verify whether a system satisfies its contractual requirements" (Hamburg and Mogyorodi, 2024) | Acceptance Testing (Hamburg and Mogyorodi, 2024; Firesmith, 2015, p. 30) | Contract Acceptance Testing, CAT (conflicts with "customer AT") (Firesmith, 2015, p. 30) | 
Control Flow Analysis | Approach | "Analysis based on a representation of unique paths for executing a component or system" (Hamburg and Mogyorodi, 2024) | Static Analysis (Hamburg and Mogyorodi, 2024) |  | 
Control Flow Testing | Technique (Washizaki, 2024, p. 5-13) | Testing that "covers all" of a particular subdivision of code (Washizaki, 2024, p. 5-13), namely the "sequence in which operations are performed during … execution" (IEEE, 2017, p. 101; OG IEEE, 2015) | Structure-based Testing (Washizaki, 2024, p. 5-13), Model-based Testing (IEEE, 2022, p. 13; 2021, pp. 6, 10; implied by Doğan et al., 2014, p. 179), (with its sub-techniques) Web Application Testing (Doğan et al., 2014, p. 179) |  | "The adequacy of such tests is measured in percentages" and can also be performed on "blocks of statements[] or specific combinations of statements" (Washizaki, 2024, p. 5-13); would these be a different testing type? Related to data flow testing? (IEEE, 2017, p. 101)
Control System Testing? (Forsyth et al., 2004) | Approach | Testing of "system[s] which respond[] to input signals from parts of machine elements, operators, external control equipment or any combination of these and generate[] output signals causing the machine to behave in the intended manner" (ISO, 2015) | System Testing, Domain-Specific Testing? | Machine Control System Testing (implied by ISO, 2022) | Often performed using "real time simulators", which requires "large amounts of flexible, accurate, high speed I/O" (Forsyth et al., 2004, pp. 332-333). Can be performed "at the manufacturer's facility [or] … where the equipment is integrated in the actual power system" (p. 333)
Conversion Testing | Type (IEEE, 2022, p. 22) | Testing that verifies that the software can be modified "to enable it to operate with similar functional capability in a different environment" (IEEE, 2017, p. 103), for example, "in replacement systems" (Kam, 2008, p. 43) | Portability Testing? | Migration Testing? (Kam, 2008, p. 46) | 
Cookie Testing | Approach | Testing based on the use of cookies to "get [a]round the stateless nature of the web and how this might be subverted" (Gerrard, 2000b, p. 18), such as by "crack[ing] the password algorithm" (pp. 28-29) | Penetration Testing (Gerrard, 2000b, p. 28), Web Application Testing |  | 
Correctness Testing (Firesmith, 2015, p. 53) | Type (implied by its quality (IEEE, 2017, p. 104; Washizaki, 2024, p. 3-13) and by Firesmith, 2015, p. 53) | Testing the "degree to which a system or component is free from faults in its specification, design, and implementation[,] … meet[s] specified requirements[, or] … meet[s] user needs and expectations" (IEEE, 2017, p. 104) | Functional Suitability Testing (ISO/IEC, 2023a) | Functional Testing? (Washizaki, 2024, p. 5-7) | Synonym for "conformance"? Related to functional testing (Washizaki, 2024, p. 5-7)
COTS Testing (Firesmith, 2015, p. 34) | Approach |  | Reuse Testing (Firesmith, 2015, p. 34) | Commercial Off-the-Shelf Testing (Hamburg and Mogyorodi, 2024) | 
COTS Vendor Testing (Firesmith, 2015, p. 37) | Practice? |  | Development Organization Testing (Firesmith, 2015, p. 37), COTS Testing |  | 
Cross-Browser Compatibility Testing (Doğan et al., 2014, Tab. 8) | Approach | Testing the "appearance and behavior" of a website "in different browsers" (Choudhary et al., 2010, p. 1) | Web Application Testing (Doğan et al., 2014, Tabs. 8, 22), UI Testing, Functionality Testing (Choudhary et al., 2010, p. 1), Automated Testing (Gerrard, 2000a, Tab. 2; 2000b, Tab. 1; Choudhary et al., 2010, p. 3), Back-to-Back Testing, Differential Assertion Checking (implied by p. 1), Regression Testing (can be) (Tab. 1), Manual Testing (often) (pp. 1, 5-6), Developer Testing (Gerrard, 2000a, p. 11), Fault-based Testing (implied by Doğan et al., 2014, pp. 195-196), Configuration Testing (implied by Gerrard, 2000a, p. 11), Compatibility Testing | Cross-Browser Compliance Testing (implied by Choudhary et al., 2010, p. 1), Browser Syntax Compatibility (Testing?) (implied by Gerrard, 2000b, p. 5) | "Issues range from simple cosmetic problems in the user interface to critical functionality failures" and "are observed on the client side" (Choudhary et al., 2010, p. 1). Can be performed based on structural and/or visual analysis (p. 2) and using multiple platforms, browsers, and/or version (p. 3)
Crowd Testing | Approach (Hamburg and Mogyorodi, 2024) | Testing performed by "a large group of testers" (Hamburg and Mogyorodi, 2024) |  |  | 
Customer Acceptance Testing (Firesmith, 2015, p. 30) | Level (Firesmith, 2015, p. 30; inferred from acceptance testing) |  | Acceptance Testing (Firesmith, 2015, p. 30) | CAT (conflicts with "contract(ual) AT") (Firesmith, 2015, p. 30) | 
Dark Launches | Technique (Washizaki, 2024, p. 6-5) |  |  |  | A method for "testing the software in the production system context" which "can be particularly challenging" (Washizaki, 2024, p. 6-5)
Data Center Testing (Firesmith, 2015, p. 24) | Level (inferred from operational testing) |  | Operational Testing (Firesmith, 2015, p. 30) |  | 
Data Dependence Transition Relation Testing (Doğan et al., 2014, Tab. 13; OG Peng and Lu, 2011) | Approach |  | Web Application Testing (Doğan et al., 2014, Tab. 13), Data-driven Testing? |  | 
Data Flow Analysis | Approach | "Analysis based on the lifecycle of variables" (Hamburg and Mogyorodi, 2024) | Static Analysis (Hamburg and Mogyorodi, 2024) |  | 
Data Flow Testing | Technique (IEEE, 2022, p. 22; 2021, p. 3, Fig. 2; Washizaki, 2024, p. 5-13; Kam, 2008, p. 43), Practice? (since it is a "class of … techniques" (IEEE, 2021, p. 3); see notes) | Control flow testing with additional "information about how the variables are defined, used, and killed" (Washizaki, 2024, p. 5-13) "based on exercising definition-use pairs" (IEEE, 2021, p. 3) | Structure-based Testing (IEEE, 2022, p. 22; 2021, p. 3, Fig. 2; Kam, 2008, p. 43), Web Application Testing (Doğan et al., 2014, p. 179; can be in Kam, 2008, pp. 16-17), Control Flow Testing (implied by Washizaki, 2024, p. 5-13; IEEE, 2017, p. 101?), Model-based testing (implied by Doğan et al., 2014, p. 179) |  | May involve data flow analysis or "data analysis". See Patton (2006, p. 114) and van Vliet (2000, pp. 424-425)
Data Integrity Testing | Approach | "Testing the methods and processes used to access and manage the data and to ensure access methods, processes and data rules function as expected" (Kam, 2008, p. 44) |  |  | 
Data Migration Testing (Firesmith, 2015, p. 53) | Type (implied by Firesmith, 2015, p. 53) |  | Correctness Testing (Firesmith, 2015, p. 53), Data Integrity Testing?, Database Admin Testing? |  | 
Database Admin Testing (Firesmith, 2015, p. 39) | Practice? |  | Operator Testing (Firesmith, 2015, p. 39) |  | 
Database Coverage Testing? (Doğan et al., 2014, Tab. 13) | Technique? (inferred from control flow testing) |  | Web Application Testing (Doğan et al., 2014, Tab. 13), Control Flow Testing? |  | Includes page access, SQL statement, and server environment variable testing (Doğan et al., 2014, Tab. 13; OG Alalfi et al., 2010)
Database Integrity Testing | Approach | Data integrity testing where data is stored in a database that also ensures "that during access to the database, data is not corrupted or unexpectedly deleted, updated or created" (Kam, 2008, p. 44) | Web Application Testing (implied by Kam, 2008, p. 9), Data Integrity Testing? |  | 
Data-driven Testing | Practice (IEEE, 2022, p. 22), Technique (Kam, 2008, p. 43; OG Fewster and Graham) | Testing "that uses data files to contain the test data [including "test input" (Kam, 2008, p. 43)] and expected results needed to execute the test scripts" (Hamburg and Mogyorodi, 2024) | Automated Testing (IEEE, 2022, pp. 22, 35; Firesmith, 2015, p. 44; implied by Hamburg and Mogyorodi, 2024), Scripted Testing (Kam, 2008, p. 43) | Sometimes spelled without a hyphen (Kam, 2008, p. 43) | Similar to keyword-driven testing (Hamburg and Mogyorodi, 2024). Can be used to support "test execution tools such as capture/playback tools" (Kam, 2008, p. 43)
Decision Condition Testing | Technique (Kam, 2008, p. 44) | Testing "in which test cases are designed to execute condition outcomes and decision outcomes" (Kam, 2008, p. 44) | Specification-based Testing (Kam, 2008, p. 44) |  | 
Decision Table Testing | Technique (IEEE, 2022, pp. 4, 22; 2021, p. 3, Fig. 2; Washizaki, 2024, p. 5-11; Hamburg and Mogyorodi, 2024) | Testing "based on exercising decision rules in a decision table" (IEEE, 2022, p. 4; 2021, p. 3; similar on p. 18 and in Hamburg and Mogyorodi, 2024) "by considering every possible combination of conditions and their corresponding resultant actions" (Washizaki, 2024, p. 5-11) | Specification-based Testing (IEEE, 2022, pp. 4, 22; 2021, p. 3, Fig. 2; Washizaki, 2024, p. 5-11; Hamburg and Mogyorodi, 2024; Sharma et al., 2021, Fig. 1; Firesmith, 2015, p. 47), Model-based Testing (IEEE, 2022, p. 13; 2021, pp. 6, 18; Bourque and Fairley, 2014, p. 4-10) |  | Any "infeasible decision rules … do not need to be covered during testing" (IEEE, 2021, p. 18). Related to cause-effect graphing (Washizaki, 2024, p. 5-11). See BS 7925-2; Myers 1979; Peters and Pedrycz, 2000, pp. 448, 450-453
Decision Testing | Technique (IEEE, 2022, pp. 4, 22; 2021, p. 3, Fig. 2; Washizaki, 2024, p. 5-13; Hamburg and Mogyorodi, 2024) | Testing "based on exercising decision outcomes in the control flow of the test item" (IEEE, 2022, p. 4; 2021, p. 3; similar in Hamburg and Mogyorodi, 2024) | Structure-based Testing (IEEE, 2022, pp. 4, 22; 2021, p. 3, Fig. 2; Hamburg and Mogyorodi, 2024; Sharma et al., 2021, Fig. 1), Control Flow Testing (IEEE, 2022, p. 4; 2021, p. 3; Washizaki, 2024, p. 5-13), Decision Condition Testing (implied by Kam, 2008, p. 44) | Condition Testing (Washizaki, 2024, p. 5-13) | 
Defect-based Testing | Technique (Hamburg and Mogyorodi, 2024) | Testing "in which test cases are developed from what is known about a specific defect type" (Hamburg and Mogyorodi, 2024) | Fault-Based Testing? |  | Related to the idea of a "defect taxonomy" (Hamburg and Mogyorodi, 2024)
Denial of Service | Approach | "Security attack[s] … intended to overload the system with requests such that legitimate requests cannot be serviced" (Hamburg and Mogyorodi, 2024) | Security Attacks (Hamburg and Mogyorodi, 2024), Stress Testing? | DoS (Hamburg and Mogyorodi, 2024) | 
Design-based Testing | Technique? | Testing "in which test cases are designed based on the architecture and/or detailed design of a component or system" (Kam, 2008, p. 44) |  |  | 
Design-driven Testing | Approach | Testing that "verifies" the "system conforms to [the specified] design" (Firesmith, 2015, p. 33) |  |  | 
Desk Checking | Technique (IEEE, 2017, p. 133) | A "manual simulation of program execution" or visual examination of code listings, test results, or other documentation to "detect faults" and " identify errors" (IEEE, 2017, p. 133; OG ISO/IEC 2015) |  |  | Related to inspections and walkthroughs (IEEE, 2017, p. 133)
Desktop Development Testing | Approach, Level? (Gerrard, 2000a, p. 13) | Testing of web-based applications that focuses on, "broadly, what the browser executes" (Gerrard, 2000a, p. 13) | Web Application Testing, Development Testing? |  | 
Deterministic Testing? | Technique? (implied by Washizaki, 2024, p. 5-16) |  |  |  | In contrast to random testing; it is unclear if this is an actual test approach or simply a method for selecting input data, etc. for tests (Washizaki, 2024, p. 5-16)
Dev/Sec/Ops Testing? (implied by Dev/Sec/Ops (Washizaki, 2024, p. 9-5) and DevOps testing (Firesmith, 2015, p. 29)) | Practice? | DevOps testing that "applies security at all phases of the software life cycle", including in the testing phase (Washizaki, 2024, p. 9-5) | DevOps Testing, Security Testing, Agile Testing, Shift-Left Testing (Washizaki, 2024, p. 9-5), Continuous Testing, Automated Testing (Washizaki, 2024, p. 9-5; implied by DevOps testing) |  | 
Developer Testing (Firesmith, 2015, p. 39; Gerrard, 2000a, p. 11) | Practice? | Testing tied to "developer code check-in/check-out procedures" (Gerrard, 2000a, p. 11) | Development Testing (IEEE, 2017, p. 136), Role-based Testing (Firesmith, 2015, p. 39) |  | See Extreme Programming Explained by Kent Beck
Development Environment Testing (Firesmith, 2015, p. 25) | Technique? |  | Development Testing? (Gerrard, 2000a, p. 11) |  | 
Development Organization Testing (Firesmith, 2015, p. 37) | Practice? |  | Organization-based Testing (Firesmith, 2015, p. 37), Development Testing |  | 
Development Testing | Level? Stage? | "Testing conducted during the development of a system or component, usually in the development environment by the developer … to establish whether … [it] satisfies its criteria" (IEEE, 2017, p. 136) |  | Developmental Testing (DT)? (Firesmith, 2015, p. 30) | The secondary definition, "testing conducted to establish whether a new software product or software-based system (or components of it) satisfies its criteria" (IEEE, 2017, p. 136), seems to overlap with acceptance testing. Can be used to generate test cases for regression testing (Gerrard, 2000a, p. 11); is this sufficient for a "parent" relation? There are "[m]any [t]ypes" (Firesmith, 2015, p. 30), but no examples are given
Development Tool Testing (Firesmith, 2015, p. 25) | Technique? |  | Development Testing? |  | 
Device-based Testing | Practice? | "Testing in which test suites are executed on physical or virtual devices" (Hamburg and Mogyorodi, 2024) |  |  | 
DevOps Testing (Firesmith, 2015, p. 29) | Practice? | Testing performed in the context of DevOps: a "set of principles and practices … for … specifying, developing, and operating software and systems products and services, and continuous improvements in all aspects of the life cycle" (Washizaki, 2024, p. 10-7; OG [11]) | Continuous Testing (Firesmith, 2015, p. 29; implied by Washizaki, 2024, pp. 10-7 (OG [11]), 11-11), Automated Testing (implied by Washizaki, 2024, p. 11-11) |  | 
Differential Assertion Checking (DAC) (Lahiri et al., 2013) | Practice? | The "checking [of] two versions of a program with respect to a set of assertions" to see if there is "an environment in which [one version] passes but [another version] fails" (Lahiri et al., 2013, p. 345) | Assertion Checking, Relative Correctness Testing (if it exists) (Lahiri et al., 2013, p. 345), Regression Testing (Lahiri et al., 2013, p. 346), Back-to-Back Testing? |  | 
Disaster/Recovery Testing (or Disaster Recovery Testing (implied by Washizaki, 2024, p. 6-8; IEEE, 2013, p. 20)) | Type (IEEE, 2022, p. 22) | Testing to determine the degree to which a system can "return to normal operation after a hardware or software failure " (IEEE, 2017, p. 140) |  |  | "Requires stopping the service, identifying the checkpoint state and triggering the failover process"; "should be constantly rehearsed as changes to the production environment are made" (Washizaki, 2024, p. 6-8). Difference between this and recovery testing (in the context of performance)?
Distributed Testing (Firesmith, 2015, p. 42) | Approach |  |  |  | 
DOM Testing | Technique (Bajammal and Mesbah, 2018, p. 199) | The "use [of] a browser automation tool… to make assertions on the DOM (Document Object Model) of the webpage" (Bajammal and Mesbah, 2018, p. 193), such as the presence of certain elements and their properties and hierarchy (p. 199) | Web Application Testing (Bajammal and Mesbah, 2018, p. 193), Model-based Testing (implied by Doğan et al., 2014, p. 179) |  | Cannot be used for canvas elements (Bajammal and Mesbah, 2018, p. 193), although their visual information may be able to be "represented as an augmented DOM inside the canvas element" (Bajammal and Mesbah, 2018), which may be used to support test-driven development (p. 199)
Domain Analysis? | Approach? | "A combination of equivalence partitioning and boundary value analysis" (IEEE, 2021, p. 11; OG Beizer 1995) | Equivalence Partitioning, Boundary Value Analysis (IEEE, 2021, p. 11; OG Beizer 1995) |  | See Beizer 1995
Domain-Based Testing (Firesmith, 2015, p. 26) | Technique? |  |  |  | 
Domain-Independent Testing (Firesmith, 2015, p. 26) | Technique? |  | Domain-Based Testing (Firesmith, 2015, p. 26) |  | There are "[m]any [t]ypes" (Firesmith, 2015, p. 26), but no examples are given
Domain-Specific Testing (Firesmith, 2015, p. 26) | Technique? |  | Domain-Based Testing (Firesmith, 2015, p. 26) |  | All examples given by Firesmith (2015, p. 26) are focused on hardware, but this might not be representative
DT Organization Testing (Firesmith, 2015, p. 37) | Practice? |  | Independent Test Organization Testing (Firesmith, 2015, p. 37), Developmental Testing? (Firesmith, 2015, p. 30) |  | 
Dynamic Analysis | Approach | The "process of evaluating a system or component based on its behavior during execution" (IEEE, 2017, p. 149) | Dynamic Testing? (implied by their static counterparts in IEEE, 2022, pp. 9, 17, 25, 28 and Hamburg and Mogyorodi, 2024) |  | This definition seems vague, but may have a similar relation to "dynamic testing" as between the static counterparts
Dynamic Testing | Approach | "Testing in which a test item is evaluated by executing it" (IEEE, 2022, p. 4) | V-Model Testing, W-Model Testing (Gerrard, 2000a, p. 9) | Dynamic Analysis? (IEEE, 2017, p. 149) | Can "only occur in the parts of the life cycle when executable code is available" (IEEE, 2022, p. 18)
Each Choice Testing | Technique (IEEE, 2022, p. 22; 2021, p. 2, Fig. 2) | Testing that covers enough P-V pairs so that "each parameter value is included at least once" (IEEE, 2021, p. 17) | Combinatorial Testing (IEEE, 2022, p. 22; 2021, pp. 2, 17, Fig. 2), t-wise Testing | 1-wise Testing (IEEE, 2021, p. 17) | "The minimum number of test cases required to achieve 100% … [coverage is] the maximum number of values any one of the test item parameters can take" (IEEE, 2021, p. 17). See Grindal et al., 2005
Efficiency Testing (Kam, 2008, p. 44) | Type (implied by its quality (IEEE, 2017, p. 154; Hamburg and Mogyorodi, 2024)) | Testing that evaluates the "degree to which a system or component performs its designated functions with minimum consumption of resources" (IEEE, 2017, p. 154) or "the degree to which resources are expended in relation to results achieved" (Hamburg and Mogyorodi, 2024) |  |  | Has the following subcategories: "execution" and "storage" (IEEE, 2017, p. 154). Related to effectiveness testing (if it exists) (Hamburg and Mogyorodi, 2024). See the IREB Glossary
Elasticity Testing | Approach | Testing that "assesses the ability of the SUT … to rapidly expand or shrink compute, memory, and storage resources without compromising the capacity to meet peak utilization" (Washizaki, 2024, p. 5-9) | Non-functional Testing (Washizaki, 2024, p. 5-9) |  | Some objectives are "to control behaviors, to identify the resources to be (un)allocated, to coordinate events in parallel, and to evaluate scalability" (Washizaki, 2024, p. 5-9); the last one seems like it should be under scalability testing?
Elementary Comparison Testing | Technique (Kam, 2008, p. 44) | Testing "in which test cases are designed to execute combinations of inputs using the concept of condition determination coverage" (Kam, 2008, p. 44) | Specification-based Testing (Kam, 2008, p. 44), Comparison Testing? |  | 
Embedded Tester Testing (Firesmith, 2015, p. 39) | Practice? |  | Tester Testing (Firesmith, 2015, p. 39) |  | 
Encryption Testing (Firesmith, 2015, p. 57) | Type (implied by Firesmith, 2015, p. 57) |  | Security Testing (Firesmith, 2015, p. 57) |  | 
End-to-end Functionality Testing | Approach |  | Smoke Testing, Dynamic Testing, Systems Integration Testing (Gerrard, 2000a, Tab. 2; 2000b, Tab. 1), Acceptance Testing (2000b, p. 31), Scenario-based Testing (implied by 2000b, p. 31), Functionality Testing, End-to-end Testing | Spelled without hyphens by Gerrard (2000a, Tab. 2; 2000b, Tab. 1), but they were added for consistency | 
End-to-end Testing | Level?, Type (Hamburg and Mogyorodi, 2024), Technique? (inferred from specification-based testing) | Testing "in which business processes are tested from start to finish under production-like circumstances" (Hamburg and Mogyorodi, 2024) | Integration Testing (Sharma et al., 2021, p. 603), Specification-based Testing (Firesmith, 2015, p. 47), Operational (Acceptance) Testing? | E2E Testing (Hamburg and Mogyorodi, 2024) | Ambiguous: does this test the business processes or the system?
Endurance Testing | Type (IEEE, 2013, p. 2; implied by Firesmith, 2015, p. 55) | "Testing conducted to evaluate whether a test item can sustain a required ["significant" (Hamburg and Mogyorodi, 2024)] load continuously for a specified period of time" (IEEE, 2013, p. 2; similar in Hamburg and Mogyorodi, 2024) "within the system's operational context" (Hamburg and Mogyorodi, 2024) | Performance Efficiency Testing (IEEE, 2013, p. 2), Reliability Testing (Firesmith, 2015, p. 55) |  | 
Equivalence Checking (Lahiri et al., 2013, p. 345) | Technique? | Verifying the "semantic equivalence" between "previous versions of an evolving program …  to ensure the correctness of [a] transformation", such as refactoring (Lahiri et al., 2013, p. 345; OG [25], [12], [19]) | Incremental Verification (by "carrying over invariants that are unaffected by the syntactic changes" (Lahiri et al., 2013, p. 345; OG [28]); requires the original to "not have any false warnings") (Lahiri et al., 2013, p. 345), Relative Correctness Testing (if it exists) (Lahiri et al., 2013, p. 354), Regression Testing? |  | "Applicable in very limited contexts … since most software changes … induce some behavioral change" (Lahiri et al., 2013, p. 345)
Equivalence Partitioning | Technique (IEEE, 2022, pp. 4, 20, 22; 2021, pp. 4, 8, Fig. 2; 2013, p. 3; Washizaki, 2024, p. 5-11) | Testing "designed to exercise equivalence partitions by using one or more [arbitrary (IEEE, 2021, p. 11)] representative members of each partition" (2022, p. 4; 2021, p. 4; 2013, p. 3) "based on a specified criterion or relation" to create "a representative test suite" (Washizaki, 2024, p. 5-11) | Specification-based Testing (IEEE, 2022, p. 22; 2021, p. 4, Fig. 2; Washizaki, 2024, p. 5-11; Hamburg and Mogyorodi, 2024; Sharma et al., 2021, Fig. 1), Model-based Testing (IEEE, 2022, p. 13; 2021, p. 6, 10), Negative Testing (IEEE, 2021, pp. 10-11), Positive Testing (p. 11), One-to-One Testing, Minimized Testing (can be; p. 11; OG BS 7925-2; Myers 1979), Usability Testing, Classification Tree Method? (can be; p. 10), Gray-Box Testing (Firesmith, 2015, p. 48), Dynamic Testing, W-Model Testing (Gerrard, 2000a, Fig. 5), Functional Testing? (IEEE, 2022, p. 20) | Equivalence Classing (although this sometimes has a bit different of a definition; see IEEE, 2021; p. 10; 2017, p. 164) (Patton, 2006, p. 67; implied by IEEE, 2022, p. 4; 2021, p. 4), Partition Testing (Hamburg and Mogyorodi, 2024; OG Beizer), Equivalence Testing? (Sharma et al., 2021, Fig. 1) | 
Ergonomics Testing | Approach | "Testing to determine whether a component or system and its input devices are being used properly with correct posture" (Hamburg and Mogyorodi, 2024) |  |  | Does this test the system or its use?
Error Guessing | Technique (IEEE, 2022, pp. 4, 22, 34; 2021, pp. 4, 11, Fig. 2; 2013, p. 3; Washizaki, 2024, p. 5-13) | Testing based on "the tester's knowledge of past failures, or general knowledge of failure modes" (IEEE, 2022, p. 4; 2013, p. 3) "to anticipate the most plausible faults in each SUT" (Washizaki, 2024, p. 5-13) | Experience-based Testing (IEEE, 2022, pp. 4, 22; 2021, pp. 4, 11, Fig. 2; Washizaki, 2024, p. 5-13; Hamburg and Mogyorodi, 2024; Sharma et al., 2021, Fig. 1; Firesmith, 2015, p. 50), Fault-based Testing (Bourque and Fairley, 2014, p. 4-9) | Error Guessing Testing? (Firesmith, 2015, p. 50) | See Patton (2006, pp. 88-89)
Error Seeding | Practice? | The "process of intentionally adding known faults to those already in a computer program … [to] estimat[e] the number of faults remaining" (IEEE, 2017, p. 165) |  | Fault Seeding (IEEE, 2017, p. 165; van Vliet, 2000, p. 427), Bug Seeding (IEEE, 2017, p. 165), Bebugging (Hamburg and Mogyorodi, 2024) | See van Vliet (2000, pp. 427-428). Also mentioned by Firesmith (2015, p. 34)
Error Tolerance Testing (Firesmith, 2015, p. 56) | Type (implied by its quality (IEEE, 2017, p. 166) and by Firesmith, 2015, p. 56) | Testing the "ability of a system or component to continue normal operation despite the presence of erroneous inputs" (IEEE, 2017, p. 166) "that should be rejected" (Kam, 2008, p. 45) | Robustness Testing (Firesmith, 2015, p. 56) | Invalid Testing (Kam, 2008, p. 45) | Related to fault tolerance testing and robustness testing (IEEE, 2017, p. 166)
Event Space Testing | Technique? (inferred from control flow testing) | Testing that aims to maximize the "number of events in the GUI space of the SUT exercised by [the] test suite" (Doğan et al., 2014, Tab. 13; OG Saxena et al., 2010) | Web Application Testing (Doğan et al., 2014, Tab. 13), GUI Testing, Control Flow Testing? | All-Events Testing? (Doğan et al., 2014, Tab. 13; OG Mansour and Houri, 2006) | 
Evidence-based Testing | Technique (Washizaki, 2024, p. 5-12) | Testing that "follows a rigorous research approach", including "identifying" and "critically analyzing the evidence in light of the problem" (Washizaki, 2024, p. 5-12) | Specification-based Testing (Washizaki, 2024, p. 5-12) |  | "Evidence-based software engineering (EBSE) … is the _best_ solution for a practical problem" (Washizaki, 2024, p. 5-12); related to experience-based testing?
Exhaustive Testing  | Approach (IEEE, 2022, p. 4; Hamburg and Mogyorodi, 2024) | Testing "in which all combinations of input values and preconditions are tested" (IEEE, 2022, p. 4; similar to Hamburg and Mogyorodi, 2024) | Dynamic Testing (IEEE, 2022, p. 18) | Complete Testing (Hamburg and Mogyorodi, 2024; Kam, 2008, p. 6) | Impossible in most non-trivial situations (IEEE, 2022, p. 4; Washizaki, 2024, p. 5-5; van Vliet, 2000, p. 421; Peters and Pedrycz, 2000, pp. 439, 461)
Experience-based Testing | Practice (IEEE, 2022, p. 22; 2021, p. viii), Technique (Firesmith, 2015, p. 46) | Testing based on testers' experience (IEEE, 2022, p. 4; 2021, p. 4; Hamburg and Mogyorodi, 2024), knowledge, and intuition (Washizaki, 2024, p. 5-13; Hamburg and Mogyorodi, 2024), as well as the SUT's context (Washizaki, 2024, p. 5-13) | Dynamic Testing (IEEE, 2022, p. 17; Sharma et al., 2021, Fig. 1), Unscripted Testing (often) (IEEE, 2022, p. 34) | Sometimes spelled without a hyphen (Sharma et al., 2021, Fig. 1) | "Can include concepts such as test attacks, tours, and error taxonomies" and can "target … security, performance, and other quality areas" (IEEE, 2022, p. 4; 2021, p. 4). See Patton (2006, pp. 88-89)
Expert Usability Reviews | Approach | "Informal usability review[s] in which the reviewers are … usability experts [and/]or subject matter experts" (Hamburg and Mogyorodi, 2024) | Informal Testing, Usability Testing, Reviews (Hamburg and Mogyorodi, 2024) |  | 
Exploratory Testing | Practice (IEEE, 2022, pp. 20, 22, 34; 2021, p. viii) | "Simultaneous learning, test design and test execution" (Washizaki, 2024, p. 5-14; similar in Hamburg and Mogyorodi, 2024) that is "spontaneous" and aims to find "hidden properties" that "can interfere with other properties of the software under test" (IEEE, 2022, p. 5; 2013, p. 3) | Experience-based Testing (IEEE, 2022, p. 5; 2021, p. viii; 2013, p. 3; Washizaki, 2024, p. 5-14; Sharma et al., 2021, Fig. 1; Firesmith, 2015, p. 50); Unscripted Testing (IEEE, 2022, p. 33; 2017, p. 174; Firesmith, 2015, p. 45; implied by Washizaki, 2024, p. 5-14), Informal Testing (Kam, 2008, p. 44) |  | "Test cases are not defined in advance but are dynamically designed, executed, and modified according to the collected evidence" (Washizaki, 2024, p. 5-14), but this process is often structured with "session sheets", which are also "used to capture information about what was tested, and any anomalous behaviour observed" (2022, p. 33), or "test charters" (Hamburg and Mogyorodi, 2024). Patton says this is used when a specification is not available to determine and test the software's features (2006, p. 65). "Widely used in shift-left development (such as Agile)" (Washizaki, 2024, p. 5-14). See Whittaker (2010)
Extended Entry Table Testing | Technique (inferred from decision table testing and IEEE, 2021, p. 18) | Testing "based on exercising decision rules" (IEEE, 2022, p. 4) in an extended entry table (2021, p. 18; 2017, p. 175; OG ISO, 1984) | Decision Table Testing (IEEE, 2021, p. 18; 2017, p. 175; OG ISO, 1984), Equivalence Partitioning (IEEE, 2021, p. 18) |  | 
External Links Integration (Testing) (Gerrard, 2000a, Tab. 2; 2000b, Tab. 1) | Level (inferred from integration testing) |  | Functional Testing, Dynamic Testing, Large Scale Integration Testing (Gerrard, 2000a, Tab. 2; 2000b, Tab. 1), Integration Testing, Web Application Testing |  | 
Extreme Value Analysis (implied by Kam, 2008, p. 7) | Technique (inferred from boundary value analysis) |  | Specification-based Testing (Kam, 2008, p. 7), Equivalence Partitioning (inferred from boundary value analysis) |  | 
Factory Acceptance Testing | Level (IEEE, 2022, p. 22; Firesmith, 2015, p. 30; inferred from acceptance testing) |  | Acceptance Testing (IEEE, 2022, p. 22; Firesmith, 2015, p. 30) | FAT (Firesmith, 2015, p. 30) | 
Failover Testing | Approach | Testing that "validates the SUT's ability to manage heavy loads or unexpected failure to continue typical operations" (Washizaki, 2024, p. 5-9) by entering a "backup operational mode in which [these responsibilities] … are assumed by a secondary system" (Hamburg and Mogyorodi, 2024) | Non-functional Testing (Washizaki, 2024, p. 5-9), Bottom-Up Testing (Gerrard, 2000b, p. 27), Failure Tolerance Testing? (Firesmith, 2015, p. 56), Data Center Testing? (Firesmith, 2015, p. 24) | Failover and Recovery Testing? (p. 56), Failover and Restore Testing? (Firesmith, 2015, p. 24) | Can be done by "allocating extra resources" (Washizaki, 2024, p. 5-9) and "should be constantly rehearsed as changes to the production environment are made" (Washizaki, 2024, p. 6-8). Failures are simulated "with an automated load running to explore system behaviour in production situations" (Gerrard, 2000b, p. 27). Related to recoverability validation (Washizaki, 2024, p. 5-9)
Failure Tolerance Testing (Firesmith, 2015, p. 56) | Type (implied by Firesmith, 2015, p. 56) |  | Robustness Testing (Firesmith, 2015, p. 56) |  | 
Fault Injection Testing (IEEE, 2022, p. 42) | Approach | Testing where "faults are artificially introduced into the SUT" (Washizaki, 2024, p. 5-18) to, at least partially, "test the robustness of the system in the event of internal and external failures" (IEEE, 2022, p. 42) and "whether it can detect and possibly recover from [them]" (Hamburg and Mogyorodi, 2024) | Robustness Testing (IEEE, 2022, p. 42), Fault Tolerance Testing (Firesmith, 2015, p. 56) |  | 
Fault Tolerance Testing (Firesmith, 2015, p. 56) | Type (implied by its quality (ISO/IEC, 2023a; IEEE, 2017, pp. 38, 375; Washizaki, 2024, p. 7-10) and by Firesmith, 2015, p. 56) | Testing the "capability of a product to operate as intended despite the presence of hardware or software faults" (ISO/IEC, 2023a; similar in Washizaki, 2024, p. 7-10) "by detecting errors and then recovering from them or containing their effects if recovery is not possible" (Washizaki, 2024, p. 4-11) | Reliability Testing (IEEE, 2017, p. 375; Washizaki, 2024, p. 7-10), Availability Testing (IEEE, 2017, p. 38), Robustness Testing (Firesmith, 2015, p. 56), Dependability Testing (if it exists) (ISO/IEC, 2023a) | Robustness Testing (Hamburg and Mogyorodi, 2024) | 
Fault Tree Analysis | Technique? (Hamburg and Mogyorodi, 2024) | "A technique for analyzing the causes of failures that uses a hierarchical model of events and their logical relationships" (Hamburg and Mogyorodi, 2024) | Static Analysis |  | 
Fault-Based Testing | Technique (Washizaki, 2024, p. 5-14) | Testing that "devise[s] test cases specifically to reveal likely or predefined fault categories" (Washizaki, 2024, p. 5-14) |  |  | See (Doğan et al., 2014, Tab. 27) for a collection of fault models/bug taxonomies for web application testing
Feature-based Testing (Firesmith, 2015, p. 28) | Approach |  | Unit Testing? (implied by Firesmith, 2015, p. 28) |  | 
Features Testing (Gerrard, 2000a, Fig. 5) | Approach |  | Dynamic Testing, W-Model Testing (Gerrard, 2000a, Fig. 5), Integration Testing? (implied by Gerrard, 2000a, Fig. 5; Sangwan and LaPlante, 2006, p. 26), System Testing? (Sangwan and LaPlante, 2006, p. 26) |  | 
Field Testing | Approach | "Testing conducted to evaluate the system behavior under productive connectivity conditions in the field" (Hamburg and Mogyorodi, 2024) | Beta Testing? (implied by Kam, 2008, p. 44), Operational (Acceptance) Testing? | Operational (Acceptance) Testing? | 
Flexibility Testing (Firesmith, 2015, p. 53) | Type (implied by its quality (ISO/IEC, 2023a; IEEE, 2017, p. 184) and by Firesmith, 2015, p. 53) | Testing the "capability of a product to be adapted to changes in its requirements, contexts of use, or system environment" (ISO/IEC, 2023a; similar in IEEE, 2017, p. 184) |  |  | 
Follow-on Operational Testing | Level (inferred from operational testing) |  | Operational Testing (Firesmith, 2015, p. 30) | FOT (Firesmith, 2015, p. 30) | 
Forcing Exception Testing | Technique (Washizaki, 2024, p. 5-12) | Testing that "check[s] whether the SUT can manage a predefined set of exceptions/errors" (Washizaki, 2024, p. 5-12) | Scenario-based Testing? (Washizaki, 2024, p. 5-13) |  | Related to the "test-to-fail" approach (Patton, 2006, pp. 66-67)
Formal Methods (Kam, 2008, Tab. 1) | Approach |  | Formal Testing? |  | 
Formal Modular Verification (Chalin et al., 2006, p. 342) | Approach |  | Formal Testing |  | Does this imply "modular verification"?
Formal Reviews | Approach | "Review[s] that follow[] … defined process[es] with … formally documented output[s]" (Hamburg and Mogyorodi, 2024) | Reviews (Washizaki, 2024, p. 12-14; Hamburg and Mogyorodi, 2024), Formal Testing |  | See ISO 20246
Formal Testing | Approach | "Testing conducted in accordance with test plans and procedures that have been reviewed and approved" (IEEE, 2017, p. 188) |  |  | Since informal testing still follows "test plans and procedures" (IEEE, 2017, p. 220), this is probably not related to scripted testing (at least specifically). In the domain of web testing, this can be split into TestUML and StateChart (Kam, 2008, pp. 4-5)
Formative Evaluations | Approach | "Evaluation[s] designed and used to improve the quality of a component or system, especially when it is still being designed" (Hamburg and Mogyorodi, 2024) | Development Testing? |  | 
Full Conformance Testing (implied by IEEE, 2021, p. 7) | Type (inferred from conformance testing) | Testing that "all of the requirements … of the chosen (non-empty) set of techniques … and the corresponding test coverage measurement approaches … have been satisfied" (IEEE, 2021, p. 7; may be specific to this) | Conformance Testing |  | 
Functional Suitability Testing (IEEE, 2022, p. 7; 2021, p. viii) | Type (IEEE, 2021, p. viii; implied by its quality (ISO/IEC, 2023a)) | Testing to determine the "capability of a product to provide functions that meet stated and implied needs of intended users when it is used under specified conditions" (ISO/IEC, 2023a) |  | Functionality Testing? (implied by Hamburg and Mogyorodi, 2024) | This includes meeting "the functional specification" (ISO/IEC, 2023a), but originally explicitly didn't (2011). Difference between this and functional testing?
Functional Testing | Type (IEEE, 2022, pp. 15, 20, 22; 2021, p. 7; implied by the quality of "correctness" (IEEE, 2017, p. 104; Washizaki, 2024, p. 3-13)) | Testing "used to check the implementation of functional requirements" (IEEE, 2022, p. 21), which "identif[y] what results a product or process shall produce" (IEEE, 2017, p. 195) based on software algorithms that support work tasks (p. 422), and "to verify that the SUT conforms to standards, rules, specifications, requirements, design, processes, or practices" (Washizaki, 2024, p. 5-7) | Functional Suitability Testing? | Conformance Testing, Correctness Testing? (Washizaki, 2024, p. 5-7) | 
Functional Testing | Technique (inferred from specification-based testing) | "Testing that … focuses solely on the outputs generated in response to selected inputs and execution conditions" or that "evaluate[s] the compliance of a system or component with specified functional requirements" (IEEE, 2017, p. 196) which "identif[y] what results" (IEEE, 2017, p. 195) or "observable behaviours that the software is to provide (Washizaki, 2024, p. 1-4) "based on an analysis of the specification of … [its] functionality" (Kam, 2008, p. 44) | Automated Testing (can be) (Gerrard, 2000a, p. 11) | Specification-based Testing (IEEE, 2017, p. 196; Kam, 2008, p. 44; van Vliet, 2000, p. 399) | Difference between this and specification-based testing (IEEE, 2017, p. 196; van Vliet, 2000, p. 399; Souza et al., 2017, p. 3)?
Functionality Testing | Type? (implied by its quality (IEEE, 2017, p. 196) and by Firesmith, 2015, p. 53) | Testing of the "capabilities of the various … features provided by a product" (IEEE, 2017, p. 196) | Build Verification Testing (Hamburg and Mogyorodi, 2024), Smoke Testing?, Functionality Suitability Testing? | Functional Suitability Testing? (seems incorrect) (Hamburg and Mogyorodi, 2024) | Should be performed "in all projects", possibly implicitly "during development and user evaluation", but is "typically the … most expensive and time consuming to implement and execute" (Gerrard, 2000a, p. 13). Difference between this and functional testing? Gerrard makes a distinction between them (2000a, Tab. 2; 2000b, Tab. 1)
Functions Testing (implied by Doğan et al., 2014, Tab. 11) | Technique (inferred from structure-based testing) |  | Requirements-based Testing? (Kam, 2008, p. 47), Structured-based Testing (implied by Doğan et al., 2014, Tab. 11), Control Flow Testing? |  | Difference between this and method testing?
Fuzz Testing | Technique (IEEE, 2022, p. 36; Hamburg and Mogyorodi, 2024), Practice? (inferred from mathematical-based testing) | Testing where "high volumes of random (or near random) data, called fuzz, are used to generate [test] inputs" (IEEE, 2022, p. 5; similar in Hamburg and Mogyorodi, 2024) "aimed at breaking the software" (Bourque and Fairley, 2014, p. 4-8) or "discover[ing] security vulnerabilities" (Hamburg and Mogyorodi, 2024) | Mathematical-based Testing (IEEE, 2022, p. 36), Security Testing (Hamburg and Mogyorodi, 2024), Random Testing (Bourque and Fairley, 2014, p. 4-8; Firesmith, 2015, p. 51; implied by IEEE, 2022, p. 5; Hamburg and Mogyorodi, 2024) | Fuzzing (Hamburg and Mogyorodi, 2024) | Often used for security testing (Bourque and Fairley, 2014, p. 4-8). This is tagged (?) as "artificial intelligence" (IEEE, 2022, p. 5), but I don't think AI is required
Galumphing (Firesmith, 2015, p. 50) | Technique? |  | Exploratory Testing (Firesmith, 2015, p. 50) |  | 
Graphical User Interface (GUI) Testing | Approach | "Testing performed by interacting with the software under test via the graphical user interface" (Hamburg and Mogyorodi, 2024) | Browser Page Testing (implied by Gerrard, 2000b, p. 13), Dynamic Testing |  | See Banerjee et al. (2013)
Grey-Box Testing | Technique (IEEE, 2021, p. 8; Firesmith, 2015, p. 46) | Testing that "utilis[es] a combination of knowledge from the test item's specification and structure" (IEEE, 2021, p. 8) | Specification-based Testing, Structure-based Testing (IEEE, 2021, p. 8; Patton, 2006, p. 218) | Sometimes spelled "gray-box" (Patton, 2006, p. 218) or without a hyphen ("graybox"; Firesmith, 2015, p. 46) | 
Group Testing (Firesmith, 2015, p. 36) | Approach |  |  |  | 
Heartbeat (Firesmith, 2015, p. 31) | Practice? |  | Periodic Built-In Testing (Firesmith, 2015, p. 31), Self-Testing? (implied by Firesmith, 2015, p. 31) |  | Not sure what this is; investigate
Heuristic Evaluations | Technique (Hamburg and Mogyorodi, 2024) | "Usability review[s] … that evaluate[] a work product by using a set of heuristics" (Hamburg and Mogyorodi, 2024) | Usability Reviews (Hamburg and Mogyorodi, 2024), Usability Testing (Gerrard, 2000a, p. 13; 2000b, p. 22) |  | See [18] in Gerrard, 2000b, p. 22
High Frequency Testing (Sharma et al., 2021, p. 601; OG [19]) | Approach |  | Integration Testing (Sharma et al., 2021, p. 603) |  | 
High-Level Testing | Approach | Testing "with concrete values for preconditions, input data, expected results, postconditions, and a detailed description of actions (where applicable)" (Hamburg and Mogyorodi, 2024) |  |  | OG definition was about test cases, not a test approach
Human Factors Engineer Testing (Firesmith, 2015, p. 39) | Practice? |  | Developer Testing (Firesmith, 2015, p. 39) |  | 
Human-in-the-Loop Testing (Firesmith, 2015, p. 23) | Level (implied by system testing) |  | System Testing (Firesmith, 2015, p. 23) | HIL Testing (Firesmith, 2015, p. 23) | 
Hyperlink Testing (Doğan et al., 2014, Tab. 13; OG Ricca and Tonella, 2001; 2002) | Technique? (inferred from control flow testing) | Testing in which "every hyperlink from every page in the site is traversed at least once" (Doğan et al., 2014, Tab. 13; OG Ricca and Tonella, 2001; 2002) | Web Application Testing (Doğan et al., 2014, Tab. 13), Smoke Testing, Desktop Development Testing (Gerrard, 2000a, Tab. 2; 2000b, Tab. 1), Gray-Box Testing? (Patton, 2006, p. 220), Page Testing, Control Flow Testing? | All-Hyperlinks Testing? (Doğan et al., 2014, Tab. 13; OG Mansour and Houri, 2006), Link Checking? | 
Hypothesis Testing | Approach | "Validation of a theory and its assumptions using sample data" (Hamburg and Mogyorodi, 2024) |  |  | Ambiguous: what is a "theory"? why use "sample data" and not just "data"? is it specific to software or does it just refer to general science? Potentially related to model verification
In-container Testing (Doğan et al., 2014, Tab. 8) | Approach | "Testing in application servers" (Doğan et al., 2014, Tab. 8) | Web Application Testing (Doğan et al., 2014, Tab. 8) |  | 
Incremental Testing (Firesmith, 2015, p. 29) | Practice? | Testing that "occur[s] in an overlapping … manner" to other phases of development (IEEE, 2017, p. 218) "through a series of iterations" (Washizaki, 2024, p. 10-5; OG [3, 8, 13]) or "where components or systems are integrated and tested one or some at a time" (Kam, 2008, p. 45) | Lifecycle-based Testing (Washizaki, 2024, p. 10-5; OG [2, 3, 10]; Firesmith, 2015, p. 29) | Incremental Verification? (implied by Lahiri et al., 2013, p. 345) | 
Independent Test Organization Testing (Firesmith, 2015, p. 37) | Practice? |  | Organization-based Testing (Firesmith, 2015, p. 37), Independent Tester Testing |  | 
Independent Tester Testing (Firesmith, 2015, p. 39) | Practice? |  | Tester Testing (Firesmith, 2015, p. 39) |  | 
Individual Testing (Firesmith, 2015, p. 36) | Approach |  |  |  | 
Inductive Assertion Methods | Technique (IEEE, 2017, p. 220; OG ISO/IEC, 2002) | The process "in which assertions are written describing program inputs, outputs, and intermediate conditions, a set of theorems is developed relating satisfaction of the input assertions to satisfaction of the output assertions, and the theorems are proved or disproved using proof by induction" (IEEE, 2017, p. 220; OG ISO/IEC, 2002) | Proofs of Correctness (IEEE, 2017, p. 220; OG ISO/IEC, 2002), Mathematical-based Testing, Assertion Checking, Static Testing? |  | 
Industrial Web Application Testing | Approach |  | Web Application Testing (Kam, 2008, p. 10) |  | 
Informal Reviews | Approach | "Review[s] that do[] not follow a defined process and ha[ve] no formally documented output" (Hamburg and Mogyorodi, 2024) | Reviews (Washizaki, 2024, p. 12-14; Hamburg and Mogyorodi, 2024), Informal Testing |  | 
Informal Testing | Approach, Technique? (Kam, 2008, p. 6) | "Testing conducted in accordance with test plans and procedures that have not been reviewed and approved by a customer, user, or designated level of management" (IEEE, 2017, p. 220) |  |  | "Widely accepted by industry" (Kam, 2008, p. 6) (which I think is wild) and "the tedious and confusing software testing jargon" is a drawback (Kam, 2008, p. 6) (although this isn't specific to informal testing)
Infrastructure Compatibility Testing | Type (implied by Firesmith, 2015, p. 53) |  | Compatibility Testing (Firesmith, 2015, p. 53), Infrastructure Testing |  | 
Infrastructure Testing | Type (implied by Firesmith, 2015, p. 57), Level? (Gerrard, 2000a, p. 13) | Testing of "infrastructure components[, or "what runs on the servers" (Gerrard, 2000a, p. 13),] to reduce the chances of downtime and improve the performance of the IT infrastructure" (Washizaki, 2024, p. 5-9) | Security Testing (Firesmith, 2015, p. 57), Non-functional Testing (Washizaki, 2024, p. 5-9) |  | 
Initial Operational Testing | Level (inferred from operational testing) |  | Operational Testing (Firesmith, 2015, p. 30) | IOT (Firesmith, 2015, p. 30) | 
Input Data Testing | Level (Hamburg and Mogyorodi, 2024) | Testing "that focuses on the quality of the data used for training and prediction by ML models" (Hamburg and Mogyorodi, 2024) | ML Model Testing |  | 
Input Validation Testing (Gerrard, 2000a, Fig. 5; Doğan et al., 2014, Tab. 13; OG Liu and Kuan Tan, 2008) | Approach, Technique? (inferred from path testing) | Testing that ensures "at least one path in the program's CFG w.r.t. the validation of inputs has been covered" (Doğan et al., 2014, Tab. 13; OG Liu and Kuan Tan, 2008) | Dynamic Testing, W-Model Testing (Gerrard, 2000a, Fig. 5), Path Testing, Data-driven Testing? |  | Related to the idea of "input validation coverage (IVC)" (Doğan et al., 2014, Tab. 13; OG Liu and Kuan Tan, 2008)
Input-Parameter Testing (Doğan et al., 2014, Tab. 13; OG Halfond and Orso, 2007) | Technique? (inferred from combinatorial testing) | Testing that aims to "cover[] all possibilities of input parameters" (Doğan et al., 2014, Tab. 13; OG Halfond and Orso, 2007) | Web Application Testing, Specification-based Testing (Doğan et al., 2014, Tab. 13), Model-based Testing (IEEE, 2022, p. 13; 2021, p. 6), Combinatorial Testing |  | 
Insourced Testing | Practice? | "Testing performed by people who are co-located with the project team but are not fellow employees" (Hamburg and Mogyorodi, 2024) |  |  | Also mentioned by Firesmith (2015, p. 41)
(Code) Inspections | Technique (IEEE, 2017, p. 227) | "Visual examination[s] of … [code] to detect and identify software anomalies, including errors and deviations from standards and specifications" (IEEE, 2017, p. 227; OG IEEE, 2008) that are "led by impartial facilitators who are trained in inspection techniques" (IEEE, 2017, p. 227) and "use[] defined team roles and measurement" (Hamburg and Mogyorodi, 2024) | Static Analysis (IEEE, 2017, p. 227), Static Testing (IEEE, 2017, p. 227; Gerrard, 2000a, Fig. 4, p. 12; 2000b, p. 3), Formal Reviews (Hamburg and Mogyorodi, 2024), W-Model Testing (Gerrard, 2000a, Fig. 4) |  | Related to peer reviews (Hamburg and Mogyorodi, 2024). Could also include inspection of the software product itself, like in the context of usability (Gerrard, 2000a, p. 13)? See ISO 20246
Installability Testing | Type (IEEE, 2022, p. 22; 2017, p. 228; implied by its quality) | "Testing conducted to evaluate whether … test items can be installed [and/or uninstalled (ISO/IEC, 2023a)] as required in all specified environments" (IEEE, 2017, p. 228; OG IEEE, 2013) or a specific one (ISO/IEC, 2023a) | Portability Testing (ISO/IEC, 2023a; IEEE, 2017, p. 228; implied by Kam, 2008, p. 45); Replaceability Testing? (ISO/IEC, 2023a) |  | 
Installation Testing | Level (Peters and Pedrycz, 2000, p. 445; implied by Washizaki, 2024, p. 5-8) | "System testing conducted in the operational environment of hardware configurations and other operational constraints"; may also verify installation procedures (Washizaki, 2024, p. 5-8) | Dynamic Testing, W-Model Testing (Gerrard, 2000a, Fig. 5), System Testing? (implied by Gerrard, 2000a, Fig. 5), Online Testing? |  | "Typically observe[s] the newly started server for a while, ensuring that the server doesn't crash or otherwise misbehave" (Washizaki, 2024, p. 6-10)
Intake Testing | Approach |  |  |  | 
Integrated System Testing (Firesmith, 2015, p. 24) | Level? (implied by system testing?) |  | Data Center Testing (Firesmith, 2015, p. 24) | Systems Integration Testing? | 
Integration Testing | Level (IEEE, 2022, pp. 12, 20-22, 26-27; 2021, p. 6; Washizaki, 2024, p. 5-7; Hamburg and Mogyorodi, 2024) | Testing that "verifies the interactions among SUT elements (for instance, components, modules, or subsystems)" as well as "external interfaces" (Washizaki, 2024, p. 5-7; similar in IEEE, 2022, p. 13; 2021, p. 6) in a "progressive" manner (IEEE, 2017, p. 231) | Construction Testing (Washizaki, 2024, p. 4-7), V-Model Testing (Gerrard, 2000a, p. 9), W-Model Testing (Gerrard, 2000a, Figs. 3-5), Structure-based Testing (Gerrard, 2000b, p. 30) | Link Testing (implied by Gerrard, 2000a, p. 13) | More effective when automated (Washizaki, 2024, p. 7-14) (this is "the only way to accomplish this in an effective and efficient manner" for distributed systems (Sneed and Göschl, 2000, p. 18)), but may be "complicated and have to be manually executed" (Gerrard, 2000b, p. 31). "Can be performed at each development stage" (Washizaki, 2024, p. 5-7). IEEE (2017, p. 231) says it can be used when integrating systems; is this captured by "subsystems" in the SWEBOK definition? See also (Patton, 2006, p. 109)
Interface Testing | Level (implied by IEEE, 2017, p. 235 and integration testing), Type? (Kam, 2008, p. 45) | Testing that "aims to verify whether the components' interface provides the correct exchange of data and control information" (Washizaki, 2024, p. 5-10; similar in IEEE, 2017, p. 235) | Integration Testing (Hamburg and Mogyorodi, 2024; implied by Gerrard, 2000b, p. 30), Design-based Testing (Kam, 2008, p. 44), System Integration Testing (can be) (p. 48) |  | "Usually, the test cases are generated from the interface specification" (Washizaki, 2024, p. 5-10)
Internationalization Testing | Type (implied by Firesmith, 2015, p. 55) | Testing that "anyone on the planet who has the technology can … use" the software (Gerrard, 2000a, p. 8) | Flexibility Testing (Firesmith, 2015, p. 53), Usability Testing, Functional Testing, Dynamic Testing (Gerrard, 2000a, Tab. 2; 2000b, Tab. 1), Inclusivity Testing? (if it exists) |  | Includes supporting "local currencies", "tax arrangements", and "address formats" (Gerrard, 2000a, p. 8; similar on 2000b, p. 13)
Interoperability Testing | Type (IEEE, 2022, p. 22; implied by its quality (ISO/IEC, 2023a) and by Firesmith, 2015, p. 53) | Testing that aims to evaluate the "capability of a product to exchange information with other products [or "systems of different types" (IEEE, 2017, p. 238)] and mutually use the information that has been exchanged" (ISO/IEC, 2023a) or that "a modified system retains [this] capability" (IEEE, 2017, p. 238) | Compatibility Testing (IEEE, 2022, p. 3; ISO/IEC, 2023a) |  | Originally defined in the context of "two or more systems, products or components" (ISO/IEC, 2011). See "passive interconnection" (IEEE, 2017, p. 315; OG IEEE, 2006) potentially?
Interrupt-driven Built-In Testing (Firesmith, 2015, p. 31) | Practice? |  | Built-In Testing (Firesmith, 2015, p. 31) | IBIT (Firesmith, 2015, p. 31) | 
Isolation Testing | Practice? | "Testing of individual components in isolation from surrounding components" (Kam, 2008, p. 45) | Unit Testing? |  | "Surrounding components [may] be[] simulated by stubs and drivers" (Kam, 2008, p. 45)
Keyword-driven Testing | Approach, Technique? (Hamburg and Mogyorodi, 2024) | Testing that uses "keywords related to the application being tested" that "are interpreted by special supporting scripts that are called by the control script for the test" (Kam, 2008, p. 45) | Scripted Testing (Hamburg and Mogyorodi, 2024), Automated Testing (IEEE, 2022, p. 35), Data-driven Testing (Kam, 2008, p. 45) | Action Word-driven Testing (Hamburg and Mogyorodi, 2024), Action-Keyword Testing? (Firesmith, 2015, p. 44) | Similar to data-driven testing (Hamburg and Mogyorodi, 2024). See also ISO/IEC/IEEE 29119-5
Large Scale Integration (LSI) Testing (Gerrard, 2000b, p. 30) | Approach | Testing that covers "legacy system and external system integration" based on dialogs and data validation (Gerrard, 2000b, p. 30) | Integration Testing? |  | Often required due to "commercial, technical and[/or] logistic constraints" (Gerrard, 2000b, p. 30)
Layer-based Testing (Firesmith, 2015, p. 28) | Approach |  | Unit Testing? (implied by Firesmith, 2015, p. 28) |  | 
Legacy System Integration (Testing) (Gerrard, 2000a, Tab. 2; 2000b, Tab. 1) | Level (inferred from system integration testing) |  | Functional Testing, Dynamic Testing, Large Scale Integration Testing (Gerrard, 2000a, Tab. 2; 2000b, Tab. 1), System Integration Testing, Legacy Testing |  | 
Legacy Testing (Firesmith, 2015, p. 34) | Approach |  | Reuse Testing (Firesmith, 2015, p. 34) |  | 
License Compliance Audits | Practice? (inferred from audits) | "Audit[s] that reconcile[] license-related information from multiple information sources, such as entitlement consumption against entitlement rights" (IEEE, 2017, p. 250) | Audits (IEEE, 2017, p. 250) |  | 
Lifecycle-based Testing (Firesmith, 2015, p. 29) | Practice? |  |  |  | "Generally speaking, [the production stage of an SLCP] will include the production and testing of the system" (Washizaki, 2024, p. 10-7)
Linear Scripting | Practice (implied by Scripted Testing) | Scripted testing "without any control structure in the test scripts" (Hamburg and Mogyorodi, 2024) | Scripted Testing (Hamburg and Mogyorodi, 2024) | Linear(ly) Scripted Testing? | 
Link Checking (Gerrard, 2000a, Tab. 2; 2000b, Tab. 1) | Approach | Testing "the availability of linked objects" by "identify[ing] all of the linked objects on a page and … attempt[ing] to download them" (Gerrard, 2000b, p. 9) | Test Browsing (Gerrard, 2000a, Tab. 2; 2000b, Tab. 1, p. 9), Automated Testing (2000a, Tab. 2; 2000b, Tab. 1; implied by p. 32), Smoke Testing, Dynamic Testing (2000a, Tab. 2; 2000b, Tab. 1), Post-Deployment Monitoring (2000b, pp. 32-33), Gray-Box Testing? (Patton, 2006, p. 220), Availability Testing, Web Application Testing |  | May have subapproaches for static, dynamic, or form links (Kam, 2008, p. 8)
Link Dependence Transition Relation Testing (Doğan et al., 2014, Tab. 13; OG Peng and Lu, 2011) | Approach |  | Web Application Testing (Doğan et al., 2014, Tab. 13), Hyperlink Testing? |  | 
Load Balancing Testing (implied by Washizaki, 2024, p. 6-5) | Approach |  |  |  | May be done by "us[ing] infrastructure/operations services" early on in the development process (Washizaki, 2024, p. 6-5)
Load Testing | Type (IEEE, 2022, pp. 5, 20, 22; 2017, p. 253; OG IEEE 2013; Hamburg and Mogyorodi, 2024; implied by Firesmith, 2015, p. 54) | Testing "conducted to evaluate the behaviour of a test item under anticipated conditions of varying [or "increasing" (Kam, 2008, p. 45)] load" (IEEE, 2022, p. 5; 2017, p. 253; OG IEEE 2013; similar in Hamburg and Mogyorodi, 2024) | Non-functional Testing (Washizaki, 2024, p. 5-9); Performance Testing (IEEE, 2022, p. 5; Hamburg and Mogyorodi, 2024; implied by IEEE, 2022, p. 22), Performance Efficiency Testing (IEEE, 2017, p. 253; OG IEEE 2013); Capacity Testing (Firesmith, 2015, p. 54) |  | Loads used are "usually between anticipated conditions of low, typical, and peak usage" (IEEE, 2022, p. 5; 2017, p. 253; OG IEEE 2013; Hamburg and Mogyorodi, 2024) which may be different numbers of parallel users or transactions (Kam, 2008, p. 45); this may be aided by load generation and/or management (see Hamburg and Mogyorodi, 2024). Patton defines this as running the software with as large of a load as possible (2006, p. 86), and Washizaki (2024, p. 5-9) seems to imply something similar; going past this "limit" is the realm of "stress testing" (Washizaki, 2024, p. 5-9). Seeks to "discover problems … or reliability, stability, or robustness violations" (Washizaki, 2024, p. 5-9). Good to use if the software may have "a large number of concurrent users" (IEEE, 2022, p. 45). Captured as part of "object load and timing" by Gerrard (2000a, Tab. 2; 2000b, Tab. 1). See ISO 29119-1
Local Testing (Firesmith, 2015, p. 42; Jard et al., 1999) | Practice? |  | Synchronous Testing (implied by Jard et al., 1999) |  | 
Localization Testing | Type (IEEE, 2022, p. 22) | Testing "a national or specific regional version of a product" (IEEE, 2017, p. 253; OG ISO/IEC 2008) to ensure "that all user messages, prompts and output is [sic] translated correctly and that the functionality delivered to the end user is identical" (Gerrard, 2000b, p. 19) | Manual Testing (often), Web Application Testing (can be) (Gerrard, 2000b, p. 19) |  | Related to internationalization testing, but can be done "separately from the translation process" (IEEE, 2017, p. 254)
Loop Testing (Gerrard, 2000a, Fig. 5) | Technique? | Path testing that focuses on paths containing loops (inferred from Godefroid and Luchaup, 2011, p. 23), "including nested loops, loops with multiple guards, and arbitrary control-flow graphs with unstructured loops and go-tos" (Godefroid and Luchaup, 2011, p. 24) | Structure-based Testing (Sharma et al., 2021, Fig. 1), Dynamic Testing, W-Model Testing (Gerrard, 2000a, Fig. 5), Control Flow Testing? (implied by Godefroid and Luchaup, 2011, p. 24) Performance Testing? (implied by Dhok and Ramanathan, 2016), Unit Testing? (implied by Gerrard, 2000a, Fig. 5) |  | Difficult to automate due to "virtual call resolution", reachability conditions, and order-sensitivity (Dhok and Ramanathan, 2016, p. 896). Can be supported by random testing (Dhok and Ramanathan, 2016, p. 896), including fuzz testing (Godefroid and Luchaup, 2011, p. 23), symbolic execution (pp. 23-24, 32), equivalence partitioning (p. 24), and/or the use of loop assertions (p. 23)
Loopback Testing | Practice? | "Testing in which signals or data from a test device are input to a system or component, and results are returned to the test device for measurement or comparison" (IEEE, 2017, p. 257) |  |  | Related to "mechanism loopback" (IEEE, 2017, p. 270)?
Low-Level Testing | Approach | Testing "with abstract preconditions, input data, expected results, postconditions, and actions (where applicable)" (Hamburg and Mogyorodi, 2024) |  |  | OG definition was about test cases, not a test approach
Machine Learning-Assisted Testing (implied by Moghadam, 2019) | Practice? |  |  |  | 
Maintainability Testing | Type (IEEE, 2022, pp. 5, 22; implied by its quality) | Testing "conducted to evaluate the degree of effectiveness and efficiency with which a test item may be modified" (IEEE, 2022, p. 5; similar in ISO/IEC, 2023a) "by the intended maintainers" (Hamburg and Mogyorodi, 2024), including through "corrections, improvements or adaptation of the product to changes in environment, and in requirements and functional specifications", as well as the "installation of updates and upgrades" (ISO/IEC, 2023a) |  | Serviceability Testing (Kam, 2008, p. 47) | Six categories: corrective, preventive, adaptive, additive, perfective, and emergency (Washizaki, 2024, p. 7-4; "emergency" added in ISO/IEC/IEEE 14764 and mentioned in IEEE, 2017, p. 156); these may be sub-approaches
Maintenance Testing | Approach | "Testing the changes to an operational system or the impact of a changed environment to an operational system" (Hamburg and Mogyorodi, 2024) | Change-Related Testing?, Operational (Acceptance) Testing? |  | Related to portability testing and/or retesting?
Malware Scanning | Approach | The "detect[ion] and remov[al of] malicious code received at an interface" (Hamburg and Mogyorodi, 2024) | Static Analysis (Hamburg and Mogyorodi, 2024), Interface Testing (Hamburg and Mogyorodi, 2024)? |  | 
Manual Procedure Testing | Technique? |  | Specification-based Testing (Firesmith, 2015, p. 47), Manual Testing |  | 
Manual Testing | Practice (IEEE, 2022, p. 22) | "Humans performing tests by entering information into a test item and verifying the results" (IEEE, 2022, p. 6) | Scripted Testing (IEEE, 2022, p. 33) |  | "Inefficient, error prone and non-scalable" (Washizaki, 2024, p. 6-5)
Markov Chain Testing (implied by Kam, 2008, Tab. 1) | Approach | Testing performed using a Markov chain where transition probabilities are determined by "web usage model[s] … represent[ing] the possible navigation of the web application" or are "uniformly distributed" "if there is no usage information available" (Kam, 2008, p. 22) to find broken links, measure reliability, and evaluate system performance and mean time to failure (p. 23) | Web Application Testing (Kam, 2008, Tab. 1, p. 21; OG [6, 7, 14, 15, 19, 43]), Statistical Testing (Kam, 2008, Tab. 1, pp. 21-22), Specification-based Testing (usually), Non-functional Testing (Tab. 1), Usage-based Testing (p. 22), Reliability Testing, Performance Testing, Maintainenanve Tesitng, Correctness Testing (can be; p. 23) |  | Is this only applicable in the context of web application testing? My instinct says "no"
Mathematical-based Testing | Practice (IEEE, 2022, pp. 22, 36) | Testing based on "the test item's required behaviour, input space or output space" when they "can be described in sufficient detail" (IEEE, 2022, p. 36) | Automatic Testing (usually) (IEEE, 2022, p. 36) |  | Related to computation error testing from Patton (2006, p. 101)? See also ISO/IEC/IEEE 29119-4
MC/DC Testing | Technique (IEEE, 2022, p. 6; 2021, p. 4, Fig. 2; Washizaki, 2024, p. 5-13; Hamburg and Mogyorodi, 2024) | Testing "based on demonstrating that a single Boolean condition within a decision can independently affect the outcome of the decision" (IEEE, 2022, p. 6; 2021, p. 4; similar in Hamburg and Mogyorodi, 2024) | Structure-based Testing (IEEE, 2022, pp. 6, 22; 2021, Fig. 2, Hamburg and Mogyorodi, 2024), Control Flow Testing (Washizaki, 2024, p. 5-13), Condition Testing? (Kam, 2008, p. 43), Multiple Condition Testing? (Kam, 2008, p. 45) | Sometimes spelled without slash (IEEE; 2021, p. 4), Modified Condition Decision Testing (IEEE, 2022, p. 6; 2021, p. 4; Washizaki, 2024, p. 5-13; with slash in Hamburg and Mogyorodi, 2024), Condition Determination Testing, Modified Multiple Condition Testing (Hamburg and Mogyorodi, 2024) | 
Metamorphic Testing | Technique (IEEE, 2022, pp. 6, 22; 2021, p. 4, Fig. 2; Washizaki, 2024, p. 5-15; Hamburg and Mogyorodi, 2024) | Testing "based on generating test cases based on existing test cases and metamorphic relations" (IEEE, 2022, p. 6; 2021, p. 4; similar in Hamburg and Mogyorodi, 2024) | Specification-based Testing (IEEE, 2022, pp. 6, 22; 2021, p. 4, Fig. 2), Mutation Testing (Washizaki, 2024, p. 5-15) | MT (Hamburg and Mogyorodi, 2024) | Test cases that pass and are "used as the basis of follow-up test cases" are called "source test cases" (Hamburg and Mogyorodi, 2024). Good to use when it is "difficult to calculate expected results" (IEEE, 2022, p. 45). See also Kanewala and Yueh Chen, 2019
Method Testing (implied by Doğan et al., 2014, Tab. 11) | Technique (inferred from structure-based testing) |  | Structured-based Testing (implied by Doğan et al., 2014, Tab. 11), Control Flow Testing? |  | Difference between this and method testing?
Minimized Testing? | Technique? | Testing where "the minimum number of test cases is derived to cover each … [test coverage item, such as option or mutation for syntax testing (IEEE, 2021, p. 15) or equivalence partition] at least once" (p. 11; OG BS 7925-2; Myers 1979; similar on p. 15)  |  |  | "Can lead to such unrealistic test inputs that it can be unlikely that the test item will fail to identify the test input as invalid", especially for mutations in syntax testing (IEEE, 2021, p. 15)
Mixed Entry Table Testing | Technique (inferred from decision table testing) | Testing "based on exercising decision rules" (IEEE, 2022, p. 4) in a mixed entry table (IEEE, 2017, p. 278; OG ISO, 1984) | Decision Table Testing (IEEE, 2017, p. 278; OG ISO, 1984) |  | 
ML Model Testing | Level? (Hamburg and Mogyorodi, 2024) | Testing "that focuses on the ability of an ML model to meet required ML functional performance criteria and non-functional criteria" (Hamburg and Mogyorodi, 2024) | Domain-Specific Testing? |  | "ML functional performance" is defined in terms of "the functional correctness of an ML system" (Hamburg and Mogyorodi, 2024), which is ambiguous and/or incorrect
(Flash) Mob Testing (Firesmith, 2015, pp. 36, 58) | Type (implied by Firesmith, 2015, p. 58) |  | Usability Testing (Firesmith, 2015, p. 58), Group Testing (p. 36) |  | 
Mobile Testing | Type (implied by Firesmith, 2015, p. 53) |  | Compatibility Testing (Firesmith, 2015, p. 53) |  | 
Model Verification | Approach |  | Static Testing (IEEE, 2022, p. 17) |  | 
Model-based Testing | Practice (IEEE, 2022, p. 22; 2021, p. viii), Technique (Kam, 2008, p. 4; implied by IEEE, 2021, p. 7; 2017, p. 469) | Testing that uses "formal or semi-formal representations of the required behaviour of a … [test] item" to "generate test cases systematically and automatically" at "various levels of abstraction" (IEEE, 2022, p. 32) | Mathematical-based Testing (IEEE, 2022, p. 36), Automated Testing (Firesmith, 2015, p. 44), (with its sub-techniques) Web Application Testing (Doğan et al., 2014, Tabs. 8, 22) | MBT (IEEE, 2022, p. 32; Hamburg and Mogyorodi, 2024) | Models "vary in the degree of model formality" (such as Agile, semiformal, and formal models) (Washizaki, 2024, p. 1-14). Good potential for automation/generation! See also Souza et al., 2017 (term used on p. 3) and Engström and Petersen, 2015
Monkey Testing | Technique (Washizaki, 2024, p. 5-14) | Testing using "randomly generated test cases to cause the program to stop" (Washizaki, 2024, p. 5-14) | Ad Hoc Testing (Washizaki, 2024, p. 5-14), Unscripted Testing (Firesmith, 2015, p. 45), Random Testing (Firesmith, 2015, p. 51), Fuzz Testing? |  | Related to fuzz testing?
Multiplayer Testing | Approach | "Testing to determine if many players can simultaneously interact with the … game world, … computer-controlled opponents, game servers, and … each other, [sic] as expected according to the game design" (Hamburg and Mogyorodi, 2024) | Multi-User Testing |  | OG definition mentioned the "casino game world", but this can be generalized
Multiple Condition Testing | Technique (Kam, 2008, p. 46; inferred from MC/DC testing) | Testing "in which test cases are designed to execute combinations of single condition outcomes (within one statement)" (Kam, 2008, p. 46) | Structure-based Testing (Kam, 2008, p. 46) |  | 
Multiple-Hit Decision Table Testing | Technique (inferred from decision table testing) | Testing "based on exercising decision rules" (IEEE, 2022, p. 4) in a multiple-hit decision table (IEEE, 2017, p. 285; OG ISO, 1984) | Decision Table Testing (IEEE, 2017, p. 285; OG ISO, 1984) |  | 
Multi-User Testing (Gerrard, 2000a, Fig. 5) | Approach |  | Dynamic Testing, W-Model Testing (Gerrard, 2000a, Fig. 5) |  | 
Mutation Testing | Technique (Washizaki, 2024, p. 5-15); Methodology (IEEE, 2017, p. 286) | Testing where "test cases are randomly generated … or … specifically designed" to detect "slightly modified version[s] of the SUT" called "mutants" (Washizaki, 2024, p. 5-15) or "program mutations" (IEEE, 2017, p. 286) | Structure-based Testing (Washizaki, 2024, p. 5-15), Fault-based Testing (Bourque and Fairley, 2014, p. 4-9), Web Application Testing (Doğan et al., 2014, p. 181, Tabs. 8, 22) | Fault Feeding (Doğan et al., 2014, p. 181) | Assumes that "that more complex but real faults will be found by looking for simple syntactic faults" and requires "many mutants … [to] be automatically generated and executed systematically"; can be used to assist fuzz and metamorphic testing (Washizaki, 2024, p. 5-15)
Needs-Driven Testing | Approach | Testing that "tests why" the "system meets stakeholder needs"? (Firesmith, 2015, p. 33) |  |  | 
Negative Testing | Approach, Technique? (IEEE, 2021, p. 10) | "Testing a component or system in a way for which it was not intended to be used" (Hamburg and Mogyorodi, 2024), such as for functionality "not included in the specification" or "inputs … that should either be ignored … or cause … an error message" (IEEE, 2021, p. 11), using "at least one input value that the test item should reject as incorrect, ideally with an appropriate error message" (p. 10). "The application of boundary value concepts to scenario testing"? (IEEE, 2022, p. 40) | Experience-based Testing (implied by IEEE, 2021, p. 11), Security Testing? (Washizaki, 2024, p. 5-9), Forcing Exception Testing? (Washizaki, 2024, p. 5-13), Boundary Value Analysis?, Scenario-based Testing? (IEEE, 2022, p. 40), Robustness Testing? | Invalid Testing (Hamburg and Mogyorodi, 2024; implied by IEEE, 2021, p. 10), Dirty Testing (Hamburg and Mogyorodi, 2024) | "Negative test cases can be derived from the state and event combinations that do not appear" in state models (Washizaki, 2024, p. 1-20)
Neighborhood Integration Testing | Level (inferred from integration testing) | "Integration testing … [based on] the nodes that connect to a given node" (Hamburg and Mogyorodi, 2024) | Integration Testing (Hamburg and Mogyorodi, 2024) |  | What does "node" mean in this context?
Network Admin Testing (Firesmith, 2015, p. 39) | Practice? |  | Operator Testing (Firesmith, 2015, p. 39) |  | 
Network Traffic Testing (Firesmith, 2015, p. 24) | Approach |  | Data Center Testing (Firesmith, 2015, p. 24), Network Admin Testing? |  | 
Neuron Coverage (Testing)? | Approach | Testing based on "the coverage of activated neurons in the neural network for a set of tests" (Hamburg and Mogyorodi, 2024) | ML Model Testing (implied by Hamburg and Mogyorodi, 2024) |  | 
Non-functional Testing (Washizaki, 2024, p. 5-8) | Approach | Testing that "targets the validation of non-functional aspects (such as performance, [security,] usability, or reliability)" (Washizaki, 2024, p. 5-8; IEEE, 2022, p. 21; similar in Hamburg and Mogyorodi, 2024) that tend to "constrain the technologies to be used in the implementation" (Washizaki, 2024, p. 1-4) | Requirements-based Testing (Kam, 2008, p. 47), Dynamic Testing (although this seems over-zealous), W-Model Testing (Gerrard, 2000a, p. 9) |  | Hundreds of subapproaches that can be "performed at all test levels" (Washizaki, 2024, p. 5-8). "Nonfunctional requirements" are also called "performance attributes" (IEEE, 2017, p. 293); what does this imply for the relationship between non-functional and performance testing? In constrast to functional testing (IEEE, 2022, p. 21)
N-Switch Testing | Technique (inferred from state transition testing and IEEE, 2021, p. 20) | Testing "derived to cover valid sequences of N + 1 transitions in the state model" (IEEE, 2021, p. 20) | State Transition Testing (IEEE, 2021, p. 20; Kam, 2008, p. 46) | Multiple Transitions Testing (implied by IEEE, 2021, p. 20) | See Chow, 1978
Object-based Testing | Approach |  | Web Application Testing, Object-Oriented Testing, Structure-based Testing, Data Flow Testing, Functional Testing (Kam, 2008, Tab. 1) |  | 
Object-Oriented Testing (Doğan et al., 2014, Tab. 1) | Practice? |  |  |  | See Binder (1996)
Offline MBT | Approach (Hamburg and Mogyorodi, 2024) | "Model-based test[ing] … whereby test cases are generated into a repository for future execution" (Hamburg and Mogyorodi, 2024) | Offline Testing, Model-based Testing (Hamburg and Mogyorodi, 2024) |  | 
Offline Testing | Practice? | Testing "in an environment without external interaction" (Washizaki, 2024, p. 5-6), or testing "whereby test cases are generated into a repository for future execution" (Hamburg and Mogyorodi, 2024) |  |  | Sometimes spelled with a hyphen ("off-line"; Washizaki, 2024, p. 5-6)
One-to-One Testing? | Technique? | Testing where "each test case is derived to exercise a specific" test coverage item, such as an "option or mutation" for syntax testing (IEEE, 2021, p. 15) or equivalence partition (p. 11; OG BS 7925-2; Myers 1979) |  |  | 
Ongoing Built-In Testing (Firesmith, 2015, p. 31) | Practice? |  | Built-In Testing (Firesmith, 2015, p. 31), Continuous Testing? | OBIT (Firesmith, 2015, p. 31) | 
Online MBT | Approach (Hamburg and Mogyorodi, 2024) | "Model-based test[ing] … whereby test cases are generated and executed simultaneously" (Hamburg and Mogyorodi, 2024) | Online Testing, Model-based Testing (Hamburg and Mogyorodi, 2024) | On-the-Fly MBT (Hamburg and Mogyorodi, 2024) | 
Online Testing | Practice? | Testing that "interacts with the real application environment" (Washizaki, 2024, p. 5-6), or testing "whereby test cases are generated and executed simultaneously" (Hamburg and Mogyorodi, 2024) |  | On-the-Fly Testing (implied by Hamburg and Mogyorodi, 2024) | 
OO Web Testing | Approach |  | Web Application Testing, Object-Oriented Testing, Structure-based Testing, Data Flow Testing, Functional Testing (Kam, 2008, Tab. 1) |  | 
Open Beta Testing (Firesmith, 2015, p. 58) | Level (inferred from beta testing), Type (implied by Firesmith, 2015, p. 58) |  | Beta Testing (Firesmith, 2015, pp. 39, 58) |  | 
Open Loop Testing (Control Flow) | Technique? |  | Loop Testing |  | Not explicitly described by a source (in the context of software control flows); implied by the potential "closed loop testing"
Open Loop Testing (Control Systems) | Technique? |  | Automated Testing (ideally; Preuße et al., 2012, p. 1), Safety Testing, Non-functional Testing (can be; p. 1), Correctness Testing (can be; p. 6) Model-based Testing (implied by Preuße et al., 2012), Domain-Specific Testing? | Sometimes spelled with a hyphen (Preuße et al.) | "Will cause serious problems if the system complexity exceeds the human imagination for thinking about and running test cases" since "all possible input information would have to be considered, regardless whether practically relevant" (Preuße et al., 2012, p. 4). See also Pierre et al., (2017; if in scope)
Open Source Testing (Firesmith, 2015, p. 34) | Approach, Practice? |  | Reuse Testing (Firesmith, 2015, p. 34) |  | 
Operational (Acceptance) Testing | Level (IEEE, 2022, p. 22; Firesmith, 2015, p. 30; inferred from acceptance testing) | "Test[ing] to determine the correct installation, configuration and operation of a module and that it operates securely in the operational environment" (ISO/IEC, 2018) or "evaluate a system or component in its operational environment" (IEEE, 2017, p. 303), particularly "to determine if operations and/or systems administration staff can accept [it]" (Hamburg and Mogyorodi, 2024) | Acceptance Testing (IEEE, 2022, p. 22; Hamburg and Mogyorodi, 2024; Firesmith, 2015, p. 30; LambdaTest, 2024), Non-functional Testing (LambdaTest, 2024), Reliability Testing (likely incorrectly) (Bourque and Fairley, 2014, p. 4-6) | "Operational testing" and "operational acceptance testing" are treated as synonyms in this glossary, although there is sometimes a distinction (Firesmith, 2015, p. 30). Production Acceptance Testing (Hamburg and Mogyorodi, 2024), OAT, OT (Firesmith, 2015, p. 30) | Ensured by the use of TDD and ATDD (Washizaki, 2024, p. 6-9)
Operational Effectiveness Testing | Level (Firesmith, 2015, p. 30; inferred from operational testing) |  | Operational Testing (Firesmith, 2015, p. 30) |  | 
Operational Profile Testing | Approach | "Testing using a model of system operations (short duration tasks) and their probability of typical use" (Kam, 2008, p. 46; OG Musa) | Statistical Testing (Kam, 2008, p. 46; OG Musa), Scenario Testing?, Usage-based Testing? |  | 
Operational Suitability Testing | Level (Firesmith, 2015, p. 30; inferred from operational testing) |  | Operational Testing (Firesmith, 2015, p. 30) |  | 
Operations Organization Testing (Firesmith, 2015, p. 37) | Practice? |  | Organization-based Testing (Firesmith, 2015, p. 37), Operational Testing? |  | 
Operator Testing (Firesmith, 2015, p. 39) | Practice? |  | Role-based Testing (Firesmith, 2015, p. 39) |  | 
Organization-based Testing | Practice? |  | Role-based Testing? | Role-based Testing? | 
Orthogonal Array Testing | Technique? |  |  | Pairwise Testing? | See Mandl 1985
OT Organization Testing (Firesmith, 2015, p. 37) | Practice? |  | Independent Test Organization Testing (Firesmith, 2015, p. 37), Operational Testing? (Firesmith, 2015, p. 30) |  | 
Outside-In Testing (Firesmith, 2015, p. 28) | Level? (inferred from integration testing) |  | Integration Testing? (see bottom-up and top-down testing) |  | 
Outsourced Testing | Practice? | "Testing performed by people who are not co-located with the project team and are not fellow employees" (Hamburg and Mogyorodi, 2024) | Independent Tester Testing? |  | Also mentioned by Firesmith (2015, p. 41)
Page Testing (Doğan et al., 2014, Tab. 13; OG Ricca and Tonella, 2001; 2002) | Technique? (inferred from control flow testing) | Testing in which "every page in the SUT is visited at least once" (Doğan et al., 2014, Tab. 13; OG Ricca and Tonella, 2001; 2002) | Web Application Testing (Doğan et al., 2014, Tab. 13), Control Flow Testing? |  | 
Pair Testing | Technique (Washizaki, 2024, p. 5-14) | Testing in which "two persons, e.g. two testers, a developer and a tester, or an end-user and a tester, working together to find defects" (Kam, 2008, p. 46); can be structured so that "one generates and runs the test cases[ and] the other observes and analyzes the testing process" (Washizaki, 2024, p. 5-14), and usually involves "shar[ing] one computer and trad[ing] control of it" (Kam, 2008, p. 46) | Ad Hoc Testing (Washizaki, 2024, p. 5-14), Group Testing (Firesmith, 2015, p. 36), Embedded Tester Testing (Firesmith, 2015, p. 39), Developer Testing (implied by Gerrard, 2000a, p. 11) |  | "Allows [for] generating test cases with broad and better test coverage" (Washizaki, 2024, p. 5-14). Related to buddy testing
Pairwise Integration Testing | Level (inferred from integration testing) | "Integration testing that targets pairs of components that work together as shown in a call graph" (Hamburg and Mogyorodi, 2024) | Integration Testing (Hamburg and Mogyorodi, 2024) |  | 
Pairwise Testing | Technique (IEEE, 2022, pp. 7, 22; 2021, p. 2, Fig. 2; Washizaki, 2024, p. 5-11; Hamburg and Mogyorodi, 2024) | Testing that covers "all possible pairs" of some set of "unique pairs of P-V pairs, where each P-V pair within the pair is for a different test item parameter" (IEEE, 2021, p. 16) | Combinatorial Testing (IEEE, 2022, pp. 7, 22; 2021, pp. 2, 16, Fig. 2; Washizaki, 2024, p. 5-11), Specification-Based Testing (IEEE, 2022, p. 7; Hamburg and Mogyorodi, 2024), Model-based Testing (IEEE, 2022, p. 13; 2021, p. 6), All Combinations Testing (p. 16), t-wise Testing | Sometimes spelled with a hyphen (IEEE, 2021, pp. 2, 16, Fig. 2), All Pairs Testing (p. 16), Orthogonal Array Testing (OAT) (Washizaki, 2024, p. 5-11; implied by IEEE, 2021, p. 17; OG Mandl 1985 - investigate further) | "The most popular form of combinatorial testing" (IEEE, 2022, p. 7). See ISO 29119-4
Partial Regression Testing (Firesmith, 2015, p. 34) | Approach |  | Regression Testing (Firesmith, 2015, p. 34) |  | 
Password Cracking | Approach | "Security attack[s] recovering secret passwords stored in a computer system or transmitted over a network" (Hamburg and Mogyorodi, 2024) | Security Attacks (Hamburg and Mogyorodi, 2024), Security Testing (implied by "transmitted over a network" in Hamburg and Mogyorodi, 2024), Network Admin Testing? |  | See NIST.IR.7298
Path Testing | Technique (Washizaki, 2024, p. 5-13; Kam, 2008, p. 46) | Testing that "aims to execute all entry-to-exit control flow paths in a SUT's control flow graph" (Washizaki, 2024, p. 5-13) | Control Flow Testing (Washizaki, 2024, p. 5-13; implied by Hamburg and Mogyorodi, 2024), Structure-based Testing (Sharma et al., 2021, Fig. 1; Kam, 2008, p. 46), Dynamic Testing, W-Model Testing (Gerrard, 2000a, Fig. 5) | All-Paths Testing? (van Vliet, 2000, p. 421), All Round-Trip Paths Testing? (Kam, 2008, p. 15) | "Exhaustive path testing is generally not feasible because of loops" (Washizaki, 2024, p. 5-13), the exponential increase of possible paths with more branches (van Vliet, 2000, p. 421), and the "significant problem" of infeasible paths (Washizaki, 2024, p. 5-5). The number of test cases should be at least "the number of linearly independent paths through a program's source code" (Washizaki, 2024, p. 4-2). Possibly involves "path analysis"
Patterns-based Testing | Technique (Firesmith, 2015, p. 46) |  |  |  | 
Peer Reviews | Approach | "Review[s] of work products performed by peers [with similar abilities (Hamburg and Mogyorodi, 2024)] during development of the work products to identify defects for removal" (Washizaki, 2024, p. 12-13; OG [14], might be IEEE, 2017, p. 317?) | Reviews (IEEE, 2017, p. 317; Washizaki, 2024, p. 12-13; Hamburg and Mogyorodi, 2024), Static Analysis? (Washizaki, 2024, p. 12-13) |  | "Often performed during development of the work products to identify defects for removal", "increase the quality of the work product", and "reduce cost by fixing defects as soon as possible" (IEEE, 2017, p. 317). Potentially a byproduct of pair programming (or else there is another type of "Pair Reviews") (Washizaki, 2024, p. 12-14). See ISO 20246
Penetration Testing | Type (inferred from security testing and implied by Firesmith, 2015, p. 57), Technique (Hamburg and Mogyorodi, 2024) | Testing that "tests a system in its final production environment" (Washizaki, 2024, p. 13-5) by "exploit[ing] security vulnerabilities (known or unknown) to gain unauthorized access" (Hamburg and Mogyorodi, 2024), such as "submit[ting] malformed, malicious and random data to [its] entry points" (Washizaki, 2024, p. 13-5) | Security Testing (Washizaki, 2024, p. 13-4; Firesmith, 2015, p. 57; Gerrard, 2000b, pp. 28-29; implied by Hamburg and Mogyorodi, 2024), Web Application Testing, Attacks (Gerrard, 2000b, p. 28), implied by Doğan et al., 2014, p. 194), Online Testing?, Operational Testing? | Ethical Hacking Testing (Washizaki, 2024, p. 13-4), Ethical Hacking (Gerrard, 2000b, p. 28) | Should be conducted by security experts (Washizaki, 2024, p. 13-5). Related to fuzz testing? (Washizaki, 2024, p. 13-5)
Performance Efficiency Testing | Type (inferred from performance testing) | Testing to evaluate the "capability of a product to perform its functions within specified time and throughput parameters and be efficient in the use of resources under specified conditions" (ISO/IEC, 2023a; similar but less specific in IEEE, 2017, p. 319) | Performance Testing (implied by IEEE, 2017, p. 319), Reliability Testing, Dependability Testing (if it exists) (ISO/IEC, 2023a), Efficiency Testing? |  | Resources can include devices, configurations, energy, or materials (ISO/IEC, 2023a). Related to the idea of "performance deficiency" (IEEE, 2017, p. 319)
Performance Testing | Type (IEEE, 2022, pp. 7, 22, 26-27; 2021, p. 7; implied by Firesmith, 2015, p. 53) | Testing "conducted to evaluate the degree to which a test item accomplishes its designated functions within given constraints of time and other resources" (IEEE, 2022, p. 7; 2017, p. 320; similar in Moghadam, 2019, p. 1187) focused on "measuring the performance metrics" (Moghadam, 2019, p. 1187; similar in Hamburg and Mogyorodi, 2024) (such as the "system's capacity for growth" (Gerrard, 2000b, p. 23)), "detecting the functional problems appearing under certain execution conditions" (Moghadam, 2019, p. 1187), and "detecting violations of non-functional requirements under expected and stress conditions" (Moghadam, 2019, p. 1187; similar in Washizaki, 2024, p. 5-9) | Non-functional Testing (Washizaki, 2024, p. 5-8; Kam, 2008, pp. 46-47; Gerrard, 2000a, Tab. 2; 2000b, Tab. 1, p. 22), Performance-related Testing (IEEE, 2022, p. 22), Automated Testing (Dhok and Ramanathan, 2016, p. 895; Gerrard, 2000a, Tab. 2; 2000b, Tab. 1; implied by p. 32), Dynamic Testing (Gerrard, 2000a, Fig. 5, Tab. 2), Post-Deployment Monitoring (2000b, p. 32), Dynamic/Static Analysis (Dhok and Ramanathan, 2016, p. 895), Web Application Testing (can be; Gerrard, 2000b, p. 3) | Performance-related Testing (Moghadam, 2019, p. 1187) | "Performance, load and stress testing might considerably overlap in many areas" (Moghadam, 2019, p. 1187). "Performance issues are hard to detect in-house during testing and usually manifest in the field" (Dhok and Ramanathan, 2016, p. 895; OG [28]) and may include "repetitive computations, redundant loops, object bloat, latent performance bugs, and performance issues in clouds and smart phones" (Dhok and Ramanathan, 2016, p. 895). May be specific to "real-time constraints" (IEEE, 2022, p. 43). May be done by "us[ing] infrastructure/operations services" early on in the development process (Washizaki, 2024, p. 6-5) or automated test tools (Gerrard, 2000b, p. 24). Requires well-defined requirements, stable software, production hardware, and a controlled test environment, and estimating an "upper limit" for web application testing isn't feasible (p. 23); in this case, testing with test drivers may be sufficient (p. 24). Difference between this and performance efficiency testing? Related to efficiency testing (Kam, 2008, p. 46)
Periodic Built-In Testing (Firesmith, 2015, p. 31) | Practice? |  | Built-In Testing (Firesmith, 2015, p. 31) | PBIT (Firesmith, 2015, p. 31) | 
Personalization Testing (Firesmith, 2015, p. 53) | Type (implied by Firesmith, 2015, p. 53) |  | Flexibility Testing (Firesmith, 2015, p. 53) |  | 
Pharming | Approach | "Security attack[s] intended to redirect a website's traffic to a fraudulent website without the user's knowledge or consent" (Hamburg and Mogyorodi, 2024) | Security Attacks (Hamburg and Mogyorodi, 2024) |  | 
Physical Configuration Audits (PCAs) | Practice? (inferred from audits) | "Audit[s] conducted to verify that a configuration item, as built, conforms to the technical documentation that defines it" (IEEE, 2017, p. 322) | Audits (IEEE, 2017, p. 250) |  | 
Player Perspective Testing | Level? | "Testing done by testers from a player's perspective to validate player satisfaction" (Hamburg and Mogyorodi, 2024) | Satisfaction Testing (if it exists) (Hamburg and Mogyorodi, 2024) |  | 
Playtesting | Level? | "Testing of a game [performed] by players to identify failures and gather feedback" (Hamburg and Mogyorodi, 2024) | Ad Hoc Testing (Hamburg and Mogyorodi, 2024), User as Tester Testing |  | 
Portability Testing | Type (IEEE, 2022, pp. 7, 22; implied by its quality) | Testing to evaluate the "capability of a product to be adapted to changes in its requirements, contexts of use, or system environment" (ISO/IEC, 2023a; similar in IEEE, 2022, p. 7; 2017, pp. 184, 329; and Hamburg and Mogyorodi, 2024) |  | Flexibility Testing (ISO/IEC, 2023a); Transportability Testing (implied by IEEE, 2017, p. 329) | Related to co-existence and installability testing, as well as adaptability and replaceability testing (if they exist) (Hamburg and Mogyorodi, 2024) and potentially compatibility testing, and can improve user assistance and interaction capability (ISO/IEC, 2023a) "Can be measured either as the extent to which a product can be used by additional types of users to achieve additional types of goals … or by a capability to be modified to support adaptation for new types of users", etc. (ISO/IEC, 2011)
Positive Testing | Approach, Technique? (IEEE, 2021, p. 10) | Testing that uses "input values that the test item should accept as correct" (IEEE, 2021, p. 10) |  | Valid Testing (implied by IEEE, 2021, p. 10) | 
Post-Deployment Monitoring | Approach, Level? (Gerrard, 2000a, p. 13) | "Monitor[ing a] … site in production" (Gerrard, 2000b, p. 32; similar in 2000a, p. 15), including the server hardware, CGI programs, and links (2000b, p. 32) | Automated Testing (Gerrard, 2000a, pp. 13, 15), Performance Testing (implied by p. 15), Regression Testing |  | May include the use of "retain[ed] automated tests" (Gerrard, 2000a, p. 13; similar in 2000b, p. 34), remote monitoring services, and/or consultants (2000b, p. 34)
Post-Release Testing | Type (Hamburg and Mogyorodi, 2024) | "Testing to ensure that the release is performed correctly and the application can be deployed" (Hamburg and Mogyorodi, 2024) | Online Testing?, Operational Testing? |  | 
Power Testing? | Approach | Testing "based on power consumption and battery failure" (IEEE, 2022, p. 43); term is original | Performance Testing |  | 
Power-Up Built-In Testing (Firesmith, 2015, p. 31) | Practice? |  | Built-In Testing (Firesmith, 2015, p. 31) | PupBIT (Firesmith, 2015, p. 31) | 
Prime Contractor Testing (Firesmith, 2015, p. 37) | Practice? |  | Development Organization Testing (Firesmith, 2015, p. 37) |  | 
Prime Path Testing? (implied by Doğan et al., 2014, p. 184) | Technique? |  | Model-based Testing (Doğan et al., 2014, p. 184) |  | See Sakamoto et al., (2013)
Prioritization Testing | Practice? | Testing that "schedule[s] test cases to increase the rate [and likelihood] of fault detection, … the coverage of code under test, and … reliability" (Washizaki, 2024, p. 5-8) |  |  | What does "schedule" mean in this context?
Privacy Testing | Approach | Testing that "assess[es] the security and privacy of users' personal data to prevent local attacks" (Washizaki, 2024, p. 5-10) | Security Testing? |  | Assesses policies and profile/data management (Washizaki, 2024, p. 5-10); seems to overlap with IEEE's definition of security testing
Procedure Testing | Type (IEEE, 2022, pp. 7, 22; 2017, p. 337; OG IEEE, 2013) | Testing "conducted to evaluate whether procedural instructions for interacting with a test item or using its outputs meet user requirements and support the purpose of their use" (IEEE, 2022, p. 7; 2017, p. 337; OG IEEE, 2013) | Functional Suitability Testing (IEEE, 2022, p. 7; 2017, p. 337; OG IEEE, 2013) |  | 
Process-Driven Scripting | Technique (Hamburg and Mogyorodi, 2024) | Testing "where scripts are structured into scenarios which represent use cases of the software under test" and "can be parameterized with test data" (Hamburg and Mogyorodi, 2024) | Scripted Testing, Scenario Testing (Hamburg and Mogyorodi, 2024) |  | 
Processor-in-the-Loop Testing (Firesmith, 2015, p. 23) | Level (implied by system testing) |  | System Testing (Firesmith, 2015, p. 23) | PIL Testing (Firesmith, 2015, p. 23) | 
Product Lines Testing (Doğan et al., 2014, Tab. 1) | Approach |  |  |  | See Neto et al., (2012; 2011a; 2011b) and Engström and Runeson (2011)
Production Acceptance Testing | Level (Firesmith, 2015, p. 30; inferred from acceptance testing) |  | Acceptance Testing (Firesmith, 2015, p. 30) | Operational Acceptance Testing (Hamburg and Mogyorodi, 2024), PAT (Firesmith, 2015, p. 30) | 
Production Verification Testing | Level (IEEE, 2022, p. 22; inferred from acceptance testing) |  | Acceptance Testing (IEEE, 2022, p. 22), Online Testing?, Operational Testing? | Production Acceptance Testing? | 
Prognostics and Health Management (Firesmith, 2015, p. 31) | Practice? |  | Ongoing Built-In Testing (Firesmith, 2015, p. 31), Self-Testing? (implied by Firesmith, 2015, p. 31) | PMH (Firesmith, 2015, p. 31) | Not sure what this is; investigate
Programmer Testing (Firesmith, 2015, p. 39) | Practice? |  | Developer Testing (Firesmith, 2015, p. 39) | Developer Testing? | 
Proofs of Correctness | Technique, Artifact (IEEE, 2017, p. 355) | "Formal technique[s] used to prove mathematically that a computer program satisfies its specified requirements" (IEEE, 2017, p. 355) | Formal Testing, Mathematical-based Testing, Static Testing? |  | 
Proofs of Partial Correctness (implied by proofs of correctness (IEEE, 2017, p. 355) and partial correctness (p. 314)) | Technique, Artifact (IEEE, 2017, p. 355) | "Formal technique[s] used to prove mathematically" (IEEE, 2017, p. 355) "that a program's output assertions follow logically from its input assertions and processing steps" (p. 314) | Formal Testing, Mathematical-based Testing, Static Testing? |  | Difference between this and total correctness?
Proofs of Total Correctness (implied by proofs of correctness (IEEE, 2017, p. 355) and partial correctness (p. 314)) | Technique, Artifact (IEEE, 2017, p. 355) | "Formal technique[s] used to prove mathematically" (IEEE, 2017, p. 355) "that a program's output assertions follow logically from its input assertions and processing steps" (p. 480) | Formal Testing, Mathematical-based Testing, Static Testing? |  | Difference between this and partial correctness?
Protection System Testing? (Forsyth et al., 2004) | Approach |  | System Testing, Domain-Specific Testing? |  | Often performed using "real time simulators" (Forsyth et al., 2004, p. 332)
Qualification Operational Testing | Level (inferred from operational testing) |  | Operational Testing (Firesmith, 2015, p. 30), Qualification Testing? | QOT (Firesmith, 2015, p. 30) | Difference between this and qualification testing?
Qualification Testing | Level? | "Testing … to demonstrate that a software product meets its specifications and is ready for use in its target environment or integration with its containing system" (IEEE, 2017, p. 360; OG ISO/IEC, 2008) |  | Operational (Acceptance) Testing? | "Conducted by the developer and witnessed by the acquirer (as appropriate)" (IEEE, 2017, p. 360). Including "software" in its definition may be incorrect, since hardware qualification testing exists (Firesmith, 2015, p. 21). Difference between this and qualification operational testing?
Quick Testing | Technique (Washizaki, 2024, p. 5-14) | Testing "in which a very small test suite is selected and executed" (Washizaki, 2024, p. 5-14) | Ad Hoc Testing (Washizaki, 2024, p. 5-14) |  | "Guarantees that no failure can be experienced because of SUT components that are not fully operational" (Washizaki, 2024, p. 5-14), but this is not elaborated on
Random Testing | Technique (IEEE, 2022, pp. 7, 22, 36; 2021, p. 5, Fig. 2; Washizaki, 2024, p. 5-12; Hamburg and Mogyorodi, 2024; Firesmith, 2015, p. 46) | Testing "based on generating test cases to exercise randomly selected test item inputs" (IEEE, 2022, p. 7; 2021, p. 5) which can be "generated based on an operational profile" (Hamburg and Mogyorodi, 2024) | Specification-based Testing (IEEE, 2022, pp. 7, 22; 2021, p. 5, Fig. 2; Washizaki, 2024, p. 5-12; Hamburg and Mogyorodi, 2024), Usage-based Testing (Washizaki, 2024, p. 5-15; implied by use operational profile by Hamburg and Mogyorodi, 2024), Mathematical-based Testing (IEEE, 2022, p. 36) | Randomized Testing (Doğan et al., 2014, p. 192; OG Halfond and Orso, 2007), Cat on the Keyboard Testing? (Firesmith, 2015, p. 46) | Often used in automated testing (Washizaki, 2024, p. 5-12) or to support non-functional testing, such as performance testing (Kam, 2008, p. 46) or reliability testing (Kam, 2008, p. 46; van Vliet, 2000, p. 439). Implied to be related to statistical testing (Washizaki, 2024, p. 5-15)
Random Walk Testing (Kam, 2008, p. 12; OG [18]) | Technique? (inferred from path testing) | Testing that "ensures arbitrary path selection with the same probability to be chosen" (Kam, 2008, p. 12) | Path Testing, Web Application Testing (implied by Kam, 2008, p. 12) |  | 
Rapid Prototyping Testing | Practice? | Testing performed on prototypes developed "early in the development process to permit early feedback and analysis" (IEEE, 2017, p. 365) | Lifecycle-based Testing, At-the-Beginning Testing? |  | 
Reactive Testing | Practice? | "Testing that dynamically responds to the behavior of the test object and to test results being obtained" (Hamburg and Mogyorodi, 2024) | Dynamic Testing (implied by Hamburg and Mogyorodi, 2024) |  | What does "responds" mean in this context?
Recovery Testing | Type (IEEE, 2022, p. 22; implied by the quality of "recoverability" (ISO/IEC, 2023a; IEEE, 2017, p. 370; Washizaki, 2024, p. 5-9)) | Testing of "software restart capabilities after a system crash or other disaster" (Washizaki, 2024, p. 5-9) including "recover[ing] the data directly affected and re-establish[ing] the desired state of the system" (ISO/IEC, 2023a) so that the system "can perform required functions" (IEEE, 2017, p. 370) | Performance(-related) Testing (IEEE, 2022, p. 22), Reliability Testing (IEEE, 2017, p. 375; Washizaki, 2024, pp. 4-11, 7-10), Availability Testing (IEEE, 2017, p. 38), Fault Tolerance Testing (Washizaki, 2024, p. 4-11), Non-functional Testing (Washizaki, 2024, p. 5-9), Usability Testing? (Washizaki, 2024, p. 5-10), Dynamic Testing? (implied by Gerrard, 2000a, Fig. 5) | Recoverability Testing (Kam, 2008, p. 47), Restart & Recovery (Testing)? (Gerrard, 2000a, Fig. 5) | May be done through simulations (Washizaki, 2024, p. 5-28). Difference between this and disaster/recovery testing?
Red Team Testing (Firesmith, 2015, p. 57) | Type (implied by Firesmith, 2015, p. 57) |  | Penetration Testing (Firesmith, 2015, p. 57) |  | 
Regression Testing | Approach, Level? (Barbosa et al., 2006, p. 3) | The "selective retesting of a system or component to verify that modifications [to a test item or to its operational environment (IEEE, 2022, p. 8; similar in Kam, 2008, p. 47), such as refactoring (Lahiri et al., 2013, p. 345) or bug fixes (p. 346)] have not caused unintended effects", specifically in the areas of "functionality, reliability [and] performance", and have "not introduced additional defects" (IEEE, 2017, p. 372), primarily "in unmodified parts of the test item" (IEEE, 2022, p. 8; similar in Hamburg and Mogyorodi, 2024) | Functional Testing, Non-functional Testing, Continuous Testing (Washizaki, 2024, p. 5-8), Change-Related Testing (Hamburg and Mogyorodi, 2024), Web Application Testing (Doğan et al., 2014, Tabs. 8, 22, p. 185), Developer Testing (can be) (Gerrard, 2000a, p. 11), Relative Correctness Testing (if it exists) | Non-regression Testing (Washizaki, 2024, p. 5-8) | "Does not test that the modification works correctly"; this is "retesting" (IEEE, 2022, p. 8; also described as separate by Washizaki, 2024, p. 6-5; Firesmith, 2015, p. 34). Interesting to note it is sometimes described as such (Washizaki, 2024, pp. 7-5 to 7-6; IEEE, 2017, p. 372), maybe just in the sense of "testing again"? Should be part of any test strategy and its level should be "based on a knowledge of the risks associated with developers making changes" (IEEE, 2022, p. 23), although it can be applied to any level (Washizaki, 2024, p. 5-8), and "play[s] an important role in software engineering operations" (Washizaki, 2024, p. 6-5) and "maintenance" (Washizaki, 2024, p. 7-5). Can be supported by tools, such as "tinderboxes" (IEEE, 2017, p. 478). The use of "selective" seems to implicitly describe partial regression testing (see Firesmith, 2015, p. 34)
Regulatory Acceptance Testing | Level (Firesmith, 2015, p. 30; inferred from acceptance testing) | "Testing performed to determine the compliance of the test object" (Hamburg and Mogyorodi, 2024) | Acceptance Testing (Hamburg and Mogyorodi, 2024; Firesmith, 2015, p. 30) | Regulation Acceptance Testing (RAT)? (Firesmith, 2015, p. 30) | Difference between this and acceptance testing?
Relative Correctness Testing (implied by Lahiri et al., 2013, p. 345 and correctness testing) | Approach |  | Correctness Testing |  | Weaker than absolute correctness testing (Lahiri et al., 2013, p. 345)
Reliability Enhancement Testing (Firesmith, 2015, p. 55) | Type (implied by Firesmith, 2015, p. 55) |  | Reliability Testing (Firesmith, 2015, p. 55) |  | 
Reliability Growth Testing (Firesmith, 2015, p. 55) | Type (implied by Firesmith, 2015, p. 55) |  | Reliability Testing (Firesmith, 2015, p. 55) |  | 
Reliability Mechanism Testing (Firesmith, 2015, p. 55) | Type (implied by Firesmith, 2015, p. 55) |  | Reliability Testing (Firesmith, 2015, p. 55) |  | 
Reliability Testing | Type (IEEE, 2022, pp. 8, 22; 2017, p. 375; 2013, p. 5; implied by its quality (ISO/IEC, 2023a; IEEE, 2017, p. 425) and by Firesmith, 2015, p. 53) | Testing that evaluates the "capability of a product to perform specified functions under specified conditions for a specified period of time without interruptions and failures" (ISO/IEC, 2023a); can be mesaured as "the frequency with which failures occur" (IEEE, 2022, p. 8; 2013, p. 5) or the "probability that software will not cause the failure of a system" (IEEE, 2017, p. 425) | Non-functional Testing (Washizaki, 2024, p. 5-9; Kam, 2008, p. 46; Gerrard, 2000a, Tab. 2; 2000b, Tab. 1, p. 22), Security Testing (implied by IEEE, 2017, p. 404), Web Application Testing (Doğan et al., 2014, p. 185), Performance Testing (Gerrard, 2000b, pp. 23, 26), Automated Testing (2000a, Tab. 2; 2000b, Tab. 1, p. 26), Smoke Testing, Dynamic Testing (2000a, Tab. 2; 2000b, Tab. 1) | Soak Testing (Gerrard, 2000a, Tab. 2; 2000b, Tab. 1, p. 26), Dependability Testing (if it exists, although this has a wider scope) (ISO/IEC, 2023a) | Often uses statistical models of user behaviour, reliability growth models (Washizaki, 2024, p. 5-9), and/or random testing (van Vliet, 2000, p. 439) and may be facilitated by DevOps (Washizaki, 2024, p. 5-9) such as "infrastructure/operations services", which can be done early on in the development process (Washizaki, 2024, p. 6-5). Can be done using "the test-retest method, the alternative form method, the split-halves method and the internal consistency method" (verify this applies to software) (Washizaki, 2024, p. 18-14) and can find "obscure bugs" "over extended periods" (Gerrard, 2000b, p. 23), which is how they should be performed (p. 26)
Remote Testing (Jard et al., 1999) | Practice? |  | Asynchronous Testing (implied by Jard et al., 1999), Manual Testing (implied by p. 26) |  | "Error-prone" (Jard et al., 1999, p. 25)
Request Testing (Doğan et al., 2014, Tab. 13; OG Peng and Lu, 2011) | Approach |  | Web Application Testing (Doğan et al., 2014, Tab. 13) |  | 
Requirement(s)-based Testing | Technique (IEEE, 2022, pp. 8, 22; 2021, p. 5, Fig. 2), Approach (Hamburg and Mogyorodi, 2024) | Testing "based on test objectives and test conditions derived from [atomic (IEEE, 2022, p. 8; 2021, p. 5)] requirements, e.g. tests that exercise specific functions or probe non-functional attributes such as reliability or usability" (Kam, 2008, p. 47) | Specification-based Testing (IEEE, 2022, pp. 8, 22; 2021, p. 5, Fig. 2; Firesmith, 2015, p. 47?), Risk-based Testing (IEEE, 2022, p. 20), Model-based Testing? (implied by IEEE, 2022, p. 13; 2021, p. 6), User-session-based Testing (Doğan et al., 2014, p. 183, implied by p. 193) | Software Quality Evaluations? (IEEE, 2017, p. 425; OG ISO/IEC, 2014) | May involve "requirements analysis"
Requirements Animation | Approach |  | Static Testing, W-Model Testing (Gerrard, 2000a, Fig. 4), Requirements-driven Testing |  | 
Requirements Engineer Testing (Firesmith, 2015, p. 39) | Practice? |  | Developer Testing (Firesmith, 2015, p. 39), Requirements-driven Testing? |  | 
Requirements-driven Testing | Approach | Testing that "verifies" the "system meets system requirements" (Firesmith, 2015, p. 33) |  |  | Difference between this and requirements-based testing?
Resource Utilization Testing (Kam, 2008, p. 47) | Type (implied by its quality (ISO/IEC, 2023a)) | The "capability of a product to use no more than the specified amount of resources to perform its function under specified conditions" (ISO/IEC, 2023a) | Performance Efficiency Testing (ISO/IEC, 2023a), Efficiency Testing (implied by Kam, 2008, p. 47) | Storage Testing? (but this seems incomplete) (Hamburg and Mogyorodi, 2024) | 
Response-Time Testing | Approach | Testing that evaluates the "capability of a product to perform its specified function under specified conditions so that the response time … meet[s] the requirements" (ISO/IEC, 2023a) | Performance Testing (Washizaki, 2024, p. 5-9; implied by IEEE, 2022, p. 22); Time Behaviour Testing? (ISO/IEC, 2023a) |  | Good to use if the software may have "a large number of concurrent users" (IEEE, 2022, p. 45). Captured as part of "object load and timing" by Gerrard (2000a, Tab. 2; 2000b, Tab. 1)
Retesting | Approach | "Testing performed to check that modifications made to correct a fault have successfully removed the fault" (IEEE, 2022, p. 8; similar in 2017, p. 386 and Hamburg and Mogyorodi, 2024) or "testing that runs test cases that failed the last time they were run, [sic] in order to verify the success of corrective actions" (Kam, 2008, p. 47) | Change-Related Testing (Hamburg and Mogyorodi, 2024) | Sometimes spelled with a hyphen (Hamburg and Mogyorodi, 2024), Confirmation Testing (IEEE, 2022, p. 8; 2017, p. 386; Kam, 2008, p. 43) | Should be part of any test strategy and its level should be "based on a knowledge of the risks associated with developers making changes" (IEEE, 2022, p. 23) and "play[s] an important role in software  engineering operations" (Washizaki, 2024, p. 6-5). "In most cases, the original test cases associated with the fixed code are used for retesting [as prescribed by IEEE (2017, p. 386)], but they are sometimes supplemented by new test cases that provide improved coverage" (IEEE, 2022, p. 35)
Reuse Testing (Firesmith, 2015, p. 34) | Approach |  |  |  | 
Reviews | Approach | "Process[es] or meeting[s] during which a software product is presented to project personnel, managers, users, customers, user representatives, or other interested parties for comment or approval" (IEEE, 2017, p. 388) "to detect defects or to provide improvements" (Hamburg and Mogyorodi, 2024) | Static Testing (IEEE, 2022, pp. 9, 17, 25, 28; Hamburg and Mogyorodi, 2024; Gerrard, 2000a, p. 12, Fig. 4; 2000b, p. 3), W-Model Testing (Gerrard, 2000a, Fig. 4), Static Analysis? (Washizaki, 2024, p. 12-13) |  | "Can identify issues early in development or even before a component is designed" (Washizaki, 2024, p. 12-13; implied by Gerrard, 2000a, pp. 9-10). See also ISO/IEC 20246
ReWeb Testing | Approach |  | Web Application Testing, UML Testing, Structure-based Testing, Control Flow Testing, Functional Testing (Kam, 2008, Tab. 1) |  | 
Risk-based Testing | Approach, Technique? (IEEE, 2022, p. 18; 2021, p. vii) | Testing "in which the management, selection, prioritization, and use of testing activities and resources are consciously based on corresponding types and levels of analysed risk" (IEEE, 2022, p. 8; 2017, p. 394; OG 2013) | Specification-based Testing (Firesmith, 2015, p. 47), Dynamic Testing? (IEEE, 2022, p. 18) |  | Recommended technique for "choosing the subset of possible tests that are most likely to uncover issues of interest" (IEEE, 2022, p. 18) and helps to "determine the set of techniques … applicable in specific situations" (IEEE, 2021, p. vii) "for a given project or organization" (p. 7) and "design[] effective tests to find faults" without "worry[ing] about doing 'too little' testing" (Gerrard, 2000a). May involve "risk analysis". See the ISO/IEC 25000 SQuaRE family of standards and Gerrard
Robustness Testing | Type (implied by Firesmith, 2015, p. 53) | Testing the "degree to which a system or component can function correctly in the presence of invalid inputs or stressful environmental conditions" (IEEE, 2017, p. 394) | Boundary-Value Analysis (Washizaki, 2024, p. 5-11), Stress Testing (implied by Moghadam, 2019, p. 1188) | Fault Tolerance Testing (implied by Hamburg and Mogyorodi, 2024) | Related to error/fault tolerance (IEEE, 2017, p. 394) and potentially stress testing?
Role-based Reviews | Approach | Reviews "in which a work product is evaluated from the perspective of different stakeholders" (Hamburg and Mogyorodi, 2024) | Reviews (Hamburg and Mogyorodi, 2024), Role-based Testing, Scenario Testing? |  | 
Role-based Testing (Firesmith, 2015, p. 39) | Practice? |  |  |  | 
Runtime Assertion Checking (RAC) | Practice? | "Testing … [separation logic] specifications during program execution", with "any violations result[ing] in special errors being reported" (Chalin et al., 2006, p. 343) | Assertion Checking (Chalin et al., 2006, p. 343), Dynamic Analysis?, Specification-based Testing? |  | 
Safety Demonstrations | Artifact | "Bod[ies] of evidence and rationale that show[] an item is justified as being safe within allowed limits on risk" (IEEE, 2017, p. 397; OG ISO/IEC, 2011) | Safety Testing |  | 
Safety Engineer Testing (Firesmith, 2015, p. 39) | Practice? |  | Developer Testing (Firesmith, 2015, p. 39), Safety Testing |  | 
Safety Testing (Firesmith, 2015, p. 53; Kam, 2008, p. 47) | Type (implied by its quality (ISO/IEC, 2023a; IEEE, 2017, pp. 397, 427; OG 1994) and by Firesmith, 2015, p. 53) | Testing the "capability of a product under defined conditions to avoid a state in which human life, health, property, or the environment is endangered" (ISO/IEC, 2023a; similar in IEEE, 2017, p. 397) or "freedom from software hazards" (IEEE, 2017, p. 427; OG 1994) |  |  | May be based on safety requirements (see IEEE, 2017, p. 398; OG ISO/IEC, 2011). See ISO/IEC/IEEE 12207:2017 and ISO/IEC Guide 51
Sandwich Testing | Level (inferred from integration testing) | Testing where "slices" of the system are tested across multiple layers (inferred from Sangwan and LaPlante, 2006, Fig. 3) | Integration Testing (Washizaki, 2024, p. 5-7; Sharma et al., 2021, p. 603; Sangwan and LaPlante, 2006, p. 27) | Mixed Testing (Washizaki, 2024, p. 5-7) | 
Scalability Testing | Type (implied by its quality (ISO/IEC, 2023a) and by Firesmith, 2015, p. 53) | Testing the "capability of a product to handle growing or shrinking workloads or to adapt its capacity to handle variability" (ISO/IEC, 2023a; similar in Gerrard and Thompson, 2002) | Portability Testing (ISO/IEC, 2023a); Non-functional Testing (Washizaki, 2024, p. 5-8) |  | "Particularly important in distributed or high-performance systems" (Washizaki, 2024, p. 5-9) and may be done by "us[ing] infrastructure/operations services" early on in the development process (Washizaki, 2024, p. 6-5). Washizaki seems to define it as usability testing (2024, p. 5-9), despite correctly defining "scalability" (2024, p. 5-5). Related to elasticity testing?
Scenario Testing | Technique (IEEE, 2022, pp. 9, 22; 2021, pp. 5, 8, Fig. 2; 2017, p. 400; OG 2013; Washizaki, 2024, p. 5-12; Sangwan and LaPlante, 2006, p. 26) | Testing "based on exercising sequences of interactions between the test item and other systems," including users (IEEE, 2022, p. 9; 2021, p. 5; similar on p. 20), to test "usage flows involving the test item"; this should include "typical" and "alternative" scenarios, with the latter including "abnormal use, extreme or stress conditions, exceptions and error handling" (p. 20) | Specification-based Testing (IEEE, 2022, pp. 9, 22; 2021, p. 5, Fig. 2; Washizaki, 2024, p. 5-12; Hamburg and Mogyorodi, 2024; Firesmith, 2015, p. 47), Model-based Testing (IEEE, 2021, p. 20; implied by Bourque and Fairley, 2014, p. 4-10), System Testing, Acceptance Testing (can be; IEEE, 2021, p. 20), Stress Testing, Error-based Testing, End-to-End Testing, Functional Testing (implied by p. 20), Object-Oriented Testing (implied by Sangwan and LaPlante, 2006, p. 27) | User Scenario Testing, Use Case Testing (Hamburg and Mogyorodi, 2024), Scenario-based Testing (Sangwan and LaPlante, 2006, p. 26) | "Often used with test automation harnesses" (Washizaki, 2024, p. 5-12). See Desikan and Ramesh 2007
Scenario Walkthroughs | Approach |  | Static Testing, W-Model Testing (Gerrard, 2000a, Fig. 4), Walkthroughs, Scenario Testing |  | 
Scenario-based Reviews | Approach | Testing "to determine [a work product's] ability to address specific scenarios" (Hamburg and Mogyorodi, 2024) | Reviews (Hamburg and Mogyorodi, 2024), Scenario Testing |  | 
Scripted Testing | Practice (IEEE, 2022, pp. 20, 22) | "Testing performed based on a documented test script" (IEEE, 2022, p. 9; 2017, p. 403; OG 2013) or "written instructions in a test case" (IEEE, 2017, p. 403; OG 2013) | Dynamic Testing (IEEE, 2017, p. 403; OG 2013), Manual Testing (usually) (IEEE, 2022, pp. 9, 33; 2017, p. 403; Hamburg and Mogyorodi, 2024), Automatic Testing ("typically requires more detail") (IEEE, 2022, p. 33; Hamburg and Mogyorodi, 2024; Firesmith, 2015, p. 44) | Script-based Testing? (Firesmith, 2015, p. 44) | "Helps achieve required test coverage levels" (IEEE, 2022, p. 33)
Security Attacks | Approach | "Attempt[s] to gain unauthorized access to a component or system, resources, information, or … to compromise system integrity" (Hamburg and Mogyorodi, 2024) | Security Testing, Attacks, Integrity Testing (if it exists) |  | "An example of a security attack would be to block access to software libraries" (IEEE, 2022, p. 34). Could be malicious or as a genuine part of testing; see note on attacks. See NIST.IR.7298
Security Audits | Practice? | Audits that "aim to ensure that all of the products installed on a site are secure when checked against the known vulnerabilities for those products" (Gerrard, 2000b, p. 28) | Security Testing, Audits |  | Either performed manually (often by consultants (Gerrard, 2000b, p. 34)) or by automated scans "that perform ping sweeps, port scans, [and] operating system detection" (p. 28)
Security Engineer Testing (Firesmith, 2015, p. 39) | Practice? |  | Developer Testing (Firesmith, 2015, p. 39), Security Testing |  | 
Security Testing | Type (IEEE, 2022, pp. 9, 22, 26-27; 2021, p. 7; 2017, p. 405; OG 2013; implied by its quality (ISO/IEC, 2023a; Washizaki, 2024, p. 13-4) and by Firesmith, 2015, p. 53) | Testing that evaluates the "capability of a product to protect information and data [including data in transmission (ISO/IEC, 2023a)] so that persons or other products have the degree of data access appropriate to their types and levels of authorization, and to defend against attack patterns by malicious actors" (ISO/IEC, 2023a; similar in IEEE, 2022, p. 9; Washizaki, 2024, pp. 5-9, 13-4) | Reliability Testing (ISO/IEC, 2023a), Functionality Testing (Gerrard, 2000a, Tab. 2; 2000b, Tab. 1; implied by Kam, 2008, p. 47), Dynamic Testing (Gerrard, 2000a, Fig. 5, Tab. 2), Sys Admin Testing (2000b, p. 29), Post-Deployment Monitoring (2000b, pp. 32-33), Non-functional Testing, (2000a, Tab. 2; 2000b, Tab. 1), System Testing? (implied by 2000a, Fig. 5), Dependability Testing (if it exists) (ISO/IEC, 2023a), Security Testing? | Information Security Testing (Hamburg and Mogyorodi, 2024) | Verifies "confidentiality, integrity, and availability" and usually includes negative testing (Washizaki, 2024, p. 5-9); can be supported by fuzz testing (Godefroid and Luchaup, 2011, p. 23). Good to use when the software will be widely available (IEEE, 2022, p. 45)
Session-based Testing | Approach (Hamburg and Mogyorodi, 2024) | Testing "in which test activities are planned as test sessions" (Hamburg and Mogyorodi, 2024), potentially based on navigation models or logs (Doğan et al., 2014, Tab. 22) | Web Application Testing (Doğan et al., 2014, Tab. 22) |  | 
Shoe Testing (Firesmith, 2015, p. 51) | Technique? |  | Random Testing (Firesmith, 2015, p. 51) |  | 
Shutdown Built-In Testing (Firesmith, 2015, p. 31) | Practice? |  | Built-In Testing (Firesmith, 2015, p. 31) | SBIT (Firesmith, 2015, p. 31) | 
Sign Change Coverage (Testing?) | Approach | Testing of "the coverage of neurons activated with both positive and negative activation values in a neural network for a set of tests" (Hamburg and Mogyorodi, 2024) | ML Model Testing |  | 
Sign-Sign Coverage (Testing?) | Approach | Testing of "the coverage achieved if by changing the sign of each neuron it can be shown to individually cause one neuron in the next layer to change sign while all other neurons in the next layer do not change sign for a set of tests" (Hamburg and Mogyorodi, 2024) | ML Model Testing |  | See ISO 29119-11
Similarity-based Prioritization Testing | Practice? | Testing that prioritizes test cases "starting from those most dissimilar according to a predefined distance function" (Washizaki, 2024, p. 5-8) | Prioritization Testing (Washizaki, 2024, p. 5-8) |  | 
Single-Hit Decision Table | Technique (inferred from decision table testing) | Testing "based on exercising decision rules" (IEEE, 2022, p. 4) in a single-hit decision table (IEEE, 2017, p. 415; OG ISO, 1984) | Decision Table Testing (IEEE, 2017, p. 175; OG ISO, 1984) |  | 
Site Acceptance Testing | Level (Firesmith, 2015, p. 30; inferred from acceptance testing) | "Acceptance testing by users/customers at their site, [sic] to determine whether or not a component or system satisfies the user/customer needs and fits within the business processes" (Kam, 2008, p. 47) | Acceptance Testing (Firesmith, 2015, p. 30; Kam, 2008, p. 47) | SAT (Firesmith, 2015, p. 30) | "Normally includ[es] hardware as well as software" (Kam, 2008, p. 47)
Slicing? (Kam, 2008, Tab. 1) | Approach |  |  |  | 
Smoke Testing | Technique (Washizaki, 2024, p. 5-14) | A subset of all testing (Kam, 2008, p. 47) that "ensures that the SUT's core functionalities behave properly" (Washizaki, 2024, p. 5-14; similar in Kam, 2008, p. 47) or testing that "the SUT is operational before the planned testing begins" (Washizaki, 2024, p. 5-14; similar in Hamburg and Mogyorodi, 2024) | Ad Hoc Testing, Quick Testing (Washizaki, 2024, p. 5-14), Unscripted Testing (implied by Washizaki, 2024, p. 5-14 and Hamburg and Mogyorodi, 2024), Integration Testing (Sharma et al., 2021, p. 603), Automated Testing (often) (Gerrard, 2000a, p. 13), Offline Testing? | Build Verification Testing (Washizaki, 2024, p. 5-14), Sanity Testing (Hamburg and Mogyorodi, 2024), Intake Testing (Hamburg and Mogyorodi, 2024), Confidence Testing (Hamburg and Mogyorodi, 2024) | Should be prioritized in the presence of "severe time pressure" (Gerrard, 2000a, p. 13). "Prevents failures because of the test environment" (Washizaki, 2024, p. 5-14). Seems to be implied to be the responsibility of DevOps (Washizaki, 2024, p. 6-9)
SOA Testing (Doğan et al., 2014, Tab. 1) | Approach |  |  |  | See Palacios et al., (2011) and Mesbah and Prasad (2011)
Software Design Audits | Practice? (inferred from audits) | "Review[s] of … software product[s] to determine compliance with requirements, standards, and contractual documents" (IEEE, 2017, p. 420) | Audits, Reviews (IEEE, 2017, p. 420) |  | Is this specific to the software's design, or to the software itself?
Software Qualification Testing | Level? | "Testing performed on completed, integrated software to provide evidence for compliance with software requirements" (Hamburg and Mogyorodi, 2024) | Safety Testing (implied by Knüvener Mackert GmbH, 2022, pp. 36-37), System Testing?, Dynamic Testing? |  | Difference between this and system testing?
Software-in-the-Loop Testing (Firesmith, 2015, p. 23) | Level (implied by system testing) | "Testing performed using real software in a simulated environment or with experimental hardware" (Hamburg and Mogyorodi, 2024) | System Testing (Firesmith, 2015, p. 23), Formal Testing (Preuße et al., 2012, p. 3), Dynamic Testing (Hamburg and Mogyorodi, 2024), Integration Testing? (Knüvener Mackert GmbH, 2022, p. 153) | SiL Testing (Hamburg and Mogyorodi, 2024; Preuße et al., 2012, p. 3), SIL Testing (Firesmith, 2015, p. 23), SiL Verification? (Preuße et al., 2012, p. 7) | Used by "the scientific community" and is "vendor- and hardware-independent" (Preuße et al., 2012, p. 2)
SoS Integration Testing (Firesmith, 2015, p. 23) | Level (implied by system testing) |  | System Testing (Firesmith, 2015, p. 23), Integration Testing |  | 
SoS Testing (Firesmith, 2015, p. 23) | Level (implied by system testing) |  | System Testing (Firesmith, 2015, p. 23) |  | 
Specification-based Testing | Technique (IEEE, 2022, p. 22; 2021, p. 8; Washizaki, 2024, p. 5-10; Hamburg and Mogyorodi, 2024; Souza et al., 2017, p. 3; Firesmith, 2015, p. 46; implied by IEEE, 2022, pp. 2-4, 6-9) | "Testing in which the principal test basis is the external inputs and outputs of the test item" (IEEE, 2022, p. 9; 2017, p. 431) or its "requirements, specifications, models [and/]or user needs" (2021, p. 8) that "select[s] a few test cases from the input domain that can detect specific categories of faults" (Washizaki, 2024, pp. 5-10 to 5-11) | Dynamic Testing (IEEE, 2022, p. 17; Sharma et al., 2021, Fig. 1), Model-based Testing? (IEEE, 2022, p. 13; 2021, p. 6) | Black-Box Testing (IEEE, 2022, p. 9; 2021, p. 8; 2017, p. 431; Washizaki, 2024, p. 5-10; Hamburg and Mogyorodi, 2024; Firesmith, 2015, p. 46 (without hyphen); van Vliet, 2000, p. 399), Domain Testing (Washizaki, 2024, p. 5-10), Closed-Box Testing (IEEE, 2022, p. 9; 2017, p. 431), Input Domain-Based Testing (implied by Bourque and Fairley, 2014, p. 4-8), Functional Testing (van Vliet, 2000, p. 399; implied by IEEE, 2017, p. 431) | Should be done before structure-based testing to avoid bias towards "test cases based on how the module works" (Patton, 2006, p. 113). Difference between this and functional testing (van Vliet, 2000, p. 399; IEEE, 2017, p. 431; Souza et al., 2017, p. 3)? Umar (2020) has more synonyms
Spike Testing | Approach | "Testing to determine the ability of a system to recover from sudden bursts of peak loads and return to a steady state" (Hamburg and Mogyorodi, 2024) |  |  | 
Spiral Testing | Practice? | Testing "performed iteratively until the software is complete" alongside other phases of development (IEEE, 2017, p. 432) | Lifecycle-based Testing (Washizaki, 2024, p. 10-5; OG [2, 3, 10]), Risk-based Testing? (Washizaki, 2024, p. 10-6; OG [3]), Continuous Testing |  | 
SQL Injection | Approach | "A type of code injection in the structured query language (SQL)" (Hamburg and Mogyorodi, 2024) | Code Injection (Hamburg and Mogyorodi, 2024) |  | 
Stability Testing (Firesmith, 2015, p. 55) | Type (implied by its quality (IEEE, 2017, p. 434; OG ISO/IEC, 2009) and Firesmith, 2015, p. 55) | Testing a "property that an object has with respect to a given failure mode if it cannot exhibit that failure mode" (IEEE, 2017, p. 434; OG ISO/IEC, 2009) | Build Verification Testing (Hamburg and Mogyorodi, 2024), Reliability Testing? (Firesmith, 2015, p. 55), Modifiability Testing (if it exists) (ISO/IEC, 2023a) |  | Example: endurance stability testing (Firesmith, 2015, p. 55)
State Testing? (implied by IEEE, 2021, p. 19; Doğan et al., 2014, p. 184) | Technique (inferred from state transition testing and IEEE, 2021, p. 19) | Testing in which "all states in the state model … [are] 'visited'" (IEEE, 2021, p. 19) | Model-based Testing (IEEE, 2021, p. 19; Doğan et al., 2014, p. 184), State Transition Testing (IEEE, 2021, p. 19) | All States Testing? (Kam, 2008, p. 15; implied by IEEE, 2021, p. 19) | 
State Transition Testing | Technique (IEEE, 2022, pp. 9, 22; 2021, p. 5, Fig. 2; Washizaki, 2024, p. 5-12; Hamburg and Mogyorodi, 2024) | Testing based on "a model of the states the test item can occupy, the transitions between states, the events which cause transitions and the actions that can result from the transitions" (IEEE, 2021, p. 19) | Specification-based Testing (IEEE, 2022, pp. 9, 22; 2021, p. 5, Fig. 2; Washizaki, 2024, p. 5-12; Hamburg and Mogyorodi, 2024; Sharma et al., 2021, Fig. 1; Firesmith, 2015, p. 47?), Model-based Testing (IEEE, 2022, pp. 9, 13; 2021, ppp. 6, 10, 19; Bourque and Fairley, 2014, p. 4-10; implied by Hamburg and Mogyorodi, 2024 and Doğan et al., 2014, pp. 179, 184), Web Application Testing (Doğan et al., 2014, p. 179), Closed-Loop Testing (Preuße et al., 2012, p. 6), Open-Loop Testing? | Finite State Testing (Hamburg and Mogyorodi, 2024), Finite-State Machine (FSM) Testing (implied by Doğan et al., 2014, p. 179), Model Edge Testing?, Model Transition Testing? (implied by Doğan et al., 2014, p. 184), State-based Testing? (Firesmith, 2015, p. 47), All Transitions Testing? (Kam, 2008, p. 15) | Examples of state models include state tables (IEEE, 2022, p. 9; 2021, pp. 5, 19), state [transition (2022, p. 9; 2021, pp. 5, 19)] diagrams (2017, p. 438), and finite-state machines (Washizaki, 2024, p. 5-12); their states should be "discrete, identifiable and finite in number" (IEEE, 2021, p. 19). See BS 7925-2; Chow, 1978; Patton, 2006, pp. 79-87
State-based Web Browser Testing | Technique (Doğan et al., 2014, p. 193) |  | Web Application Testing (Kam, 2008, Tab. 1, p. 11), Formal Methods, Specification-based Testing, Control Flow Testing, Functional Testing (Tab. 1), State Transition Testing (p. 15), Transaction (Flow) Testing/Verification (p. 16) | State-based Testing (Doğan et al., 2014, p. 193), Web Browser Testing (Kam, 2008, pp. 14-15), Statechart Testing? (implied by Kam, 2008, Tab. 1, p. 11) | "Needs to be integrated with another testing method"  (Kam, 2008, p. 15) and "can test whether or not there are any side effects caused by users using the back, forward, and refresh/reload control buttons to navigate the website" (pp. 15-16) although "the reload path branches [are often pruned] to eliminate redundancy", which overlooks "the security of time sensitive [sic] expiration pages" (p. 16). See Di Lucca et al., [22, 23]
Statement Testing | Technique (IEEE, 2022, pp. 9, 22; 2021, p. 5, Fig. 2; 2017, p. 438; Washizaki, 2024, p. 5-13; Hamburg and Mogyorodi, 2024) | Testing "based on exercising executable statements" (IEEE, 2022, p. 9; 2021, p. 5; similar in Kam, 2008, p. 48) by "forc[ing the] execution of individual statements in a test item" (IEEE, 2017, p. 439; OG IEEE, 2013) | Structure-based Testing (IEEE, 2022, p. 22; 2021, p. 5, Fig. 2; Hamburg and Mogyorodi, 2024; Sharma et al., 2021, Fig. 1), Automated Testing (can be supported with "statement coverage analysers"; IEEE, 2021, p. 10), Control Flow Testing (Washizaki, 2024, p. 5-13; Firesmith, 2015, p. 49) | Line Testing, Node Testing (implied by Doğan et al., 2014, Tab. 11), All-Nodes Testing (van Vliet, 2000, p. 421) | 
Static Analysis | Approach | The "process of evaluating a system or component based on its form, structure, content, or documentation" (IEEE, 2017, p. 439) that "involves the use of tools to detect anomalies in code or documents without execution" (IEEE, 2022, p. 18) | Static Testing (IEEE, 2022, pp. 9, 17, 25, 28; Hamburg and Mogyorodi, 2024; Gerrard, 2000a, Fig. 4, p. 12; 2000b, p. 3), W-Model Testing (Gerrard, 2000a, Fig. 4), Developer Testing (implied by Lahiri et al., 2013, p. 345) |  | See also ISO/IEC 20246
Static Assertion Checking (Lahiri et al., 2013, p. 345) | Practice? | The use of "logical techniques … to prove, before runtime, that no violations of [separation logic] specifications will take place at runtime" (Chalin et al., 2006, p. 343) | Assertion Checking, Static Analysis (Lahiri et al., 2013, p. 345; Chalin et al., 2006, p. 343), Specification-based Testing? | Static Verification (SV) (Chalin et al., 2006, p. 343), SAC? | Often limited by "the need to define a[ "fairly complete" (Chalin et al., 2006, p. 343)] assertion (or specification) to check, to provide environment specifications and to provide auxiliary invariants for loops and procedures" (Lahiri et al., 2013, p. 345), but "often provides stronger guarantees and … can give them earlier" than RAC (Chalin et al., 2006, p. 343)
Static Testing | Approach | "Testing in which a test item is examined against a set of quality or other criteria without the test item being executed" (IEEE, 2022, p. 9; 2017, p. 440; OG 2013) | W-Model Testing (Gerrard, 2000a, p. 9) | Static Verification? (implied by Chalin et al., 2006, p. 343) | "Helps form an optimal test strategy" (IEEE, 2022, p. 21), "can be performed anywhere in the life cycle" (IEEE, 2022, p. 17), including "prior to dynamic testing[,] and can find defects before test execution becomes possible" (IEEE, 2022, p. 21). Not always considered "testing" (Washizaki, 2024, p. 5-2). See also ISO/IEC 20246
Statistical Testing | Technique (Kam, 2008, pp. 23, 48) | Testing "in which a model of the statistical distribution of the input is used to construct representative test cases" (Kam, 2008, p. 48) | Usage-based Testing (Washizaki, 2024, p. 5-15), Model-based Testing |  | "Often provide[s] a snapshot of the more troublesome areas of the software product under examination" (Washizaki, 2024, p. 12-8). "Usage-based statistical testing is applied more during the acceptance testing stage" (Washizaki, 2024, p. 5-15); how to track this? Implied to be related to random testing (Washizaki, 2024, p. 5-15)
Stress Testing | Type (IEEE, 2022, pp. 9, 22; 2017, p. 442; implied by Firesmith, 2015, p. 54) | Testing of "the SUT [at or (Hamburg and Mogyorodi, 2024)] beyond its capabilities" (Washizaki, 2024, p. 5-9) by "providing extreme test conditions to find the performance breaking points" by "manipulating … factors affecting the performance" (Moghadam, 2019, p. 1187); for example, "load[s] greater than what the system is expected to handle" (Washizaki, 2024, p. 5-9) or insufficient resource availability (IEEE, 2022, p. 9; 2017, p. 442; OG 2013), "such as access to memory or servers" (Hamburg and Mogyorodi, 2024) | Non-functional Testing (Washizaki, 2024, p. 5-9), Performance Efficiency Testing (IEEE, 2022, p. 9; 2017, p. 442), Performance Testing (Hamburg and Mogyorodi, 2024; Moghadam, 2019, p. 1187; Gerrard, 2000b, p. 23; implied by IEEE, 2022, p. 22), Capacity Testing (Firesmith, 2015, p. 54), Boundary Condition Testing (Patton, 2006, p. 86; implied by IEEE, 2017, p. 442), Dynamic Testing, W-Model Testing (Gerrard, 2000a, Fig. 5) |  | Can be generated "based on source code or system model analysis, or use-case based design approaches"; issues emerge from "performance bottlenecks" resulting from "application-, platform-, … [or]  workload-wise causes" (Moghadam, 2019, p. 1187)
Structure-based Testing | Technique (IEEE, 2021, p. 8; Washizaki, 2024, pp. 5-10, 5-13; Hamburg and Mogyorodi, 2024; Firesmith, 2015, p. 46; implied by IEEE, 2022, pp. 2, 4, 6, 9) | Testing "derived from an examination of the structure[, internal contents or implementation (IEEE, 2017, p. 199)] of the test item" (IEEE, 2022, p. 9; similar in 2021, p. 8) | Model-based Testing (IEEE, 2022, p. 13; 2021, pp. 6, 10), Dynamic Testing (IEEE, 2022, pp. 9, 17; 2017, p. 444; Washizaki, 2024, p. 5-13; Sharma et al., 2021, Fig. 1), Control Flow Testing (normally) (IEEE, 2021, p. 10), Automated Testing (can be supported with "statement coverage analysers"; IEEE, 2021, p. 10), Static Testing (likely when supported by tools (IEEE, 2021, p. 10); Washizaki, 2024, p. 5-13) | White-Box Testing (IEEE, 2022, p. 9; 2021, p. 8; 2017, pp. 443-444; Washizaki, 2024, p. 5-10; Hamburg and Mogyorodi, 2024; Firesmith, 2015, p. 46 (without hyphen); Patton, 2006, p. 55), Glass-Box Testing (IEEE, 2022, p. 9; 2017, pp. 443-444; Washizaki, 2024, p. 5-10; Hamburg and Mogyorodi, 2024; Peters and Pedrycz, 2000, p. 439), Structural Testing (IEEE, 2022, p. 9; 2017, pp. 443-444; Hamburg and Mogyorodi, 2024), Code-based Testing (Washizaki, 2024, p. 5-13; Bourque and Fairley, 2014, p. 4-8; Kam, 2008, p. 43), Clear-Box Testing (IEEE, 2021, p. 8; Washizaki, 2024, p. 5-10; Hamburg and Mogyorodi, 2024; Patton, 2006, p. 55) | "Can be performed at different levels (such as code development, code inspection, or unit testing)" (Washizaki, 2024, p. 5-13). Hamburg and Mogyorodi (2024), Umar (2020), and Kam (2008) have more synonyms; it seems like "structure-based testing" is specific to dynamic testing (IEEE, 2017, p. 444) but "structural testing" isn't (p. 443)
Structured Scripting | Technique? (Hamburg and Mogyorodi, 2024) | "Scripting … that builds and utilizes a library of reusable (parts of) scripts" (Hamburg and Mogyorodi, 2024) | Scripted Testing |  | 
Structured Walkthroughs | Practice? | "Systematic examination[s] of the requirements, design, or implementation of a system, or any part of it, by qualified personnel" (IEEE, 2017, p. 444; OG ISO/IEC, 2015) | Walkthroughs, Static Testing |  | 
Stuck Key Testing (Firesmith, 2015, p. 51) | Technique? |  | Random Testing (Firesmith, 2015, p. 51) |  | 
Subcontractor Testing (Firesmith, 2015, p. 37) | Practice? |  | Development Organization Testing (Firesmith, 2015, p. 37) |  | 
Subsystem Testing (Firesmith, 2015, p. 23) | Level (implied by system testing) |  | System Testing (Firesmith, 2015, p. 23), Unit Testing? (seems incorrect) (implied by Firesmith, 2015, p. 28) | Subsystem-based Testing? (Firesmith, 2015, p. 28) | 
Summative Evaluation(s) | Approach | "Evaluation[s] designed and used to gather conclusions about the quality of a component or system, especially when a substantial part of it has completed design" (Hamburg and Mogyorodi, 2024) | System Testing? |  | 
Symbolic Execution | Technique (IEEE, 2017, p. 451) | Testing "in which program execution is simulated using symbols … and program outputs are expressed as logical or mathematical expressions involving these symbols" (IEEE, 2017, p. 451) | Static Testing, Static Analysis?, Correctness Testing? |  | See Păsăreanu and Visser (2009)
Synchronous Testing (Jard et al., 1999) | Practice? | Testing that occurs in real time, so that, for example, "an IUT can refuse an event and … the tester can observe the refusal" (Jard et al., 1999, p. 26; OG [1]) |  |  | Sometimes possible to make asynchronous (e.g., by using "logical stamps" (Jard et al., 1999, p. 25), which are "simple counting mechanism[s]" (p. 27)) but this transformation is "a difficult task" (p. 26)
Syntax Testing | Technique (IEEE, 2022, p. 22; 2021, p. 5, Fig. 2; Washizaki, 2024, p. 5-11; Kam, 2008, p. 48) | Testing based on "rules, where each rule defines the format of an input parameter in terms of 'sequences of', 'iterations of', or 'selections between' elements in the syntax", which "may be represented in a textual or diagrammatic format" (IEEE, 2021, p. 14) | Specification-based Testing (IEEE, 2022, p. 22; 2021, p. 5, Fig. 2; Washizaki, 2024, p. 5-11; Firesmith, 2015, p. 47; Kam, 2008, p. 48), Model-based Testing (IEEE, 2022, p. 13; 2021, pp. 6, 14; implied by Bourque and Fairley, 2014, p. 4-10), Formal Testing, Positive Testing, Negative Testing, Experience-based Testing (for the negative version) (IEEE, 2021, p. 14), One-to-One Testing, Minimized Testing (can be; p. 15), Static Testing (Gerrard, 2000a, Tab. 2; 2000b, Tab. 1; implied by Washizaki, 2024, p. 1-10), Smoke Testing, Desktop Development Testing (Gerrard, 2000a, Tab. 2; 2000b, Tab. 1), Functional Testing? (Washizaki, 2024, p. 5-11), Gray-Box Testing? (Patton, 2006, p. 220), Web Application Testing (implied by Kam, 2008, p. 9; Gerrard, 2000b, pp. 3-5) | Formal Specification-Based Testing (Washizaki, 2024, p. 5-11) | "Permits automatic derivation of functional test cases[,] … provides an oracle for checking test results" (Washizaki, 2024, p. 5-11); positive inputs are called "options" and negative ones are "mutations" (IEEE, 2021, p. 14). "Permit[s] desired properties of the specified software to be proved" (Washizaki, 2024, p. 1-10). Test cases can be generated from these formal requirements (e.g., BDD scenarios and state models), but "determining an expected result is not always possible" and may require "additional business domain expertise" (p. 1-20). "Backus-Naur Form is commonly used for defining the syntax of test item inputs" (IEEE, 2021, p. 5) "in a textual format", and "abstract syntax tree[s] can be used to represent formal syntax diagrammatically" (p. 14). See also Beizer 1995; Burnstein 2003; Peters and Pedrycz, 2000, pp. 448-449; and Intana et al., 2020, p. 260
Sys Admin Testing (Firesmith, 2015, p. 39) | Practice? |  | Operator Testing (Firesmith, 2015, p. 39) |  | 
System Integration Testing | Level (IEEE, 2022, pp. 12, 22; 2021, p. 6; Hamburg and Mogyorodi, 2024) | Testing the "progressive assembling of system components into the whole system" (IEEE, 2017, p. 454; OG ISO/IEC, 2015), including between packages and "external organizations (e.g. [sic] Electronic Data Interchange, Internet)" (Kam, 2008, p. 48) | Integration Testing (Hamburg and Mogyorodi, 2024), System Testing (Firesmith, 2015, p. 23) |  | 
System Qualification Testing | Level? | "Testing performed on the completed, integrated system of software components, hardware components, and mechanics to provide evidence for compliance with system requirements and that the complete system is ready for delivery" (Hamburg and Mogyorodi, 2024) | System Testing?, Dynamic Testing? | System Testing? | Difference between this and system testing?
System Testing | Level (IEEE, 2022, pp. 12, 20-22, 26-27; 2021, p. 6; 2017, p. 467; Washizaki, 2024, p. 5-7; Hamburg and Mogyorodi, 2024) | "Testing conducted on a complete, integrated system to evaluate [its] compliance with its specified requirements" (IEEE, 2017, p. 456; OG 2012; similar in Hamburg and Mogyorodi, 2024), usually in regards to "non-functional system requirements", and verify its behaviour (Washizaki, 2024, p. 5-7). | V-Model Testing (Gerrard, 2000a, p. 9), W-Model Testing (Gerrard, 2000a, Figs. 3-5), Dynamic Testing (Gerrard, 2000a, p. 9) |  | Can be supported for distributed systems by "conventional capture/replay and database editing tools" (Sneed and Göschl, 2000, p. 18; OG Beizer95). See Hetzel
Systems Integration Testing | Level? | "Testing conducted on multiple complete, integrated systems to evaluate their ability to communicate successfully with each other and to meet the overall integrated systems' specified requirements" (IEEE, 2017, p. 457) | Integration Testing | Large Scale Integration Testing (Gerrard, 2000a, p. 13) | 
Tailored Conformance Testing (implied by IEEE, 2021, p. 7) | Type (inferred from conformance testing) | Testing that "the chosen subset of requirements from the chosen (non-empty) set of techniques and corresponding test coverage measurement approaches have been satisfied", including justification and "rationale, including the consideration of any applicable risks" as to why "the normative requirements of a technique … or measure … are not followed completely" (IEEE, 2021, p. 7; may be specific to this) | Conformance Testing |  | Should "be agreed [upon] by the relevant stakeholders" (IEEE, 2021, p. 7)
Technical Reviews (Washizaki, 2024, p. 12-14) | Approach | The "systematic evaluation of a software product by a team of qualified personnel that examines the suitability of the software product for its intended use and identifies discrepancies from specifications and standards" (IEEE, 2017, p. 463; OG IEEE, 2008), often done "at logical transition points in a system life cycle" (IEEE, 2017, p. 463; OG IEEE, 2014) | Formal Reviews (Hamburg and Mogyorodi, 2024) |  | "Can … be more focused and address a specific project phase" (Washizaki, 2024, p. 12-14; OG [24]). More types given by Washizaki (2024, p. 12-14)
Technical Testing? (implied by "technical requirements"; IEEE, 2017, p. 463) | Approach | Testing "requirements relating to the technology and environment, for the development, maintenance, support and execution of the software" (IEEE, 2017, p. 463) | Non-functional Testing? |  | Includes the "programming language, testing tools, operating systems, database technology and user interface technologies" (IEEE, 2017, p. 463)
Template Variable Testing? (Doğan et al., 2014, Tab. 13; OG Sakamoto et al., 2013) |  | Testing that aims to "cover[] all the template variable [sic] in HTML pages" (Doğan et al., 2014, Tab. 13; OG Sakamoto et al., 2013) | Web Application Testing (Doğan et al., 2014, Tab. 13), HTML Testing |  | 
Test Browsing (Gerrard, 2000a, p. 12, Tab. 2; 2000b, Tab. 1) | Approach | Testing that "aims to address … faults that relate to the navigation through web pages, the availability of linked objects", download speeds, and "integration of web pages to server-based components" (Gerrard, 2000b, p. 9) | Integration Testing (partially) (Gerrard, 2000b, p. 9), Web Application Testing |  | 
Test Environment Testing (Firesmith, 2015, p. 25) | Technique? |  |  |  | 
Test Tool Testing (Firesmith, 2015, p. 25) | Technique? |  |  |  | 
Test-driven Development | Process | A development process where "developers write the tests before they develop their code" (Sangwan and LaPlante, 2006, p. 25), "think[ing] of ways to break [their code] through testing, and then add[ing] code to address that situation" (p. 26) | Developer Testing (Sangwan and LaPlante, 2006, p. 25), Robustness Testing, Fault Tolerance Testing (p. 26), Incremental Testing (p. 29) |  | Tends to focus on "low-level unit testing" (Sangwan and LaPlante, 2006, p. 25), contributing to "difficulty with integration and system-level testing, poor confidence in code quality despite high code coverage provided by unit tests that pass trivially, and increased effort in maintaining test code as ratio of test to production code goes up" (p. 28). However, it "can improve code quality" (p. 25), especially when "the quality of unit tests" is improved and continuous/automated testing (p. 28) and test frameworks are used, and tends to improve communication in an organization (p. 29)
Tester Testing (Firesmith, 2015, p. 39) | Practice? |  | Role-based Testing (Firesmith, 2015, p. 39) |  | 
TestUML Testing | Approach | Testing using "class and state diagrams via static and dynamic analysis of [the] web application[]" (so it doesn't require documentation (Kam, 2008, p. 12)) generated by WebUml "to define test cases and choose[] test paths based on random walk analysis" (p. 11; OG [4, 5]) | Web Application Testing, Formal Methods, Structure-based Testing, Control Flow Testing, Functional Testing (Kam, 2008, Tab. 1), Random Walk Testing? (Kam, 2008, p. 12), UML Testing |  | These "class and state diagrams" are generated using "UML and statecharts" and then "used as an oracle"; "can potentially be a complete testing method to perform fully automatic V&V processes", but cannot reveal "dead code or … Trojan horse program[s]" or "test problems such as uncontrolled flow transaction[s] and syntax error[s]" (Kam, 2008, p. 12)
TestWeb Testing | Approach |  | Web Application Testing, UML Testing, Structure-based Testing, Control Flow Testing, Functional Testing (Kam, 2008, Tab. 1) |  | 
Think Aloud Usability Testing | Approach, Technique? (Hamburg and Mogyorodi, 2024) | Testing "where test participants share their thoughts with the moderator and observers by thinking aloud while they solve usability test tasks" which helps the testers "understand the test participant" (Hamburg and Mogyorodi, 2024) | Usability Testing |  | 
Three-Value Boundary Testing | Technique (inferred from boundary value analysis and inclusion in IEEE, 2021, p. 13) | Testing "values on the boundary and an incremental ["the smallest significant value for the data type"] distance each side of the boundary of the equivalence partition" for "each boundary" (IEEE, 2021, p. 13) | Boundary Value Analysis (IEEE, 2021, p. 13) |  | "Can be required for certain circumstances", such as those requiring "rigorous testing" (IEEE, 2021, p. 13)
Threshold Coverage (Testing?) | Approach | Testing based on "the coverage of neurons exceeding a threshold activation value in a neural network for a set of tests" (Hamburg and Mogyorodi, 2024) | ML Model Testing |  | 
Top-Down (Integration) Testing | Level (inferred from integration testing) | Integration testing (Washizaki, 2024, p. 5-7; Kam, 2008, p. 48) that "starts with the highest-level component[s] … and proceeds through progressively lower-levels" (IEEE, 2017, p. 479) "with lower level components being simulated by stubs" (Kam, 2008, p. 48) | Integration Testing (Washizaki, 2024, p. 5-7; Sharma et al., 2021, p. 603; Kam, 2008, p. 48; Sangwan and LaPlante, 2006, p. 27), Incremental Testing (Kam, 2008, p. 48) |  | Difference between this as integration testing vs. not (as in Firesmith, 2015, p. 28)?
Tours | Practice (IEEE, 2022, p. 34) | Testing that is quite general and "guides testers through the paths of an application like a tour guide leads a tourist through the landmarks of a big city" (IEEE, 2022, p. 34), or that is exploratory yet "organized around a special focus" (Hamburg and Mogyorodi, 2024) | Exploratory Testing (IEEE, 2022, p. 34; Hamburg and Mogyorodi, 2024), Experience-based Testing (IEEE, 2022, p. 34; 2021, p. 4) |  | 
Transaction Flow Testing | Technique (inferred from scenario testing and IEEE, 2021, p. 20) |  | Scenario Testing (IEEE, 2021, p. 20) | Transaction Testing? (Gerrard, 2000a, Fig. 5) | See Beizer 1995
Transaction Testing | Approach | Testing that "addresses the integration of the browser pages, web server and other server-based components" (Gerrard, 2000b, p. 13) "to ensure that the entire transaction is processed correctly", including "the direct and indirect interfaces", and transfer of control and data (p. 16) | Dynamic Testing (Gerrard, 2000a, Fig. 5?, Tab. 2), Functionality Testing, System Testing, Functional Testing (Gerrard, 2000a, Tab. 2; 2000b, Tab. 1), Web Application Testing? (Kam, 2008, p. 9), W-Model Testing? (Gerrard, 2000a, Fig. 5), Integration Testing (2000b, pp. 13, 16), End-to-End Functionality Testing (p. 16) | Transaction Flow Testing? (Gerrard, 2000a, Fig. 5) | Should be automated if there are complex components or custom-built software involved (Gerrard, 2000b, p. 17)
Transaction Verification | Approach | Testing that "aims at ensuring that … the correct forms handler is invoked and that the parameters passed to the forms handler are correct" (Gerrard, 2000b, p. 11) | Smoke Testing, Test Browsing, Static Testing (Gerrard, 2000a, Tab. 2; 2000b, Tab. 1), Web Application Testing? (Kam, 2008, p. 9), Integration Testing (implied by Gerrard, 2000b, p. 16) | Transaction Flow Verification? (Gerrard, 2000a, Fig. 5) | "Not the same as Application System Testing"; "focuses … on selected test cases that exercise particular interfaces between components in the technical architecture and scenarios (in volumes) that System tests might not address" (Gerrard, 2000b, p. 16)
Translation Validation (Lahiri et al., 2013, p. 354; OG [26], [23], [18]) | Technique? |  | Equivalence Checking? (Lahiri et al., 2013, p. 354; OG [26], [23], [18]) |  | 
t-wise Testing | Technique (Washizaki, 2024, p. 5-11) | Testing that "considers every possible combination of [some] t input" (Washizaki, 2024, p. 5-11) | All Combinations Testing (Washizaki, 2024, p. 5-11) |  | "More than one pair is derived (i.e., by including higher-level combinations)" (Washizaki, 2024, p. 5-11)
Two-Value Boundary Testing | Technique (inferred from boundary value analysis and inclusion in IEEE, 2021, p. 13) | Testing "values on the boundary and an incremental ["the smallest significant value for the data type"] distance outside the boundary of the equivalence partition" for "each boundary" (IEEE, 2021, p. 13) | Boundary Value Analysis (IEEE, 2021, p. 13) |  | "Typically adequate in most situations" (IEEE, 2021, p. 13)
UI Testing (Doğan et al., 2014, Tab. 8) | Approach |  | Web Application Testing (Doğan et al., 2014, Tab. 8; implied by Kam, 2008, p. 9) |  | 
UML Model-based Testing (Doğan et al., 2014, p. 194) | Technique? |  | Model-based Testing | UML Testing? (implied by Kam, 2008, Tab. 1) | 
Unit Testing | Level (IEEE, 2022, pp. 12, 20-22, 26-27; 2021, p. 6; 2017, p. 467; Washizaki, 2024, p. 5-6; Hamburg and Mogyorodi, 2024) | "Testing of individual hardware or software components" (IEEE, 2012, p. 8; similar in Hamburg and Mogyorodi, 2024 and Sangwan and LaPlante, 2006, p. 26) or of "individual routines and modules" (2017, p. 490) "can include consideration of basic functionality" (2022, p. 13; 2021, p. 6) | Construction Testing (Washizaki, 2024, p. 4-7), Functionality Testing, Smoke Testing (implied by IEEE, 2022, p. 13; 2021, p. 6), Automated Testing (often) (Washizaki, 2024, p. 4-14), V-Model Testing (Gerrard, 2000a, p. 9), W-Model Testing (Gerrard, 2000a, Figs. 3-5), Dynamic Testing (Gerrard, 2000a, p. 9) | Component Testing (IEEE, 2022, pp. 12-13; 2021, p. 6; Hamburg and Mogyorodi, 2024; Firesmith, 2015, p. 22; Peters and Pedrycz, 2000, p. 444), Module Testing (Hamburg and Mogyorodi, 2024; Patton, 2006, p. 109; Sneed and Göschl, 2000, p. 18; OG Hetzel88), Class Testing (Sneed and Göschl, 2000, p. 18; OG Hetzel88) | "The terms module, component, and unit [sic] are often used interchangeably or defined to be subelements of one another in different ways depending upon the context" with no standardized relationship (IEEE, 2017, p. 82) but a distinction is sometimes made; for example, "components differ from classical modules for being re-used in different contexts independently of their development" (Baresi and Pezzè, 2006, p. 107). See also Engström and Petersen, 2015
Unscripted Testing | Approach | "Testing in which the tester's actions are not prescribed by written instructions in a test case" (IEEE, 2022, p. 15; 2017, p. 490; OG IEEE, 2013) | Dynamic Testing (IEEE, 2022, p. 15; 2017, p. 490) |  | 
Usability Test Script(ing) | Approach | The creation/use of "a document specifying a sequence of actions for the execution of a usability test" (Hamburg and Mogyorodi, 2024) | Usability Testing; Structured Testing (Hamburg and Mogyorodi, 2024) |  | 
Usability Testing | Type (IEEE, 2022, pp. 22, 26-27; 2021, p. 7; implied by its quality and by Firesmith, 2015, p. 53) | Testing that "evaluate[s] how easy it is for ['specified users' to use and (IEEE, 2017, p. 492; OG ISO/IEC, 2013)] learn to use the software" by testing functionality (Washizaki, 2024, p. 5-10, IEEE, 2017, p. 493), documentation, and/or recovery (Washizaki, 2024, p. 5-10), as well as how "attractive to the users" the product is (Kam, 2008, p. 48) | Non-functional Testing (Kam, 2008, p. 47; Gerrard, 2000a, Tab. 2; 2000b, Tab. 1), System Testing, Manual Testing (Gerrard, 2000a, Tab. 2; 2000b, Tab. 1) | Interaction Capability Testing (ISO/IEC, 2023a), Fitness-for-Use Testing (IEEE, 2017, p. 493), Human-Computer Interaction Testing? (Washizaki, 2024, p. 5-10) | Related to acceptance testing (van Vliet, 2000, p. 439) and potentially reusability (IEEE, 2017, p. 492), but this relation may just be syntactic. See also [20] in Gerrard, 2000b, p. 22
Usability Walkthroughs | Approach | "Usability evaluation[s] in which one or more evaluators step through a scenario playing the role of a user and identifying usability problems associated with successful completion of the scenario[s]" (IEEE, 2017, p. 493; OG ISO/IEC, 2010) | Usability Testing (IEEE, 2017, p. 493), Walkthroughs |  | "Evaluators can include usability specialists, developers, [and/or] end users" (IEEE, 2017, p. 493)
Usage-based Testing | Technique (Washizaki, 2024, p. 5-15) | Testing that "usually rel[ies] on a usage model or profiles" in the context of "the actual operational environment" and "usage by the target stakeholder" (Washizaki, 2024, p. 5-15) | Online Testing? |  | May involve the development/implementation of an "operational profile" (Hamburg and Mogyorodi, 2024)
Use Case Testing | Technique (Kam, 2008, pp. 48-49) | "Testing sequences of interactions (i.e. scenarios) between the test item and actors" where "various actions are performed by the test item as a result of various triggers from the actors" (IEEE, 2021, p. 20) | Model-based Testing (IEEE, 2022, p. 13; 2021, pp. 6, 20), Scenario Testing (p. 20), Specification-based Testing (Sharma et al., 2021, Fig. 1; Kam, 2008, pp. 48-49), User Story Testing? | Sometimes spelled with a hyphen (Sharma et al., 2021, Fig. 1), Scenario Testing (Kam, 2008, p. 47), User Scenario Testing (although "an actor can be a user or another system" (IEEE, 2021, p. 20)) (Kam, 2008, p. 48) | See Hass 2008; Marchetto et al., 2008
User Acceptance Testing | Level (IEEE, 2022, p. 22; Firesmith, 2015, p. 30; inferred from acceptance testing) | "A type of acceptance testing performed to determine if intended users accept the system" (Hamburg and Mogyorodi, 2024) | Acceptance Testing (IEEE, 2022, p. 22; Hamburg and Mogyorodi, 2024; Firesmith, 2015, p. 30) | UAT (Hamburg and Mogyorodi, 2024; Firesmith, 2015, p. 30) | Also mentioned by Washizaki (2024, p. 6-13)
User as Tester Testing (Firesmith, 2015, p. 39) | Practice? |  | User Testing (Firesmith, 2015, p. 39) |  | 
User Interface Navigation Testing | Approach |  | Specification-based Testing (Firesmith, 2015, p. 47), UI Testing |  | 
User Organization Testing (Firesmith, 2015, p. 37) | Practice? |  | Organization-based Testing (Firesmith, 2015, p. 37), User Testing |  | 
User Session Data Testing | Approach |  | Web Application Testing, User Session Testing, Specification-based Testing (usually), Control Flow Testing, Functional Testing (Kam, 2008, Tab. 1) |  | 
User Session Testing (Kam, 2008, Tab. 1) | Approach |  | User-based Testing? |  | 
User Story Testing | Approach | Testing "in which test conditions are the acceptance criteria of user stories" or "requirement[s] consisting of one sentence … capturing the functionality a user needs, the reason behind it, any non-functional criteria, and … acceptance criteria" (Hamburg and Mogyorodi, 2024) | Specification-based Testing (Hamburg and Mogyorodi, 2024), Requirements-based Testing, User-based Testing? |  | 
User Surveys | Approach | "Evaluation[s] whereby a representative sample of users are asked to report subjective evaluation into a questionnaire based on their experience in using a component or system" (Hamburg and Mogyorodi, 2024) | Usability Testing, User-based Testing? |  | 
User-Agent Based Testing | Approach | "Testing in which a test client is used to switch the user agent string and identify itself as a different client while executing test suites" (Hamburg and Mogyorodi, 2024) |  |  | Could be used in security testing
User-based Evaluations | Approach | "Evaluation[s] that involve[] representative users performing tasks with the system … focused on usability[,] … efficiency, effectiveness, [and/or] user satisfaction" (IEEE, 2017, p. 498; OG ISO/IEC, 2016) | Usability Testing (IEEE, 2017, p. 498), Acceptance Testing? |  | 
User-initiated Built-In Testing (Firesmith, 2015, p. 31) | Practice? |  | Built-In Testing (Firesmith, 2015, p. 31) | UBIT (Firesmith, 2015, p. 31) | 
User-session-based Testing (Doğan et al., 2014, p. 183) | Approach |  | Session-based Testing, User as Tester Testing? User Story Testing? |  | Potentially complementary to structure-based testing (Doğan et al., 2014, p. 193; OG Elbaum et al., 2005)
Validation Testing | Approach | "Test[ing] to determine whether an implemented system fulfils its specified requirements" (IEEE, 2017, p. 499; ISO/IEC, 2015) |  |  | OG definition was about a specific test, not a test approach
Verification Testing | Approach | Testing to determine whether a system fulfils "its specified requirements at a particular stage of its development" (IEEE, 2017, p. 504; ISO/IEC, 2015) |  |  | This seems to conflate the definition of "verification" with "validation"
Visual Browser Validation | Approach | Testing visually "that the appearance of [web]pages on … other browser[s] are acceptable" (Gerrard, 2000b, p. 8) | Usability Testing, Manual Testing, Static/Dynamic Testing? (Gerrard, 2000a; Tab. 2; 2000b, Tab. 1), Cross-Browser Compatibility Testing (implied by 2000b, p. 8), Web Application Testing, Visual Testing |  | 
Visual Testing | Approach | Testing of GUI objects (Hamburg and Mogyorodi, 2024; Bajammal and Mesbah, 2018, p. 193) "rel[ying] exclusively on the application's appearance" and "a visual comparison between a number of initial screenshots" (Bajammal and Mesbah, 2018, p. 193) | GUI Testing, Web Application Testing (Bajammal and Mesbah, 2018, p. 193) |  | May use "image recognition" (Hamburg and Mogyorodi, 2024) and is "highly fragile compared to DOM-based methods" (Bajammal and Mesbah, 2018, p. 193; OG [4, 5]) since "it is difficult to assess what state is the canvas in at any given moment" (p. 194). May use visual analysis (p. 194). See ISO 29119-11
V-Model Testing (Firesmith, 2015, p. 29) | Practice? | Testing that occurs alongside the phases of the waterfall model in a "layered and phased nature" (Gerrard, 2000a, p. 9) | Waterfall Testing (Washizaki, 2024, p. 10-6; OG [3]; Firesmith, 2015, p. 29), Lifecycle-based Testing (Washizaki, 2024, p. 10-5; OG [2, 3, 10]), W-Model Testing? (implied by Gerrard, 2000a, p. 9) |  | See also Washizaki (2024, p. 10-6; OG [3])
Volume Testing | Type (implied by Firesmith, 2015, p. 54) | Testing to assess "the SUT's internal storage limitations and its ability to exchange data and information" (Washizaki, 2024, p. 5-9) or "process specified volumes of data (usually at or near maximum specified capacity)" (IEEE, 2017, p. 508; OG 2013; similar in Kam, 2008, p. 49) | Performance Efficiency Testing (IEEE, 2017, p. 508; OG 2013), Non-functional Testing (Washizaki, 2024, p. 5-9), Capacity Testing (Firesmith, 2015, p. 54), Dynamic Testing, W-Model Testing (Gerrard, 2000a, Fig. 5) |  | 
Walkthroughs | Technique? (IEEE, 2017, p. 509) | Evaluations "in which a designer or programmer leads members of the development team and other interested parties through a segment of documentation or code, and the participants ask questions and make comments about possible errors, violation of development standards, and other problems" (IEEE, 2017, p. 508; similar in Hamburg and Mogyorodi, 2024) | Static Analysis (IEEE, 2017, p. 508), Formal Reviews, Reviews (Hamburg and Mogyorodi, 2024) | Structured Walkthroughs (Hamburg and Mogyorodi, 2024) | Sometimes spelled with a hyphen ("walk-through"; IEEE, 2017, pp. 133, 439, 508). See ISO 20246
Waterfall Testing | Practice? | Testing performed in the context of the waterfall model; i.e., after implementation but before installation and checkout, either strictly sequentially (Washizaki, 2024, p. 10-5) or "possibly with overlap but with little or no iteration" (IEEE, 2017, p. 509) | Lifecycle-based Testing (Washizaki, 2024, p. 10-5; OG [2, 3, 10]; Firesmith, 2015, p. 29) |  | 
Web (Application) Testing (WAT) (Doğan et al., 2014; Choudhary et al., 2010; Kam, 2008) | Approach | Testing of "an application that is accessed via a web browser using the Hypertext Transfer Protocol (HTTP) over a network such as the Internet or intranet" (Kam, 2008, p. 1) | Domain-Specific Testing? | Rich Internet Applications Testing? (implied by Doğan et al., 2014, p. 176; OG Amalfitano et al., 2010) | Difficult due to many factors (e.g., asynchronicity, heterogeneity, nondeterminism) (Doğan et al., 2014, pp. 174-15) and is often overlooked (Kam, 2008, p. 7; OG [12]). About 70% of websites in 2003 had defects (Doğan et al., 2014, p. 174; OG BIG-SF)
WebApp Slicing | Approach |  | Web Application Testing, Slicing, Structure-based Testing, Data Flow Testing, Functional Testing (Kam, 2008, Tab. 1) |  | 
W-Model Testing | Practice? | The combination of "static testing of early document or code deliverables and dynamic test stages of software deliverables" (Gerrard, 2000a, p. 9) | Incremental Testing?, Continuous Testing? | Since only dynamic testing is considered for this research, the in-scope part of W-model testing is equivalent to V-model testing | 
 |  |  |  |  | 
 |  |  |  |  | See also the ISO/IEC/IEEE 29119 series (especially 29119-4); 29119-2 provides more information on test processes
 |  |  |  |  | See also ISO/IEC 2382:2015, Information technology -— Vocabulary
 |  |  |  |  | Compare ISO/IEC TR 19759:2016 to SWEBOK
 |  |  |  |  | Investigate convertibility/functional size measurement (IEEE, 2017, p. 103)