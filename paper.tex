\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
%Template version as of 6/27/2024

\input{paper_preamble}

\newcommand{\acf}[1]{(\uppercase{#1})}
\newcommand{\acs}[1]{\uppercase{#1}}

\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\title{Putting Software Testing Terminology to the Test\\
    % Sub-titles should not be used!
    \thanks{Identify applicable funding agency here. If none, delete this.}
}

\author{\IEEEauthorblockN{Samuel J. Crawford\IEEEauthorrefmark{1},
        Spencer Smith\IEEEauthorrefmark{1}, Jacques Carette\IEEEauthorrefmark{1}}
    \IEEEauthorblockA{\IEEEauthorrefmark{1}Department of Computing and Software \\
        McMaster University\\
        Hamilton, Canada \\
        \{crawfs1, smiths, carette\}@mcmaster.ca}}

% \newcommand{\deptCAS}[1]{
%     \IEEEauthorblockA{\textit{Department of Computing and Software} \\
%         \textit{McMaster University}\\
%         Hamilton, Canada \\
%         #1@mcmaster.ca}}

% \author{\IEEEauthorblockN{Samuel~J.~Crawford}
%     \deptCAS{crawfs1}
%     \and
%     \IEEEauthorblockN{Spencer~Smith} % TODO: W.~ ?
%     \deptCAS{smiths}
%     \and
%     \IEEEauthorblockN{Jacques~Carette}
%     \deptCAS{carette}
% }

\maketitle

\begin{abstract}
    Testing is a critical part of every software development project that is
    often complicated, expensive, or overlooked. This is in part due to the
    unstable knowledge base; there is no standard, consistent, and ``complete''
    taxonomy for software testing, which inhibits unambiguous communication.
    Discrepancies and ambiguities are widespread throughout the literature, and
    sometimes exist between different parts of the same document!
    % Therefore, automating the software testing process is an area of interest,
    % and understanding the underlying domain is an important prerequisite.
    We systematically investigate the current state of software terminology
    by 1) identifying established standards (including IEEE, ISO/IEC, and SWEBOK)
    and other prominent testing resources, 2) capturing relevant testing terms
    from these sources, along with their definitions and relationships (both
    explicit and implied), and 3) building graphs to visualize and analyze
    these data. Throughout this process, over five hundred test approaches were
    uncovered, as well as
    % a (relatively) consistent method for classifying them and
    some methods for describing ``implied'' test approaches. In
    addition, a tool was built to generate graphs of the relations between test
    approaches and track their ambiguities, in addition to those captured
    manually through the research process. Our results show ten terms are
    given as synonyms to two (or more) disjoint test approaches and fourteen
    pairs of test approaches may be synonyms and/or have a child-parent
    relationship. There is also confusion surrounding functional, recovery,
    scalability, and performance testing, along with over fifty more
    ``minor'' discrepancies. Overall, there is a need for testing terminology
    to be standardized to make the discussion, analysis, and implementation of
    various test approaches more coherent, and we
    provide some preliminary advice on how to accomplish this.
\end{abstract}

\begin{IEEEkeywords}
    Software testing, terminology, taxonomy, literature review, test approaches
\end{IEEEkeywords}

\section{Background}

% TODO: tighten up, add sources

Testing software is complicated, expensive, and often overlooked. Therefore,
automating the software testing process is an area of interest. In particular,
test case generation for Drasil, a framework for ``generating all of the
software artifacts for (well understood) research software'' \cite{Drasil} was
desired.

Before attempting to automate a knowledge-based process in ad hoc manner, it is
important to understand the underlying domain. This allows the information
itself to drive the scope, including both what is possible and what is needed.
In this case, the goal was to uncover the various approaches towards testing,
as well as which prerequisites (e.g., input files, oracles) existed for each.
A search for a systematic, rigorous, and ``complete'' taxonomy revealed that
existing software testing taxonomies are inadequate:

\begin{itemize}
    \item \cite{TebesEtAl2020a} focuses on \emph{parts} of the
          testing process (e.g., test goal, testable entity)
    \item \cite{SouzaEtAl2017} prioritizes organizing testing
          approaches over defining them
    \item \cite{UnterkalmsteinerEtAl2014} provides a foundation for
          classification but not how it applies to software testing terminology
\end{itemize}

The ``solution'' to this gap was to define the scope of what kinds of
``software testing'' were of interest (\ref{scope}), then examine the existing
literature for this subsection (\ref{method}); this
quickly reinforced the need for a taxonomy! Despite the amount of
well understood and organized knowledge (\ref{observ}), there are still many
discrepancies and ambiguities, either within the same source or between various
sources (\ref{discrep}). We provide some potential solutions to some of these
(\ref{recs}).

\input{chapters/03e_scope}
\input{chapters/03b_methodology}
\input{chapters/03c_observations}
\input{chapters/03d_discrepancies}
\input{chapters/03f_recommendations}

\section*{Acknowledgment}

% TODO

\newpage

\bibliographystyle{IEEEtran}
\bibliography{IEEEabrv,references}

\end{document}
