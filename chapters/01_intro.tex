\section{Introduction}

As with all fields of science and technology, software development should
be approached systematically and rigorously. \refHelper \ifnotpaper
    \citeauthor{PetersAndPedrycz2000} \else \cite{PetersAndPedrycz2000} \fi
\multiAuthHelper{claim} that ``to be successful, development of software
systems requires an engineering approach'' that is ``characterized by a
practical, orderly, and measured development of software'' \ifnotpaper
    \citeyearpar[p.~3]{PetersAndPedrycz2000}\else \citetext{p.~3}\fi. When a
NATO study group decided to hold a conference to discuss ``the problems of
software'' in 1968, they chose the
phrase ``software engineering'' to ``imply[] the need for
software manufacture to be based on the types of theoretical foundations and
practical disciplines, [sic] that are traditional in the established branches
of engineering'' \citep[p.~13]{NATO1969}. ``The term was not in general use at
that time'', but conferences such as this ``played a major role in gaining
general acceptance \dots{} for the term'' \citep{McClure2001}. While one of the
goals of the conference was to ``discuss possible techniques, methods and
developments which might lead to the[] solution'' to these problems
\citep[p.~14]{NATO1969}, the format of the conference itself was difficult to
document. Two competing classifications of the report emerged: ``one following
from the normal sequence of steps in the development of a software product''
and ``the other related to aspects like communication, documentation,
management, [etc.]'' \citetext{p.~10}. Perhaps more surprisingly, ``to retain
the spirit and liveliness of the conference, \dots{} points of major
disagreement have been left wide open, and \dots{} no attempt \dots{} [was]
made to arrive at a consensus or majority view'' \citetext{p.~11}!

% Testing software is complicated, expensive, and often overlooked. 

% The productivity of testing and testing research would benefit from a standard
% language for communication. 

% These benefits permeate software testing terminology. 

Perhaps unsurprisingly, this lack of consensus in the field of software
engineering persists to this day, including in the subdomain of software testing.
\refHelper \ifnotpaper \citeauthor{KanerEtAl2011} \else \cite{KanerEtAl2011}
\fi \multiAuthHelper{give} the example of complete testing, which may require
the tester to discover ``every bug in the product'', exhaust the time allocated
to the testing phase, or simply implement every test previously agreed upon
\ifnotpaper \citeyearpar[p.~7]{KanerEtAl2011}\else \citetext{p.~7}\fi.
% They go on to say that
Having a clear definition of ``complete testing'' would reduce the chance for
miscommunication and, ultimately, the tester getting ``blamed for not
doing \dots{} [their] job'' \citetext{p.~7}. Because software testing uses ``a
subtantial percentage of a software development budget (in the range of 30 to
50\%)'', which is increasingly true ``with the growing complexity of software
systems'' \citep[p.~438]{PetersAndPedrycz2000}, this is crucial to the
efficiency of software development. Even more foundationally, if software
engineering holds code to high standards of clarity, consistency, and
robustness, the same should apply to its supporting literature! \ifnotpaper
    \par We noticed this lack of a standard language for software testing while
    working on our own software framework, Drasil \citep{Drasil}, with the
    goal of ``generating all of the software artifacts for (well understood)
    research software''. Currently, these include \acfp{srs}, READMEs,
    Makefiles, and code in up to six languages, depending on the specific case
    study \citep{HuntEtAl2021}. To improve the quality, functionality, and
    maintainability of Drasil, we want to add test cases to this list
    \citep{PotentialProjects,HuntEtAl2021}. This process would be a part of
    our ``continuous integration system, [sic] so that the generated code for
    the case studies is automatically tested with each build'' and would be a
    big step forward, since we currently only ``test that the generated code
    compiles'' \citep{PotentialProjects}. However, before we can include test
    cases as a generated artifact, the underlying domain---software testing---%
    needs to be ``well understood'', which requires a ``stable knowledge
    base'' \citep{HuntEtAl2021}. \fi

Unfortunately, a search for a systematic,
rigorous, and complete taxonomy for software testing revealed that the existing
ones are inadequate\todo{ProWritingAid suggests that including ``and
    incomplete'' is redundant} and mostly focus on the high-level testing
process rather than the testing approaches themselves: % and incomplete

\begin{itemize}
    \item \citeauthor{TebesEtAl2020a} \citeyearpar{TebesEtAl2020a} focus on
          \emph{parts} of the testing process (e.g., test goal, test plan,
          testing role, testable entity) and how they relate to one another,
    \item \citeauthor{SouzaEtAl2017} \citeyearpar{SouzaEtAl2017} prioritize
          organizing test approaches over defining them,
    \item \citeauthor{Firesmith2015} \citeyearpar{Firesmith2015} similarly
          defines relations between test approaches but not the approaches
          themselves, and
    \item \citeauthor{UnterkalmsteinerEtAl2014}
          \citeyearpar{UnterkalmsteinerEtAl2014}
          focus on the ``information linkage or transfer'' \citetext{p.~A:6}
          between requirements engineering and software testing and ``do[]
          not aim at providing a systematic and exhaustive state-of-the-art
          survey of [either domain]'' \citetext{p.~A:2}.
\end{itemize}

Some existing collections of software testing terminology were found, but
in addition to being incomplete, they also contained many oversights.
\ifnotpaper
    For example, \citet{IEEE2017} \multiAuthHelper{provide} the following
    term-definition pairs:
    \begin{itemize}
        \item \textbf{Event Sequence Analysis:} ``per'' \citetext{p.~170}
        \item \textbf{Operable:} ``state of'' \citetext{p.~301}
              % This may be a bad example, since the cf. provides some more context
              % \item \textbf{Software Element:} a ``system element that is software''
              %       \citetext{p.~421}
    \end{itemize}
    These definitions are nonsensical and do not define the terms they claim
    to! To be sure, they \emph{cannot} correspond to the terms given since the
    parts of speech are mismatched: the first defines a noun phrase as a
    preposition, and the second an adjective as a noun phrase fragment.
    \citet{IEEE2017} also \multiAuthHelper{define} ``device'' as a ``mechanism
    or piece of equipment designed to serve a purpose or perform a function''
    \citetext{p.~136}, but do\ifnotpaper\else{es}\fi\ not define ``equipment''
    and only \multiAuthHelper{define} ``mechanism'' in the software sense as
    ``the means used by a function to transform input into output''
    \citetext{p.~270\todo{OG IEEE 1998}}. This is an example of an incomplete
    definition; while the definition of ``device'' seems logical at first
    glance, it actually leaves much undefined.

    This problem also extends to test approaches, and
\else
    In particular,
\fi
discrepancies between the definitions of test approaches can lead to the
miscommunication mentioned by \citet[p.~7]{KanerEtAl2011}. \expBasedCatMain{}
\tourDiscrep{}
\loadDiscrep{} \alphaDiscrep{} With inconsistencies such as these, it is clear
that there is a notable gap in the literature, one which we attempt to describe
and fill. While the creation of a complete taxonomy is unreasonable, especially
considering the pace at which the field of software changes, we can make
progress towards this goal that others can extend and update as new test
approaches emerge.

\ifnotpaper
    The following three research questions guide this process:
    \begin{enumerate}
        \item \rqatext{}
        \item \rqbtext{}
        \item \rqctext{}
    \end{enumerate}
    \input{build/methodOverviewIntro}
    An excerpt of this recorded information (excluding other notes for brevity),
    is given in \Cref{tab:approachGlossaryExcerpt}.
\fi

This document describes this process, as well as its results, in more detail.
We first define the scope of
what kinds of software testing are of interest (\Cref{scope}) and examine the
existing literature (\Cref{methodology})\ifnotpaper, partially through the use
of tools created for analysis (\Cref{tools})\fi. Despite the amount of well
understood and organized knowledge, there are still many discrepancies in the
literature, either within the same source or between various
sources (\Cref{discreps}). This reinforces the need for a proper taxonomy! We
provide some potential solutions covering some of these discrepancies
(\Cref{recs}).

\ifnotpaper
    \begin{bigLandscape}
        \input{assets/tables/exampleGlossary}
    \end{bigLandscape}
\fi