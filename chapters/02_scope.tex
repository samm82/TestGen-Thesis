\section{Scope}
\label{scope}

Since our motivation is restricted to testing code, only this component of
\acf{vnv} is considered\thesisissueref{22}. However, some test approaches
are used for testing things other than code, and some approaches can be used
for both! In these cases, only the subsections of these approaches focused on
code are considered. For example, reliability testing and maintainability
testing can start \emph{without} code by ``measur[ing] structural attributes
of representations of the software'' \citep[p.~18]{FentonAndPfleeger1997}, but
only reliability and maintainability testing performed on code \emph{itself} is
in scope of this research. Therefore, some practices are excluded from
consideration either in part or in full, such as hardware testing and the
\acs{vnv} of other artifacts are completely out of scope (see \Cref{app-scope}
for more detailed discussion), as well as relevant areas of other testing
approaches that are otherwise in scope. Static testing can be performed
on code, so while it isn't relevant to the original motivation of this work, it
is a useful component of software testing and is therefore included at this level
of analysis (\Cref{static-test}). \ifnotpaper Finally, some test approaches can
    be derived from other categories of testing-related terminology
    (\Cref{derived-tests}); of these, approaches derived from programming
    languages (\Cref{lang-test}) or other orthogonal test approaches
    (\Cref{orth-test}) are out of scope. \fi

\ifnotpaper

    \subsection{Derived Test Approaches}
    \label{derived-tests}

    Since the field of software is ever-evolving, it is crucial to be able to
    adapt to, talk about, and understand new developments in software testing.
    Bases for defining new test approaches suggested by the
    literature include coverage metrics (\Cref{cov-test}), software qualities
    (\Cref{qual-test}), and attacks (\Cref{attacks}). These are meaningful
    enough to merit analysis and are therefore in scope. Requirements
    (\Cref{req-test}) may also imply related test approaches, but this mainly
    results in test approaches that would be out of scope. Other out-of-scope
    test approaches given in the literature are those derived from programming
    languages (\Cref{lang-test}) or other orthogonal test approaches
    (\Cref{orth-test}), since their information is better captured by other
    approaches.

    \subsubsection{Coverage-driven Techniques}
    \label{cov-test}

    Test techniques are able to ``identify test coverage items \dots{} and
    derive corresponding test cases''
    \ifnotpaper
        (\citealp[p.~11]{IEEE2022}; similar in \citeyear[p.~467]{IEEE2017})
    \else
        \cite[p.~11]{IEEE2022} (similar in \cite[p.~467]{IEEE2017})
    \fi
    in a ``systematic'' way
    \citeyearpar[p.~464]{IEEE2017}.
    \ifnotpaper
        This allows for ``the coverage achieved by a specific test design
        technique'' to be calculated as a percentage of ``the number of test
        coverage items covered by executed test cases'' \citeyearpar[p.~30]{IEEE2021}.
        %     ``Coverage levels can range
        %     from 0\% to 100\%'' and may or may not include ``infeasible'' test coverage
        %     items, which are ``not \dots{} executable or [are] impossible to be covered by a
        %     test case'' \citetext{p.~30}. Perhaps more interestingly, the further
        %     implication is
        % \else
        %     This means
    \fi % that
    Therefore, a given coverage metric implies a test approach aimed to
    maximize it. For example, path testing ``aims to execute all entry-to-exit
    control flow paths in a \acs{sut}'s control flow graph'' \citep[p.~5-13]{SWEBOK2024},
    thus maximizing the path coverage
    \ifnotpaper
        \citep[see][Fig.~1\thesisissueref{63}]{SharmaEtAl2021}\else
        (see \cite[Fig.~1]{SharmaEtAl2021}\thesisissueref{63})\fi.

    \subsubsection{Quality-driven Types}
    \label{qual-test}

    Since test types are ``focused on specific quality characteristics''
    \ifnotpaper
        (\citealp[p.~15]{IEEE2022}; \citeyear[p.~7]{IEEE2021};
        \citeyear[p.~473]{IEEE2017}\todo{OG IEEE 2013})%
    \else
        \cite[p.~15]{IEEE2022}, \cite[p.~7]{IEEE2021}, \cite[p.~473]{IEEE2017}%
    \fi, they can be derived from software qualities: ``capabilit[ies] of
    software product[s] to satisfy stated and implied needs when used under
    specified conditions'' \citep[p.~424]{IEEE2017}\todo{OG ISO/IEC 2014}. This
    is supported by reliability and performance testing, which are both examples of
    test types \citep{IEEE2022, IEEE2021} that are based on their underlying
    qualities \citep[p.~18]{FentonAndPfleeger1997}.
    % \ifnotpaper
    %     For quantifying quality-driven testing, measurements should include
    %     an entity to be measured, a specific attribute to measure, and the actual
    %     measure (i.e., units, starting state, ending state, what to include)
    %     \citetext{p.~36} where attributes must be
    %     defined before they can be measured \citetext{p.~38}.
    %
    % \fi
    Given the importance of software qualities to defining test types, the
    definitions of \qualityCount{} software qualities are also tracked in this
    current work\thesisissueref{21,23,27}. This was done by capturing their
    definitions, any precedent for the existence of an associated test type,
    and any synonyms (see \Cref{syn-rels}) and additional notes in a glossary.
    Software qualities are ``upgraded'' to test types when mentioned (or
    implied) by a source by adding an associated test approach to this glossary
    (as outlined in \Cref{procedure}) and removing the quality entry. Examples
    of this include conformance testing
    \ifnotpaper
        (\citealp[p.~5-7]{SWEBOK2024}; \citealp[p.~25]{JardEtAl1999}; implied
        by \citealp[p.~93]{IEEE2017})
    \else
        \cite[p.~5-7]{SWEBOK2024}, \cite[p.~25]{JardEtAl1999}
    \fi and efficiency testing \citep[p.~44]{Kam2008}.

    \subsubsection{Attacks}
    \label{attacks}
    While attacks can be ``malicious'' \citep[p.~7]{IEEE2017}, they are also
    given as a test practice (\citeyear[p.~34]{IEEE2022}; see \Cref{tab:multiCats}).
    This means that software attacks, such as code injection and password
    cracking \citepISTQB{}, can also be used for testing software, and only
    this kind of software attack is in scope. This is supported by the fact
    that penetration testing is also called ``ethical hacking testing''
    \citep[p.~13-4]{SWEBOK2024} or just ``ethical hacking''
    \citep[p.~28]{Gerrard2000b}; while hacking in general is not a test
    approach, doing so systematically to test and improve the software is.

    \subsubsection{Requirements-driven Approaches}
    \label{req-test}
    While not as universally applicable, some types of requirements have associated
    types of testing (e.g., functional, non-functional, security). This may mean
    that categories of requirements \emph{also} imply related testing approaches
    (such as ``technical testing''). \ifnotpaper Even assuming this is the case, some types of
        requirements do not apply to the code itself, and as such are out of scope%
        \thesisissueref{43}, such as:
        \begin{itemize}
            \item \textbf{Nontechnical Requirement:} a ``requirement affecting product
                  and service acquisition or development that is not a property of
                  the product or service'' \citep[p.~293]{IEEE2017}
            \item \textbf{Physical Requirement:} a ``requirement that specifies a
                  physical characteristic that a system or system component must
                  possess'' \citep[p.~322]{IEEE2017}
        \end{itemize}
    \fi

    \subsubsection{Language-specific Approaches}
    \label{lang-test}
    Specific programming languages are sometimes used to define test approaches.
    If the reliance on a specific programming language is intentional, then
    this really implies an underlying test approach that may be generalized to
    other languages. These are therefore considered out-of-scope\thesisissueref{63},
    including the following examples:

    \begin{itemize}
        \item ``They implemented an approach \dots{} for JavaScript testing
              (referred to as Randomized)'' \citep[p.~192]{DoğanEtAl2014};
              this really refers to random testing used within JavaScript
        \item ``SQL statement coverage'' is really just statement coverage
              used specifically for SQL statements \citep[Tab.~13]{DoğanEtAl2014}
              \todo{OG Alalfi et al., 2010}
        \item ``Faults specific to PHP'' is just a subcategory of fault-based
              testing, since ``execution failures \dots{} caused by missing an
              included file, wrong MySQL quer[ies] and uncaught exceptions''
              are not exclusive to PHP \citep[Tab.~27]{DoğanEtAl2014}
              \todo{OG Artzi et al., 2008}
        \item While ``HTML testing'' is listed or implied by
              \citeauthor{Gerrard2000a} (\citeyear[Tab.~2]{Gerrard2000a};
              \citeyear[Tab.~1, p.~3]{Gerrard2000b}) and
              \citet[p.~220]{Patton2006}, it seems to be a combination of syntax
              testing, functionality testing, hyperlink testing/link checking,
              cross-browser compatibility testing, performance testing, and
              content checking \citep[p.~3]{Gerrard2000b}
    \end{itemize}

    \subsubsection{Orthogonally Derived Approaches}
    \label{orth-test}
    Some test approaches appear to be combinations of other (seemingly
    orthogonal) approaches. While the use of a combination term can sometimes
    make sense, such as when writing a paper or performing testing that focuses
    on the intersection between two test approaches, they are sometimes given
    the same ``weight'' as their atomic counterparts. For example, \citetISTQB{}
    \multiAuthHelper{include} ``formal reviews'' and ``informal reviews'' in
    \ifnotpaper their \else its \fi glossary as separate terms, despite their
    definitions essentially boiling down to ``reviews that follow (or do not
    follow) a formal process'', which do not provide any new information.
    We consider these out of scope if their details are captured by their
    in-scope subapproaches, but record them as support for the orthogonality of
    test approach categories in \Cref{orth-test-exs}. If a source describes an
    orthogonally derived approach in more detail, such as security audits, we
    also record it as a distinct approach in \ourApproachGlossary{} with its
    related information.

    The existence of orthogonal combinations could allow for other test
    approaches to be extrapolated from them. For example, \citet{Moghadam2019}
    uses the phrase ``machine learning-assisted performance testing''; since
    performance testing is a known test approach, this may imply the existence
    of the test approach ``machine learning-assisted testing''. Likewise,
    \citet{JardEtAl1999} \multiAuthHelper{use} the phrases ``local synchronous
    testing'' and ``remote asynchronous testing''. While these can be
    decomposed, for example, into local testing and synchronous testing,
    the two resulting approaches may not be orthogonal, potentially even having
    a parent-child relation (defined in \Cref{par-chd-rels}).

\fi