\section{Methodology}
\label{methodology}

\subsection{Sources}
\label{sources}
As there is no single authoritative source on software testing terminology,
we need to look at many to see how various terms are used in practice.
% Unfortunately, this brings to light a variety of discrepancies.
Starting from some set of sources, we then use
``snowball sampling'' (a ``method of \dots\ sample selection \dots\ used to
locate hidden populations'' \citep{Johnson2014}) to gather further sources%
\seeParAlways{undef-terms}. Sources with a similar degree of
``trustworthiness'' are grouped into categories; sources that are more
``trustworthy'':
\begin{enumerate}
    \item have gone through a peer-review process,
    \item are written by numerous, well-respected authors,
    \item are informed by many sources, and
    \item are accepted and used in the field of software.
\end{enumerate}

We therefore create the following categories, given in order of descending
trustworthiness: \stds{}, \metas{}, \texts{}, and \papers{}. \ifnotpaper
    Additionally, some information comes from \nameref{infers}. \fi Each category is
given a unique colour to better track how their information appears in relevant
graphs (see \Cref{fig:recovery-graph-current,fig:recovery-graph-proposed,%
    fig:scal-graph-current,fig:scal-graph-proposed,fig:perf-graph}). A summary
of how many sources comprise each category is given in \Cref{fig:sourceSummary}.

\subsubsection{\stdSources{1}}
\label{stds}
\stdSources{2}
\begin{itemize}
    \item Colored \textcolor{green}{green}
    \item Information on software development and testing from
          standards bodies \ifnotpaper\else (such as IEEE and ISO)\fi
    \item Written by reputable organizations for use in software engineering
\end{itemize}

\subsubsection{\metaSources{1}}
\label{metas}
\metaSources{2}
\begin{itemize}
    \item Colored \textcolor{blue}{blue}
    \item Collections of relevant terminology (such as \acs{istqb}'s glossary,
          the \acs{swebok}, and \ifnotpaper \citeauthor{DoğanEtAl2014}\else
              Doğan et al.\fi's literature review \citeyearpar{DoğanEtAl2014})
    \item Built up from various sources, including \stds{}, and often written
          by a large organization (such as \acs{istqb}); the \acs{swebok} is
          ``proposed as a suitable foundation for government licensing, for the
          regulation of software engineers, and for the development of
          university curricula in software engineering''
          \citep[p.~xix]{KanerEtAl2011}
\end{itemize}

\subsubsection{\textSources{1}}
\label{texts}
\textSources{2}
\begin{itemize}
    \item Colored \textcolor{Maroon}{maroon}
    \item Textbooks trusted at McMaster \citep{Patton2006, PetersAndPedrycz2000,
              vanVliet2000} were the original (albeit ad hoc and arbitrary)
          starting point
    \item Written by smaller sets of authors, but with a formal review process
          before publication
    \item Used as resources for teaching software engineering and may be used
          as guides in industry
\end{itemize}

\subsubsection{\paperSources{1}}
\label{papers}
\paperSources{2}
\begin{itemize}
    \item Colored black
    \item Mainly consists of academic papers: journal articles, conference
          papers, reports \citep{Kam2008,Gerrard2000a,Gerrard2000b}, and a
          thesis \citep{Bas2024}
          % \item Includes less-formal classifications (such as
          %       \citep{KuļešovsEtAl2013})
    \item Written by much smaller sets of authors with unknown peer review
          processes
    \item Much less widespread than other categories of sources
    \item Many of these sources were investigated to ``fill in''
          missing definitions\seeSectionParAlways{undef-terms}
    \item Also included (for brevity) are some less-than-academic sources to
          investigate how terms are used in practice, such as websites
          \citep{LambdaTest2024,Pandey2023} and a booklet \citep{SPICE2022}
\end{itemize}

\ifnotpaper
    \subsubsection{Inferences}
    \label{infers}
    While not as clear-cut as the other source categories, some information is
    inferred from various sources, such as ``surface-level'' analysis that
    follows straightforwardly without being explicitly stated in the text.
    Inferred relations are colored \textcolor{gray}{gray} and
    inferred discrepancies are given in \Cref{infer-discreps}.
\fi

\begin{figure}
    \centering
    \begin{tikzpicture}
        \pie[sum=auto, after number=, text=legend, thick,
            scale=\ifnotpaper0.7\else0.5\fi,
            every label/.style={align=left, scale=0.7}]
        {\stdSources{3}/\stds{},
            \metaSources{3}/\metas{},
            \textSources{3}/\texts{},
            \paperSources{3}/\papers{}}
    \end{tikzpicture}
    \caption{Summary of how many sources comprise each source category.}
    \label{fig:sourceSummary}
\end{figure}

\subsection{Procedure}

To track terminology used in the literature, we build a glossary of test
approaches, including the term itself, its definition, and
any synonyms or parents. Many test approaches are multi-faceted and can be
``specialized'' into others, such as \nameref{perf-test-rec}. These
``specializations'' will be referred to as ``children'' or
``sub-approaches\footnote{This nomenclature extends to other categories of
    approaches from \Cref{tab:ieeeTestTerms}, such as ``sub-type''.}''
of the multi-faceted
``parent''. Any additional notes, such as questions or sources to investigate
further, are also recorded. Approach categorizations, such as those found in
\Cref{tab:ieeeTestTerms} and some outliers (e.g., ``artifact''), are tracked
for future investigation.

Most relevant sources are analyzed in their entirety to systematically extract
terminology, with the exception of some sources that were only partially
investigated. This is the case for sources chosen for a specific area of
interest or based on a test approach that was determined to be out-of-scope,
such as some sources given in \Cref{undef-terms}.
Heuristics are used to guide this process, by investigating:

\begin{itemize}
    \item glossaries and lists of terms,
    \item testing-related terms (e.g., terms containing ``test(ing)'',
          \ifnotpaper ``review(s)'', ``audit(s)'', \fi
          ``validation'', or ``verification''),
    \item terms that had emerged as part of already-discovered
          testing approaches, \emph{especially} those that were ambiguous
          or prompted further discussion (e.g., terms containing
          ``performance'', ``recovery'', ``component'', ``bottom-up'',
          \ifnotpaper ``boundary'', \fi or ``configuration''), and
    \item terms that implied testing approaches%
          \ifnotpaper\footnote{
                  Since these methods for deriving test approaches only arose
                  as research progressed, some examples would have been missed
                  during the first pass(es) of resources investigated earlier
                  in the process. While reiterating over them would be ideal,
                  this may not be possible due to time constraints.
              }\fi%
          \seeSectionPar{derived-tests}.
\end{itemize}

When terms have multiple definitions, either the clearest and most concise
version is kept, or they are merged to paint a more complete picture.
If any discrepancies or ambiguities
arise, they are reasonably investigated and always documented. If a
testing approach is mentioned but not defined, it is added to the
glossary to indicate it should be investigated further%
\seeSectionParAlways{undef-terms}. A similar methodology
is used for tracking software qualities, albeit in a separate
document\seeSectionPar{qual-test}.

During the first pass of data collection, all software-testing-focused terms
are included. Some of them are less applicable to test case automation
\ifnotpaper(such as \Cref{static-test}, \thesisissueref{39}) \fi or too
broad\ifnotpaper(such as \Cref{attacks}, \thesisissueref{55})\fi, so they
will be omitted over the course of analysis.

\ifnotpaper
    During this investigation, some terms came up that seemed to be relevant to
    testing but were so vague, they didn't provide any new information. These were
    decided to be not worth tracking\seeThesisIssuePar{39}[, \thesisissueref{44},
        \thesisissueref{28}] and are listed below:

    \begin{itemize}
        \item \textbf{Evaluation:} the ``systematic determination of the extent
              to which an entity meets its specified criteria''
              \citep[p.~167]{IEEE2017}
        \item \textbf{Product Analysis:} the ``process of evaluating a product by
              manual or automated means to determine if the product has certain
              characteristics'' \citep[p.~343]{IEEE2017}
        \item \textbf{Quality Audit:} ``a structured, independent process to
              determine if project activities comply with organizational and
              project policies, processes, and procedures'' \citep[p.~361]{IEEE2017}
              \todo{OG PMBOK}
        \item \textbf{Software Product Evaluation:} a ``technical operation that
              consists of producing an assessment of one or more characteristics
              of a software product according to a specified procedure''
              \citep[p.~424]{IEEE2017}
    \end{itemize}
\fi
\subsection{Undefined Terms}
\label{undef-terms}

The search process led to some testing approaches being
mentioned without definition;
\citep{IEEE2022} and \citep{Firesmith2015} in particular introduced many.
Once \stds{} had been exhausted, we devised a strategy to
look for sources that explicitly define these terms, consistent with
our snowballing approach. This uncovers new approaches, both in and out of
scope (such as \acf{emsec} testing, HTML testing, and aspects of loop testing and
orthogonal array testing\seeSectionPar{scope}).

The following terms (and their respective related terms) were explored%
\ifnotpaper in the following sources\fi, bringing the number of testing
approaches from \the\TotalBefore{} to \the\TotalAfter{} and the number of
\emph{undefined} terms from \the\UndefBefore{} to \the\UndefAfter{} (the
assumption can be made that about \the\numexpr 100 - 100 * (\UndefAfter -
\UndefBefore) / (\TotalAfter - \TotalBefore)\relax\% of added terms also
included a definition):

\input{build/undefTerms}

\ifnotpaper\else
    \ieeeTestTermsTable{}  % Moved here to display nicely in paper
    \subsection{Tools}  % Part of separate chapter in thesis 
    \graphGenDesc{}
\fi
